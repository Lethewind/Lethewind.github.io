<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Generative adversarial network in medical imaging A review</title>
      <link href="/2021/10/11/Generative%20adversarial%20network%20in%20medical%20imaging%20A%20review/"/>
      <url>/2021/10/11/Generative%20adversarial%20network%20in%20medical%20imaging%20A%20review/</url>
      
        <content type="html"><![CDATA[<h1 id="Generative-adversarial-network-in-medical-imaging-A-review"><a href="#Generative-adversarial-network-in-medical-imaging-A-review" class="headerlink" title="Generative adversarial network in medical imaging: A review"></a>Generative adversarial network in medical imaging: A review</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross- modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.</p><p>生成对抗网络在计算机视觉社区中获得了很多关注，因为它们无需对概率密度函数进行显式建模即可生成数据。判别器带来的对抗性损失提供了一种巧妙的方法，可以将未标记的样本纳入训练并施加更高阶的一致性。这已被证明在许多情况下都很有用，例如域适应、数据增强和图像到图像的转换。这些特性吸引了医学成像界的研究人员，我们已经看到在许多传统和新颖的应用中迅速采用，例如图像重建、分割、检测、分类和跨模态合成。 根据我们的观察，这种趋势将继续下去，因此我们对使用对抗性训练的医学成像的最新进展进行了整理，希望使对这项技术感兴趣的研究人员受益。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>With the resurgence of deep learning in computer vision starting from 2012 ( Krizhevsky et al., 2012 ), the adoption of deep learning methods in medical imaging has increased dramatically. It is estimated that there were over 400 papers published in 2016 and 2017 in major medical imaging related conference venues and journals ( Litjens et al., 2017 ). The wide adoption of deep learning in the medical imaging community is due to its demonstrated potential to complement image interpretation and augment image representation and classification. In this article, we focus on one of the most interesting recent breakthroughs in the field of deep learning - generative adversarial networks (GANs) - and their potential applications in the field of medical imaging.</p><p>随着 2012 年计算机视觉深度学习的复苏（Krizhevsky et al., 2012），深度学习方法在医学成像中的应用急剧增加。 据估计，2016年和2017年在主要医学影像相关会议和期刊上发表的论文超过400篇（Litjens et al., 2017）。深度学习在医学成像界的广泛采用是由于其在补充图像解释和增强图像表示和分类方面表现出的潜力。在本文中，我们关注深度学习领域最近最有趣的突破之一——生成对抗网络 (GAN)——及其在医学成像领域的潜在应用。</p><p>GANs are a special type of neural network model where two networks are trained simultaneously, with one focused on image generation and the other centered on discrimination. The ad-versarial training scheme has gained attention in both academia and industry due to its usefulness in counteracting domain shift, and effectiveness in generating new image samples. This model has achieved state-of-the-art performance in many image generation tasks, including text-to-image synthesis ( Xu et al., 2017 ), super-resolution ( Ledig et al., 2017 ), and image-to-image translation ( Zhu et al., 2017 ).</p><p>GAN 是一种特殊类型的神经网络模型，其中两个网络同时训练，一个专注于图像生成，另一个专注于判别。由于对抗域迁移的有用性和生成新图像样本的有效性，对抗性训练方案在学术界和业界都受到关注。该模型在许多图像生成任务中取得了最先进的性能，包括文本到图像合成（Xu et al., 2017）、超分辨率（Ledig et al., 2017）和图像到图像转换（Zhu et al., 2017）。</p><p>Unlike deep learning which has its roots traced back to the 1980s ( Fukushima and Miyake, 1982 ), the concept of ad- versarial training is relatively new with significant recent progress ( Goodfellow et al., 2014 ). This paper presents a gen- eral overview of GANs, describes their promising applications in medical imaging, and identifies some remaining challenges that need to be solved to enable their successful application in other medical imaging related tasks.</p><p>与起源于 1980 年代（Fukushima 和 Miyake，1982）的深度学习不同，对抗训练的概念相对较新，并且最近取得了重大进展（Goodfellow 等，2014）。 本文概述了 GAN，描述了它们在医学成像中的有前景的应用，并确定了一些需要解决的剩余挑战，以使其成功应用于其他医学成像相关任务。</p><p>To present a comprehensive overview of all relevant works on GANs in medical imaging, we searched databases including PubMed, arXiv, proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), SPIE Medical Imaging, IEEE International Symposium on Biomedical Imaging (ISBI), and International conference on Medical Imaging with Deep Learning (MIDL). We also incorporated cross referenced works not identified in the above search process. Since there are research publications coming out every month, without losing generality, we set the cut offtime of the search as January 1st, 2019. Works on arXiv that report only preliminary results are excluded from this review. Descriptive statistics of these papers based on task, imaging modality and year can be found in Fig. 1 .</p><p>为了全面概述医学成像中 GAN 的所有相关工作，我们检索了包括 PubMed、arXiv、医学图像计算和计算机辅助干预国际会议 (MICCAI)、SPIE 医学成像、IEEE 生物医学成像国际研讨会论文集在内的数据库 (ISBI) 和深度学习医学成像国际会议 (MIDL)。 我们还合并了上述搜索过程中未确定的交叉引用作品。 由于每个月都有研究发表，在不失一般性的情况下，我们将搜索截止时间设置为 2019 年 1 月 1 日。 arXiv 上仅报告初步结果的作品被排除在本次审查之外。 这些论文基于任务、成像方式和年份的描述性统计可以在图 1 中找到。</p><p><img src="https://i.loli.net/2021/10/09/zG6Bkgs3O2VWSpF.png" alt="image-20211009191958548"></p><p>Fig. 1. (a) Categorization of GAN related papers according to canonical tasks. (b) Categorization of GAN related papers according to imaging modality. (c) Number of GAN related papers published from 2014. Note that some works performed various tasks and conducted evaluation on datasets with different modalities. We counted these works multiple times in plotting these graphs. Works related to cross domain image transfer were counted based on the source domain. The statistics presented in figure (a) and (b) are based on papers published on or before January 1st, 2019.</p><p>图1..（a） 根据规范任务对与GAN相关的论文进行分类。（b） 根据影像学形态分类与GAN相关的论文。（c） 2014年发表的与GAN相关的论文数量。请注意，一些工作执行了各种任务，并对不同模式的数据集进行了评估。在绘制这些图表时，我们对这些作品进行了多次计数。基于源域统计与跨域图像传输相关的工作。图（a）和（b）中的统计数据基于2019年1月1日或之前发表的论文。</p><p>The remainder of the paper is structured as follows. We begin with a brief introduction of the principles of GANs and some of its structural variants in Section 2 . It is followed by a com- prehensive review of medical image analysis tasks using GANs in Section 3 including but not limited to the fields of radiology, histopathology and dermatology. We categorize all the works according to canonical tasks: reconstruction, image synthesis, segmentation, classification, detection, registration, and others. Section 4 summarizes the review and discusses prospective applications and identifies open challenges.</p><p>本文其余部分的结构如下。在第2节中，我们首先简要介绍GANs的原理及其一些结构变体。第3节对使用GANs的医学图像分析任务进行了全面回顾，包括但不限于放射学、组织病理学和皮肤学领域。我们根据标准任务对所有工作进行分类：重建、图像合成、分割、分类、检测、配准等。第4节总结了审查，讨论了潜在的应用，并确定了存在的挑战。</p><h2 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h2><h3 id="2-1-Vanilla-GAN"><a href="#2-1-Vanilla-GAN" class="headerlink" title="2.1 Vanilla GAN"></a>2.1 Vanilla GAN</h3><p>The vanilla GAN ( Goodfellow et al., 2014 ) is a generative model that was designed for directly drawing samples from the desired data distribution without the need to explicitly model the underlying probability density function. It consists of two neural networks: the generator $G$ and the discriminator $D$. The input to $G$, $z$ is pure random noise sampled from a prior distribution $p(z)$, which is commonly chosen to be a Gaussian or a uniform distribution for simplicity. The output of $G$, $x_g$ is expected to have visual similarity with the real sample $x_r$ that is drawn from the real data distribution $p_r(x)$. We denote the non-linear mapping function learned by $G$ parametrized by $θ_g$ as $x_g=G(z;θ_g)$ . The input to $D$ is either a real or generated sample. The output of $D$, $y_1$ is a single value indicating the probability of the input being a real or fake sample. The mapping learned by $D$ parametrized by $θ_d$ is denoted as $y_1=D(x;θ_d) $. The generated samples form a distribution $p_g ( x )$ which is desired to be an approximation of $p_r( x )$ after successful training. The top of Fig. 2 shows an illustration of a vanilla GAN’s configuration. G in this example is generating a 2D CT slice depicting a lung nodule.</p><p>Vanilla GAN（Goodfello et al.，2014）是一种生成模型，设计用于直接从所需数据分布中提取样本，而无需显式建模基础概率密度函数。它由两个神经网络组成：生成器$G$和判别器$D$。$G$的输入$z$是从先验分布$p(z)$中采样的纯随机噪声，为简单起见，通常选择高斯分布或均匀分布。$G$的输出$x_g$预期与从真实数据分布$p_r(x)$中提取的真实样本$x_r$具有视觉相似性。我们将$G$学习的非线性映射函数表示为$x_g=G(z;θ_G)$。$D$的输入要么是真实的样本，要么是生成的样本。$D$的输出$y_1$是一个单一值，表示输入为真实或虚假样本的概率。由$D$学习并由$θ_d$参数化的映射表示为$y_1=D(x;θ_D)$。生成的样本形成一个分布$p_g(x)$，在成功训练后，该分布期望是$p_r(x)$的近似值。图2的顶部示出了GAN的配置的图示。在本例中，G生成了一个描绘肺结节的2D CT切片。</p><p><img src="https://i.loli.net/2021/10/09/A5HREaYkfqcQoUF.png" alt="image-20211009201708590"></p><p>Fig. 2. Schematic view of the vanilla GAN for synthesis of lung nodule on CT images. Top of the figure shows the network configuration. The part below shows the input, output and the internal feature representations of the generator $G$ and discriminator $D$. $G$ transforms a sample $z$ from $p ( z )$ into a generated nodule $x_g$ . $D$ is a binary classifier that differentiates the generated and real images of lung nodule formed by $x_g$ and $x_r$ respectively.</p><p>图2.CT图像上用于合成肺结节的香草甘的示意图。图的顶部显示了网络配置。下面的部分显示了生成器$G$和判别器$D$的输入、输出和内部特征表示。$G$将样本$z$从$p(z)$转换为生成的结节$x_g$，$D$是一个二值分类器，用于区分由$x_g$和$x_r$分别形成的肺结节的生成图像和真实图像。</p><p>$D$’s objective is to differentiate these two groups of images whereas the generator $G$ is trained to confuse the discriminator $D$ as much as possible. Intuitively, $G$ could be viewed as a forger trying to produce some quality counterfeit material, and $D$ could be regarded as the police officer trying to detect the forged items. In an alternative view, we can perceive $G$ as receiving a reward signal from $D$ depending upon whether the generated data is accurate or not. The gradient information is back propagated from $D$ to $G$, so $G$ adapts its parameters in order to produce an output image that can fool $D$. The training objectives of $D$ and $G$ can be expressed mathematically as:</p><p>$D$的目标是区分这两组图像，而生成器$G$经过训练以尽可能混淆判别器$D$。直觉上，$G$可以被视为一个试图制造一些高质量假冒材料的伪造者，$D$可以被视为试图检测伪造物品的警官。在另一种观点中，我们可以将$G$视为从$D$接收到激励信号，这取决于生成的数据是否准确。梯度信息从$D$反向传播到$G$，因此$G$调整其参数，以产生可以愚弄$D$的输出图像。$D$和$G$的训练目标可以数学表示为：</p><p><img src="https://i.loli.net/2021/10/09/5WkXtMze3TYsUl4.png" alt="image-20211009203028462"></p><p>As can be seen, $D$ is simply a binary classifier with a maximum log likelihood objective. If the discriminator $D$ is trained to optimality before the next generator $G$ updates, then minimizing $\cal{L}\rm{^{GAN}_G}$ is proven to be equivalent to minimizing the Jensen–Shannon (JS) divergence between $p_r(x)$ and $p_g(x)$ ( Goodfellow et al., 2014 ). The desired outcome after training is that samples formed by $x_g$ should approximate the real data distribution $p_r(x)$.</p><p>可以看出，$D$只是一个具有<a href="####%E6%9C%80%E5%A4%A7%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E7%9B%AE%E6%A0%87">最大对数似然目标</a>的二分类器。如果在下一个生成器$G$更新之前，将判别器$D$训练为最优，那么最小化$\cal{L}\rm{^{GAN}_G}$被证明等同于最小化$p_r(x)$和$p_g(x)$之间的Jensen–Shannon(JS)散度（Goodfello等人，2014）。训练后的预期结果是，由$x_g$形成的样本应近似于实际数据分布$p_r(x)$。</p><h3 id="2-2-Challenges-in-optimizing-GANs"><a href="#2-2-Challenges-in-optimizing-GANs" class="headerlink" title="2.2 Challenges in optimizing GANs"></a>2.2 Challenges in optimizing GANs</h3><p>The above GAN training objective is regarded as a saddle point optimization problem ( Yadav et al., 2018 ) and the training is often accomplished by gradient-based methods. G and D are trained alternately from scratch so that they may evolve together. However, there is no guarantee of balance between the training of G and D with the JS divergence. As a consequence, one network may inevitably be more powerful than the other, which in most cases is D. When D becomes too strong as opposed to G, the generated samples become too easy to be separated from real ones, thus reaching a stage where gradients from D approach zero, providing no guidance for further training of G. This hap- pens more frequently when generating high resolution images due to the difficulty of generating meaningful high frequency details.</p><p>上述GAN训练目标被视为<a href="####%E9%9E%8D%E7%82%B9%E4%BC%98%E5%8C%96">鞍点优化</a>问题（Yadav等人，2018年），训练通常通过基于梯度的方法完成。G和D从零开始交替训练，以便它们可以一起进化。然而，不能保证G和D的训练与<a href="####JS%E6%95%A3%E5%BA%A6">JS散度</a>之间的平衡。因此，一个网络可能不可避免地比另一个网络更强大，在大多数情况下是D。当D相对于G变得太强时，生成的样本变得太容易与真实样本分离，从而达到D的梯度接近零的阶段，没有为G的进一步训练提供指导。由于难以生成有意义的高频细节，因此在生成高分辨率图像时，此种现象会出现地更加频繁。</p><p>Another problem commonly faced in training GANs is mode collapse, which, as the name indicates, is a case when the distribution $p_g(x)$ learned by G focuses on a few limited modes of the data distribution $p_r(x)$. Hence instead of producing diverse images, it generates a limited set of samples.</p><p>在训练GANs中通常面临的另一个问题是<a href="####%E6%A8%A1%E5%BC%8F%E5%B4%A9%E6%BA%83">模式崩溃</a>，顾名思义，这是G学习的分布$p_g(x)$关注数据分布$p_r(x)$的几个有限模式的情况。因此，它不是生成不同的图像，而是生成一组有限的样本。</p><h3 id="2-3-Variants-of-GANs"><a href="#2-3-Variants-of-GANs" class="headerlink" title="2.3 Variants of GANs"></a>2.3 Variants of GANs</h3><h4 id="2-3-1-Varying-objective-of-D"><a href="#2-3-1-Varying-objective-of-D" class="headerlink" title="2.3.1 Varying objective of D"></a>2.3.1 Varying objective of D</h4><p>In order to stabilize training and also to avoid mode collapse, different losses for D have been proposed, such as <strong>f-divergence</strong> (f-GAN) ( Nowozin et al., 2016 ), <strong>least-square</strong> (LSGAN) ( Mao et al., 2017 ), <strong>hinge loss</strong> ( Miyato et al., 2018 ), and <strong>Wasserstein distance</strong> (WGAN, WGAN-GP) ( Arjovsky et al., 2017; Gulrajani et al., 2017 ). Among these, Wasserstein distance is arguably the most popular metric. As an alternative to the real/fake discrimination scheme, Springenberg (2015) proposed an entropy based objective where real data is encouraged to make confident class predictions (CatGAN, Fig. 3 b). In EBGAN ( Zhao et al., 2016 ) and BE- GAN ( Berthelot et al., 2017 ) ( Fig. 3 c), the commonly used encoder architecture for discriminator is replaced with an autoencoder architecture. D’s objective then becomes matching autoencoder loss distribution rather than data distribution.</p><p>为了稳定训练并避免模式崩溃，提出了D的不同损失，如<a href="####f%E6%95%A3%E5%BA%A6">f散度</a>（f-GAN）（Nowozin等人，2016年）、最小二乘（LSGAN）（Mao等人，2017年）、<a href="####%E9%93%B0%E9%93%BE%E6%8D%9F%E5%A4%B1">铰链损失</a>（Miyato等人，2018年）和<a href="####Wasserstein%E8%B7%9D%E7%A6%BB">Wasserstein距离</a>（WGAN，WGAN-GP）（Arjovsky等人，2017年；Gularjani等人，2017年）。其中，Wasserstein距离可以说是最流行的度量。作为真/假鉴别方案的替代方案，Springenberg（2015）提出了一种基于熵的目标，其中鼓励真实数据进行置信的类别预测（CatGAN，图3 b）。在EBGAN（Zhao等人，2016年）和BE-GAN（Berthelot等人，2017年）（图3 c）中，用于判别器的常用编码器架构被<a href="####%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84">自动编码器架构</a>取代。D的目标是匹配自动编码器的损失分布，而不是数据分布。</p><p>GANs themselves lack the mechanism of inferencing the underlying latent vector that is likely to encode the input. Therefore, in ALI ( Dumoulin et al., 2016 ) and BiGAN ( Donahue et al., 2016 ) ( Fig. 3 d), a separate encoder network is incorporated. D’s objective then becomes separating joint samples $(x_g,z_g)$ and $(x_r,z_r)$. In InfoGAN ( Fig. 3 e), the discriminator outputs the latent vector that encodes part of the semantic features of the generated image. The discriminator maximizes the mutual information between the generated image and the latent attribute vector the generated image is conditioned upon. After successful training, InfoGAN can explore inherent data attributes and perform conditional data generation based on these attributes. The use of class labels has been shown to further improve generated image’s quality and this information can be easily incorporated into D by enforcing D to provide class probabilities and use cross entropy loss for optimization such as used in ACGAN ( Odena et al., 2017 ) ( Fig. 3 f).</p><p>GANs本身缺乏推断潜在向量的机制，该潜在向量可能对输入进行编码。因此，在ALI（Dumoulin等人，2016）和BiGAN（Donahue等人，2016）（图3 d）中，合并了一个单独的编码器网络。D的目标是分离关节样本$(x_g,z_g)$和$(x_r,z_r)$。在InfoGAN（图3e）中，判别器输出对所生成图像的部分语义特征进行编码的潜在向量。判别器最大化生成图像和生成图像所基于的潜在属性向量之间的互信息。成功训练后，InfoGAN可以探索固有的数据属性，并基于这些属性执行条件数据生成。类标签的使用已被证明可进一步提高生成图像的质量，通过强制D提供类概率并使用交叉熵损失进行优化（如在ACGAN中使用的），该信息可容易地并入D中（Odena et al.，2017）（图3 f）。</p><h4 id="2-3-2-Varying-object-of-G"><a href="#2-3-2-Varying-object-of-G" class="headerlink" title="2.3.2 Varying object of G"></a>2.3.2 Varying object of G</h4><p>In the vanilla GAN, G transforms noise z to sample $x_g=G(z)$ . This is usually accomplished by using a decoder network to progressively increase the spatial size of the output until the desired resolution is achieved as shown in Fig. 2 . Larsen et al. (2015) proposed a variational autoencoder network (VAE) as the underlying architecture of G (VAEGAN, Fig. 3 g), where it can use pixel-wise reconstruction loss to enforce the decoder part of VAE to generate structures to match the real images.</p><p>在标准GAN中，$G$将噪声$z$转换为样本$x_g=G(z)$。这通常通过使用解码器网络来逐步增加输出的空间大小来实现，直到如图2所示实现所需的分辨率。Larsen et al.（2015）提出了一种变分自动编码器网络（VAE）作为G的底层架构（VAEGAN，图3 G），其中它可以使用像素级重建损失来强制VAE的解码器部分生成与真实图像匹配的结构。</p><p>The original setup of a GAN does not have any restrictions on the modes of data it can generate. However, if auxiliary information were provided during the generation, the GAN can be driven to output images with desired properties. A GAN in this scenario is usually referred as a conditional GAN (cGAN) and the generation process can be expressed as $x_g=G(z,c)$ .</p><p>GAN的原始设置对其可以生成的数据模式没有任何限制。然而，如果在生成期间提供辅助信息，则可以驱动GAN以输出具有期望特性的图像。在这种情况下，GAN通常被称为条件GAN（cGAN），并且生成过程可以表示为$x_g=G(z,c)$。</p><p>One of the most common conditional inputs $c$ is an image. pix2pix, the first general purpose GAN based image-to-image translation framework was proposed by Isola et al. (2016) ( Fig. 4 a). Further, task related supervision was introduced to the generator. For example, reconstruction loss for image restoration and Dice loss ( Milletari et al., 2016 ) for segmentation. This form of supervision requires aligned training pairs. Zhu et al. (2017) and Kim et al. (2017) relaxed this constraint by stitching two generators together head to toe so that images can be translated between two sets of unpaired samples ( Fig. 4 b). For the sake of simplicity, we chose CycleGAN to represent this idea in the rest of this paper. Another model named UNIT ( Fig. 4 c) can also perform unpaired image-to-image transform by combining two VAEGANs together with each one responsible for one modality but sharing the same latent space ( Liu et al., 2017a ). These image-to-image translation frameworks are very popular in the medical imaging community due to their general applicability.</p><p>最常见的条件输入$c$之一是图像。pix2pix是第一个基于GAN的通用图像到图像转换框架，由Isola等人（2016）提出（图4a）。此外，还向生成器引入了与任务相关的监督。例如，用于图像恢复的重建损失和用于分割的骰子损失（Milleri等人，2016）。这种形式的监督需要成对的训练。Zhu et al.（2017）和Kim et al.（2017）通过将两个生成器从头到尾缝合在一起，从而放松了这一约束，从而可以在两组未配对样本之间转换图像（图4b）。为了简单起见，我们选择了CycleGAN在本文的其余部分中表示这个想法。另一个名为UNIT的模型（图4c）也可以通过将两个Vaegan组合在一起，每个Vaegan负责一个模态，但共享相同的潜在空间来执行未配对的图像到图像变换（Liu等人，2017a）。这些图像到图像的转换框架由于其普遍适用性而在医学成像界非常流行。</p><p>Other than image, the conditional input can be class labels (CGAN, Fig. 3 h) ( Mirza and Osindero, 2014 ), text descriptions ( Zhang et al., 2017a ), object locations ( Reed et al., 2016a; 2016b ), surrounding image context ( Pathak et al., 2016 ), or sketches ( Sangkloy et al., 2017 ). Note that ACGAN mentioned in the previous section also has a class conditional generator.</p><p>除了图像，条件输入可以是类别标签（CGAN，图3h）（Mirza和Osindero，2014）、文本描述（Zhang等人，2017a）、对象位置（Reed等人，2016a；2016b）、周围图像上下文（Pathak等人，2016）或草图（Sangkloy等人，2017）。请注意，上一节中提到的ACGAN还有一个类条件生成器。</p><h4 id="2-3-3-Varying-architecture"><a href="#2-3-3-Varying-architecture" class="headerlink" title="2.3.3 Varying architecture"></a>2.3.3 Varying architecture</h4><p>Fully connected layers were used as the building block in vanilla GAN but later on, were replaced by fully convolutional downsampling/upsampling layers in DCGAN ( Radford et al., 2015 ).<br>DCGAN demonstrated better training stability hence quickly populated the literature. As shown in Fig. 2 , the generator in DCGAN architecture works on random input noise vector by successive upsampling operations eventually generating an image from it. Two of its important ingredients are BatchNorm ( Ioffe and Szegedy, 2015 ) for regulating the extracted feature scale, and LeakyRelu ( Maas et al., 2013 ) for preventing dead gradients. Very recently, Miyato et al. (2018) proposed a spectral normalization layer that normalized weights in the discriminator to regulate the scale of feature response values. With the training stability improved, some works have also incorporated residual connections into both the generator and discriminator and experimented with much deeper networks ( Gulrajani et al., 2017; Miyato et al., 2018 ).<br>The work in Miyato and Koyama (2018) proposed a projection based way to incorporate the conditional information instead of direct concatenation and found it to be beneficial in improving the generated image’s quality.</p><p>全连接层被用作vanilla GAN中的构建块，但后来被DCGAN中的<a href="####%E5%AE%8C%E5%85%A8%E5%8D%B7%E7%A7%AF%E9%87%87%E6%A0%B7">完全卷积下采样/上采样层</a>所取代（Radford et al.，2015）。<br>DCGAN表现出更好的训练稳定性，因此很快就在文献中出现。如图2所示，DCGAN结构中的生成器通过连续的上采样操作在随机输入噪声向量上工作，最终从中生成图像。它的两个重要成分是BatchNorm（Ioffe和Szegedy，2015），用于调节提取的特征尺度，以及LeakyRelu（Maas等人，2013），用于防止死梯度。最近，Miyato等人（2018）提出了一种频谱归一化层，该层对判别器中的权重进行归一化，以调节特征响应值的尺度。随着训练稳定性的提高，一些工作还将剩余连接纳入了生成器和判别器中，并对更深层次的网络进行了试验（Gullajani等人，2017年；Miyato等人，2018年）。<br>Miyato和Koyama（2018）的工作提出了一种基于投影的方法来合并条件信息，而不是直接连接，并发现它有助于提高生成图像的质量。</p><p>Directly generating high resolution images from a noise vector is hard, therefore some works have proposed tackling it in a progressive manner. In LAPGAN ( Fig. 3 i), Denton et al. (2015) proposed a stack of GANs, each of which adds higher frequency details into the generated image. In SGAN, a cascade of GANs is also used but each GAN generates increasingly lower level representations ( Huang et al., 2017 ), which are compared with the hierarchical representations extracted from a discriminatively trained model. Karras et al. (2017) adopted an alternate way where they progressively grow the generator and discriminator by adding new layers to them rather than stacking another GAN on top of the preceding one (PGGAN). This progressive idea was also explored in conditional setting ( Wang et al., 2018 ). More recently, Karras et al. (2019) proposed a style-based generator architecture (styleGAN) where instead of directly feeding the latent code z to the input of the generator, they transformed this code first to an intermediate latent space and then use it to scale and shift the normalized image feature responses computed from each convolution layer. Similarly, Park et al. (2019) proposed SPADE where the segmentation mask was injected to the generator via a spatially adaptive normalization layer. This conditional setup was found to better preserve the semantic layout of the mask than directly feeding the mask to the generator.</p><p>从噪声矢量直接生成高分辨率图像是困难的，因此一些工作建议以渐进的方式处理它。在LAPGAN（图3 i）中，Denton等人（2015）提出了一组GANs，每个GANs都向生成的图像中添加了更高频率的细节。在SGAN中，也使用了级联的GAN，但每个GAN生成越来越低级别的表示（Huang等人，2017），这与从差别训练模型中提取的层次表示进行了比较。Karras等人（2017年）采用了另一种方法，即通过向生成器和判别器添加新层，而不是在前一层（PGGAN）的顶部堆叠另一层GAN，逐步增加生成器和判别器。这种进步的想法也在条件设置中得到了探索（Wang等人，2018年）。最近，Karras et al.（2019）提出了一种基于样式的生成器体系结构（styleGAN），其中不直接将潜在代码z提供给生成器的输入，他们首先将该代码转换为一个中间潜在空间，然后使用它来缩放和移动从每个卷积层计算的归一化图像特征响应。类似地，Park等人（2019）提出了SPADE，其中<a href="####%E5%88%86%E5%89%B2%E6%8E%A9%E6%A8%A1">分割掩模</a>通过空间自适应归一化层注入生成器。发现这种条件设置比直接将掩码提供给生成器更好地保留掩码的语义布局。</p><p>Schematic illustrations of the most representative GANs are shown in Fig. 3 . They are GAN, CatGAN, EBGAN/BEGAN, ALI/BiGAN, InfoGAN, ACGAN, VAEGAN, CGAN, LAPGAN, SGAN. Three popular image-to-image translation cGANs (pix2pix, CycleGAN, and UNIT) are shown in Fig. 4 . For a more in-depth review and empirical evaluation of these different variants of GAN, we refer the reader to Huang et al. (2018) , Creswell et al. (2018) and Kurach et al. (2018) .</p><p>图3显示了最具代表性的GAN的示意图。他们是GAN、CatGAN、EBGAN/Begin、ALI/BiGAN、InfoGAN、ACGAN、VAEGAN、CGAN、LAPGAN、SGAN。图4中显示了三种流行的图像到图像转换cgan（pix2pix、CycleGAN和UNIT）。为了更深入地回顾和实证评估这些不同的GAN变体，我们请读者参考Huang et al.（2018）、Creswell et al.（2018）和Kurach et al.（2018）。</p><p><img src="https://i.loli.net/2021/10/10/wj32VFk1fdTqelL.png" alt="image-20211010111605807"></p><p>Fig. 3. A schematic view of variants of GAN. c represents the conditional vector. In CGAN and ACGAN, c is the discrete categorical code (e.g. one hot vector) that encodes class labels and in InfoGAN it can also be continuous code that encodes attributes. $x_g$ generally refers to the generated image but can also be internal representations as in<br>SGAN.</p><p>图3. GAN变体的示意图。c表示条件向量。在CGAN和ACGAN中，c是编码类标签的离散分类代码（例如，一个独热向量），在InfoGAN中，c也可以是编码属性的连续代码。$x_g$通常指生成的图像，但也可以是SGAN中的内部表示。</p><p><img src="https://i.loli.net/2021/10/10/9tgPFwyAa71hezJ.png" alt="image-20211010211408002"></p><p>Fig. 4. cGAN frameworks for image-to-image translation. pix2pix requires aligned training data whereas this constraint is relaxed in CycleGAN but usually suffers from performance loss. Note that in (a), we chose reconstruction loss as an example of target consistency. This supervision is task related and can take many other different forms. (c) It consists of two VAEGANs with shared latent vector in the VAE part.</p><p>图4. 用于图像到图像翻译的CGA框架。pix2pix需要对齐的训练数据，而这种约束在CycleGAN中是放松的，但通常会受到性能损失的影响。注意，在(a)中，我们选择重建损失作为目标一致性的示例。这种监督与任务相关，可以采取许多其他不同形式。(c)它由两个在VAE部分具有共享潜在向量的Vaegan组成。</p><h2 id="3-Applications-in-medical-imaging"><a href="#3-Applications-in-medical-imaging" class="headerlink" title="3. Applications in medical imaging"></a>3. Applications in medical imaging</h2><p>There are generally two ways GANs are used in medical imaging. The first is focused on the generative aspect, which can help in exploring and discovering the underlying structure of training data and learning to generate new images. This property makes GANs very promising in coping with data scarcity and patient privacy. The second focuses on the discriminative aspect, where the discriminator D can be regarded as a learned prior for normal images so that it can be used as regularizer or detector when presented with abnormal images. Fig. 5 provides examples of GAN related applications, with examples (a), (b), (c), (d), (e), (f) that focus on the generative aspect and example (g) that exploits the discriminative aspect. In the following subsections, in order to help the readers find applications of their interest, we categorized all the reviewed articles into canonical tasks: reconstruction, image synthesis, segmentation, classification, detection, registration, and others.</p><p>在医学成像中，GANs通常有两种使用方式。第一个重点是生成方面，这有助于探索和发现训练数据的底层结构，并学习生成新图像。这一特性使得GANs在应对数据稀缺和患者隐私方面非常有希望。第二个关注于鉴别方面，其中判别器D可以被视为正常图像的学习先验，以便当呈现异常图像时，它可以被用作正则化器或检测器。图5提供了GAN相关应用的示例，其中示例a、b、c、d、e、f侧重于生成方面，示例g利用区别方面。在下面的小节中，为了帮助读者找到他们感兴趣的应用程序，我们将所有已审阅的文章分类为规范任务：重建、图像合成、分割、分类、检测、配准等。</p><p><img src="https://i.loli.net/2021/10/10/Y4DblKTVL7n2Avs.png" alt="image-20211010211614963"></p><p>Fig. 5. Example applications using GANs. Figures are directly cropped from the corresponding papers. (a) Left side shows the noise contaminated low dose CT and right side<br>shows the denoised CT that well preserved the low contrast regions in the liver ( Yi and Babyn, 2018 ). (b) Left side shows the MR image and right side shows the synthesized<br>corresponding CT. Bone structures were well delineated in the generated CT image ( Wolterink et al., 2017a ). (c) The generated retinal fundus image have the exact vessel<br>structures as depicted in the left vessel map ( Costa et al., 2017b ). (d) Randomly generated skin lesion from random noise (a mixture of malignant and benign) ( Yi et al.,<br>2018 ). (e) An organ (lung and heart) segmentation example on adult chest X-ray. The shapes of lung and heart are regulated by the adversarial loss ( Dai et al., 2017b ). (f) The<br>third column shows the domain adapted brain lesion segmentation result on SWI sequence without training with the corresponding manual annotation ( Kamnitsas et al.,<br>2017 ). (g) Abnormality detection of optical coherence tomography images of the retina ( Schlegl et al., 2017 ).</p><p>图5。使用GANs的示例应用程序。数字是从相应的文件中直接裁剪出来的。(a)左侧显示噪声污染的低剂量CT，右侧显示去除噪声的CT，它很好地保留了肝脏中的低对比度区域（Yi和Babyn，2018）。(b)左侧显示MR图像，右侧显示相应的合成CT。在Wolterink等人的图像中描绘了骨骼结构。(c)生成的视网膜眼底图像具有左血管图所示的精确血管结构（Costa等人，2017b）。(d)随机噪声随机产生的皮肤损伤（恶性和良性混合）（Yi等人，2018年）。(e)成人胸部X光片上的器官（肺和心脏）分割示例。肺和心脏的形状受对抗性损失的影响（Dai等人，2017b）。(f)第三列显示了SWI序列上的域自适应脑损伤分割结果，无需使用相应的手动注释进行训练（Kamnitsas et al.，2017）。(g)视网膜光学相干断层扫描图像的异常检测（Schlegl等人，2017年）。</p><h3 id="3-1-Reconstruction"><a href="#3-1-Reconstruction" class="headerlink" title="3.1 Reconstruction"></a>3.1 Reconstruction</h3><p>Due to constraints in clinical settings, such as radiation dose and patient comfort, the diagnostic quality of acquired medical images may be limited by noise and artifacts. In the last decade, we have seen a paradigm shift in reconstruction methods changing from analytic to iterative and now to machine learning based methods. These data-driven learning based methods either learn to transfer raw sensory inputs directly to output images or serve as a post processing step for reducing image noise and removing artifacts. Most of the methods reviewed in this section are borrowed directly from the computer vision literature that formulate post-processing as an image-to-image translation problem where the conditioned inputs of cGANs are compromised in certain forms, such as low spatial resolution, noise contamination, under-sampling, or aliasing. One exception is for MR images where the Fourier transform is used to incorporate the raw K-space data into the reconstruction.</p><p>由于临床环境的限制，如辐射剂量和患者舒适度，采集的医学图像的诊断质量可能受到噪声和伪影的限制。在过去十年中，我们看到重建方法的范式转变，从分析方法转变为迭代方法，现在转变为基于机器学习的方法。这些基于数据驱动的学习方法要么学习将原始感官输入直接传输到输出图像，要么作为减少图像噪声和消除伪影的后处理步骤。本节中回顾的大多数方法都是直接从计算机视觉文献中借来的，这些文献将后处理描述为图像到图像的转换问题，其中CGAN的条件输入以某些形式受到损害，例如低空间分辨率、噪声污染、欠采样或混叠。一个例外是MR图像，其中傅里叶变换用于将原始K空间数据合并到重建中。</p><p>The basic pix2pix framework has been used for low dose CT denoising ( Wolterink et al., 2017b ), MR reconstruction ( Chen et al., 2018b; Kim et al., 2018; Dar et al., 2018b; Shitrit and Raviv, 2017 ), and PET denoising ( Wang et al., 2018b ). A pretrained VGGnet ( Simonyan and Zisserman, 2014 ) was further incorporated into the optimization framework to ensure perceptual similarity ( Yang et al., 2018; Yu et al., 2017; Yang et al., 2018a; Armanious et al., 2018c; Mahapatra, 2017 ). Yi and Babyn (2018) introduced a pretrained sharpness detection network to explicitly constrain the sharpness of the denoised CT especially for low contrast regions. Mahapatra (2017) computed a local saliency map to highlight blood vessels in superresolution process of retinal fundus imaging. A similar idea was explored by Liao et al. (2018) in sparse view CT reconstruction. They compute a focus map to modulate the reconstructed output to ensure that the network focused on important regions. Besides ensuring image domain data fidelity, frequency domain data fidelity is also imposed when raw K-space data is available in MR reconstruction ( Quan et al., 2018; Mardani et al., 2017; Yang et al., 2018a ).</p><p>基本pix2pix框架已用于低剂量CT去噪（Wolterink等人，2017b）、MR重建（Chen等人，2018b；Kim等人，2018；Dar等人，2018b；Shitrit和Raviv，2017）和PET去噪（Wang等人，2018b）。预训练VGGnet（Simonyan和Zisserman，2014）进一步纳入优化框架，以确保感知相似性（Yang等人，2018；Yu等人，2017；Yang等人，2018a；Armanious等人，2018c；Mahapatra，2017）。Yi和Babyn（2018）引入了预训练锐度检测网络，以明确限制去噪CT的锐度，尤其是低对比度区域。Mahapatra（2017）计算了局部显著性图，以突出视网膜眼底成像超分辨率过程中的血管。Liao等人（2018）在稀疏视图CT重建中探索了类似的想法。他们计算一个聚焦图来调节重建的输出，以确保网络聚焦于重要区域。除了确保图像域数据保真度外，当原始K空间数据可用于MR重建时，还可施加频域数据保真度（Quan等人，2018年；Mardani等人，2017年；Yang等人，2018a）。</p><p>Losses of other kinds have been used to highlight local image structures in the reconstruction, such as the saliency loss to reweight each pixel’s importance based on its perceptual relevance ( Mahapatra, 2017 ) and the style-content loss in PET denoising ( Armanious et al., 2018c ). In image reconstruction of moving organs, paired training samples are hard to obtain. Therefore, Ravì et al. (2018) proposed a physical acquisition based loss to regulate the generated image structure for endomicroscopy super resolution and Kang et al. (2019) proposed to use CycleGAN together with an identity loss in the denoising of cardiac CT. Wolterink et al. (2017b) found that in low dose CT denoising, meaningful results can still be achieved when removing the image domain fidelity loss from the pix2pix framework, but the local image structure can be altered. Papers relating to medical image reconstruction are summarized in Table 1 .</p><p>其他类型的损失已用于强调重建中的局部图像结构，例如基于感知相关性重新加权每个像素重要性的显著性损失（Mahapatra，2017）和PET去噪中的样式内容损失（Armanious et al.，2018c）。在运动器官的图像重建中，配对训练样本难以获得。因此，Ravì等人（2018年）提出了一种基于物理采集的损失，以调节内窥镜超分辨率生成的图像结构，Kang等人（2019年）提出在心脏CT去噪中使用CycleGAN和身份损失。 Wolterink等人（2017b）发现，在低剂量CT去噪中，当从pix2pix框架中去除图像域保真度损失时，仍然可以获得有意义的结果，但局部图像结构可以改变。表1总结了与医学图像重建相关的论文。</p><p>It can be noticed that the underlying methods are almost the same for all the reconstruction tasks. MR is special case as it has a well defined forward and backward operation, i.e. Fourier transform, so that raw K-space data can be incorporated. The same methodology can potentially be applied to incorporate the sinogram data in the CT reconstruction process but we have not seen any research using this idea as yet probably because the sinogram data is hard to access. The more data used, either raw K-space or image from other sequence, the better are the reconstructed results. In general, using adversarial loss produces more visually appealing results than using pixel-wise reconstruction loss alone. But using adversarial loss to match the generated and real data distribution may make the model hallucinate unseen structures. Pixel-wise reconstruction loss helps to combat this problem if paired samples are available, and if the model was trained on all healthy images but employed to reconstruct images with pathologies, the hallucination problem will still exist due to domain mismatch. Cohen et al. (2018) have conducted extensive experiments to investigate this problem and suggest that reconstructed images should not be used for direct diagnosis by radiologists unless the model has been properly verified.</p><p>可以注意到，所有重建任务的基本方法几乎相同。MR是一种特殊情况，因为它具有定义良好的正向和反向操作，即傅里叶变换，因此可以合并原始K空间数据。同样的方法可以潜在地应用于将正弦图数据纳入CT重建过程中，但我们尚未看到任何使用此想法的研究，可能是因为正弦图数据难以访问。使用的数据越多，无论是原始K空间还是来自其他序列的图像，重建结果越好。一般来说，使用对抗性损失比单独使用像素级重建损失产生更具视觉吸引力的结果。但是，使用对抗性损失来匹配生成的和真实的数据分布可能会使模型产生看不见的结构的幻觉。如果成对样本可用，像素级重建损失有助于解决此问题，并且如果模型在所有健康图像上训练，但用于重建具有病理学的图像，则由于域不匹配，幻觉问题仍然存在。Cohen等人（2018年）进行了大量实验来研究这一问题，并建议重建图像不应用于放射科医生的直接诊断，除非模型已得到适当验证。</p><p><img src="https://i.loli.net/2021/10/10/dhsHbTnY9r75DZC.png" alt="image-20211010213340155"></p><p>However, even though the dataset is carefully curated to match the training and testing distribution, there are other problems in further boosting performance. We have seen various different losses introduced to the pix2pix framework as shown in Table 2 to improve the reconstructed fidelity of local structures. There is, however, no reliable way of comparing their effectiveness except for relying on human observer or downstream image analysis tasks. Large scale statistical analysis by human observer is currently lacking for GAN based reconstruction methods. Furthermore, public datasets used for image reconstruction are not tailored towards further medical image analysis, which leaves a gap between upstream reconstruction and downstream analysis tasks. New reference standard datasets should be created for better comparison of these GAN-based methods.</p><p>然而，尽管数据集经过精心策划以匹配训练和测试分布，但在进一步提高性能方面还存在其他问题。我们已经看到pix2pix框架引入了各种不同的损失，如表2所示，以提高局部结构的重建保真度。然而，除了依靠人类观察者或下游图像分析任务外，没有可靠的方法来比较它们的有效性。目前，基于GAN的重建方法缺乏由人类观察者进行的大规模统计分析。此外，用于图像重建的公共数据集不适合进一步的医学图像分析，这在上游重建和下游分析任务之间留下了差距。应创建新的参考标准数据集，以便更好地比较这些基于GAN的方法。</p><p><img src="https://i.loli.net/2021/10/10/ynAJLSaCK2sD5rm.png" alt="image-20211010214402753"></p><h3 id="3-2-Medical-image-synthesis"><a href="#3-2-Medical-image-synthesis" class="headerlink" title="3.2 Medical image synthesis"></a>3.2 Medical image synthesis</h3><p>Depending on institutional protocols, patient consent may be required if diagnostic images are intended to be used in a publication or released into the public domain ( Clinical Practice Committee, 20 0 0 ). GANs are widely for medical image synthesis. This helps overcome the privacy issues related to diagnostic medical image data and tackle the insufficient number of positive cases of each pathology. Lack of experts annotating medical images poses another challenge for the adoption of supervised training methods.<br>Although there are ongoing collaborative efforts across multiple healthcare agencies aiming to build large open access datasets, e.g. Biobank, the National Biomedical Imaging Archive (NBIA), The Cancer Imaging Archive (TCIA) and Radiologist Society of North America (RSNA), this issue remains and constrains the number of images researchers might have access to ( Table 3 ).</p><p>根据机构协议，如果诊断图像拟用于出版物或发布到公共领域，则可能需要患者同意（临床实践委员会，20 0）。GANs广泛应用于医学图像合成。这有助于克服与诊断医学图像数据相关的隐私问题，并解决每个病理学的阳性病例数量不足的问题。缺乏对医学图像进行注释的专家对采用监督训练方法提出了另一个挑战。<br>尽管多个医疗机构正在进行合作，以建立大型开放存取数据集，例如Biobank、国家生物医学成像档案馆（NBIA）、癌症成像档案馆（TCIA）和北美放射科医师协会（RSNA），这个问题仍然存在，并限制了研究人员可能获得的图像数量（表3）。</p><p><img src="https://i.loli.net/2021/10/10/NTjGCkZ9hd2zYDI.png" alt="image-20211010214639273"></p><p><img src="https://i.loli.net/2021/10/10/6pTcJFyd58ln7sQ.png" alt="image-20211010214657869"></p><p><img src="https://i.loli.net/2021/10/10/FWp5HNtljGx8Cae.png" alt="image-20211010214715932"></p><p>Traditional ways to augment training sample include scaling, rotation, flipping, translation, and elastic deformation ( Simard et al., 2003 ). However, these transformations do not account for variations resulting from different imaging protocols or sequences, not to mention variations in the size, shape, location and appearance of specific pathology. GANs provide a more generic solution and have been used in numerous works for augmenting training images with promising results.</p><p>增强训练样本的传统方法包括缩放、旋转、翻转、平移和弹性变形（Simard et al.，2003）。然而，这些转换并没有考虑到不同成像协议或序列导致的变化，更不用说特定病理学的大小、形状、位置和外观的变化了。GANs提供了一种更通用的解决方案，并已在许多工程中用于增强训练图像，取得了良好的效果。</p><h4 id="3-2-1-Unconditional-synthesis"><a href="#3-2-1-Unconditional-synthesis" class="headerlink" title="3.2.1 Unconditional synthesis"></a>3.2.1 Unconditional synthesis</h4><p>Unconditional synthesis refers to image generation from random noise without any other conditional information. Techniques commonly adopted in the medical imaging community include DCGAN, WGAN, and PGGAN due to their good training stability.<br>The first two methods can handle an image resolution of up to 256 ×256 but if higher resolution images are desired, the progressive technique proposed in PGGAN is a choice. Realistic images can be generated by directly using the author released code base as long as the variations between images are not too large, for example, lung nodules and liver lesions. To make the generated images useful for downstream tasks, most studies trained a separate generator for each individual class; for example, Frid-Adar et al. (2018) used three DCGANs to generate synthetic samples for three classes of liver lesions (cysts, metastases, and hemangiomas); generated samples were found to be beneficial to the lesion classification task with both improved sensitivity and specificity when combined with real training data.<br>Bermudez et al. (2018) claimed that neuroradiologists found generated MR images to be of comparable quality to real ones, however, there were discrepancies in anatomic accuracy. Papers related to unconditional medical image synthesis are summarized in Table 4 .</p><p>无条件合成是指在没有任何其他条件信息的情况下，从随机噪声中生成图像。医学成像界通常采用的技术包括DCGAN、WGAN和PGGAN，因为它们具有良好的训练稳定性。<br>前两种方法可以处理高达256×256的图像分辨率，但如果需要更高分辨率的图像，则可以选择PGGAN中提出的渐进式技术。只要图像之间的差异不太大，例如肺结节和肝脏病变，就可以直接使用作者发布的代码库生成逼真的图像。为了使生成的图像对下游任务有用，大多数研究为每个单独的类训练了一个单独的生成器；例如，Frid Adar等人（2018年）使用三种DCG生成三类肝脏病变（囊肿、转移瘤和血管瘤）的合成样本；生成的样本被发现有利于病变分类任务，与真实训练数据相结合时，灵敏度和特异性都有所提高。<br>Bermudez等人（2018年）声称，神经放射科医生发现生成的MR图像质量与真实图像相当，但在解剖准确性方面存在差异。表4总结了与无条件医学图像合成相关的论文。</p><p><img src="https://i.loli.net/2021/10/10/vp9rPDXHjbqh67E.png" alt="image-20211010214846137"></p><h4 id="3-2-2-Cross-modality-synthesis"><a href="#3-2-2-Cross-modality-synthesis" class="headerlink" title="3.2.2 Cross modality synthesis"></a>3.2.2 Cross modality synthesis</h4><p>Cross modality synthesis (such as generating CT-like images based on MR images) is deemed to be useful for multiple reasons, one of which is to reduce the extra acquisition time and cost.<br>Another reason is to generate new training samples with the appearance being constrained by the anatomical structures delineated in the available modality. Most of the methods reviewed in this section share many similarities to those in Section 3.1 .<br>pix2pix-based frameworks are used in cases where different image modality data can be co-registered to ensure data fidelity.</p><p>跨模态合成（例如基于MR图像生成CT样图像）被认为是有用的，原因有多种，其中之一是减少额外的采集时间和成本。<br>另一个原因是生成新的训练样本，其外观受可用模式中描绘的解剖结构的约束。本节中回顾的大多数方法与第3.1节中的方法有许多相似之处。<br>基于pix2pix的框架用于不同图像模态数据可以共同配准以确保数据保真度的情况。</p><p>CycleGAN-based frameworks are used to handle more general cases where registration is challenging such as in cardiac applications. In a study by Wolterink et al. (2017a) for brain CT image synthesis from MR image, the authors found that training using unpaired images was even better than using aligned images. This most likely resulted from the fact that rigid registration could not very well handle local alignment in the throat, mouth, vertebrae, and nasal cavities. Hiasa et al. (2018) further incorporated gradient consistency loss in the training to improve accuracy at the boundaries. Zhang et al. (2018d) found that using only cycle loss in the cross modality synthesis was insufficient to mitigate geometric distortions in the transformation. Therefore, they employed a shape consistency loss that is obtained from two segmentors (segmentation network). Each segmentor segments the corresponding image modality into semantic labels and provides implicit shape constraints on the anatomy during translation. To make the whole system end-to-end trainable, semantic labels of training images from both modalities are required. Zhang et al. (2018c) and Chen et al. (2018a) proposed using a segmentor also in the cycle transfer using labels in only one modality. Therefore, the segmentor is trained offline and fixed during the training of the image transfer network. As reviewed in Section 2 , UNIT and CycleGAN are two equally valid frameworks for unpaired cross modality synthesis. It was found that these two frameworks performed almost equally well for the transformation between T1 and T2-weighted MR images ( Welander et al., 2018 ). Papers related to cross modality medical image synthesis are summarized in Table 5 .</p><p>基于CycleGAN的框架用于处理配准具有挑战性的更一般情况，例如在心脏应用中。在Wolterink et al.（2017a）关于从MR图像合成大脑CT图像的研究中，作者发现使用未配对图像进行训练甚至比使用对齐图像更好。这很可能是因为刚性配准不能很好地处理咽喉、口腔、脊椎和鼻腔的局部对齐。Hiasa等人（2018年）进一步将梯度一致性损失纳入训练中，以提高边界的准确性。Zhang等人（2018d）发现，在交叉模态合成中仅使用循环损失不足以缓解变换中的几何失真。因此，他们采用了从两个分割器（分割网络）获得的形状一致性损失。每个切割器将相应的图像模态分割成语义标签，并在翻译过程中对解剖结构提供隐式形状约束。为了使整个系统端到端可训练，需要来自两种模式的训练图像的语义标签。Zhang et al.（2018c）和Chen et al.（2018a）建议在循环传输中也使用切割器，仅在一种模式中使用标签。因此，在图像传输网络的训练期间，切割器离线训练并固定。如第2节所述，UNIT和CycleGAN是两个同样有效的非配对跨模态综合框架。研究发现，这两种框架在T1和T2加权MR图像之间的转换中表现几乎相同（Welander et al.，2018）。表5总结了与跨模态医学图像合成相关的论文。</p><p><img src="https://i.loli.net/2021/10/10/Y2NRZuC87qgPwet.png" alt="image-20211010215030343"></p><p><img src="https://i.loli.net/2021/10/10/eZnBviVLNt1WXRO.png" alt="image-20211010215105058"></p><h4 id="3-2-3-Other-conditional-synthesis"><a href="#3-2-3-Other-conditional-synthesis" class="headerlink" title="3.2.3 Other conditional synthesis"></a>3.2.3 Other conditional synthesis</h4><p>Medical images can be generated by constraints on segmen- tation maps, text, locations or synthetic images etc. This is useful to synthesize images in uncommon conditions, such as lung nodules touching the lung border ( Jin et al., 2018 ). Moreover, the conditioned segmentation maps can also be generated from GANs ( Guibas et al., 2017 ) or from a pretrained segmentation net- work ( Costa et al., 2017a ), by making the generation a two stage process. Mok and Chung (2018) used cGAN to augment training images for brain tumour segmentation. The generator was condi- tioned on a segmentation map and generated brain MR images in a coarse to fine manner. To ensure the tumour was well delineated with a clear boundary in the generated image, they further forced the generator to output the tumour boundaries in the generation process. The full list of synthesis works is summarized in Table 6 .</p><p>医学图像可以通过对分割图、文本、位置或合成图像等的约束生成。这对于在罕见情况下合成图像非常有用，例如肺结节触及肺边界（Jin等人，2018）。此外，通过将生成过程分为两个阶段，也可以从GANs（Guibas等人，2017）或预训练分割网络（Costa等人，2017a）生成条件分割图。Mok和Chung（2018）使用cGAN增强用于脑肿瘤分割的训练图像。该发生器在分割图上进行调节，并以从粗到精的方式生成大脑MR图像。为了确保生成的图像中肿瘤边界清晰，他们进一步强制生成器在生成过程中输出肿瘤边界。表6总结了综合工作的完整清单。</p><p><img src="https://i.loli.net/2021/10/10/vTxdQpm7NagLrE1.png" alt="image-20211010220240451"></p><h3 id="3-3-Segmentation"><a href="#3-3-Segmentation" class="headerlink" title="3.3 Segmentation"></a>3.3 Segmentation</h3><p>Generally, researchers have used <strong>pixel-wise or voxel-wise</strong> loss such as cross entropy for segmentation. Despite the fact that U-net ( Ronneberger et al., 2015 ) was used to combine both low-level and high-level features, there is no guarantee of spatial consistency in the final segmentation map. Traditionally, conditional random field (CRF) and graph cut methods are usually adopted for segmentation refinement by incorporating spatial correlation. Their limitation is that they only take into account <strong>pair-wise potentials</strong> which might cause serious boundary leakage in low contrast regions. On the other hand, adversarial losses as introduced by the discriminator can take into account high order potentials ( Yang et al., 2017a ). In this case, the discriminator can be regarded as a shape regulator. This regularization effect is more prominent when the object of interest has a compact shape, e.g. for lung and <em>heart mask(???)</em> but less useful for deformable objects such as vessels and catheters. This regulation effect can be also applied to the internal features of the segmentor to achieve domain (different scanners, imaging protocols, modality) invariance ( Kamnitsas et al., 2017; Dou et al., 2018 ). The adversarial loss can also be viewed as a adaptively learned similarity measure between the segmented outputs and the annotated groundtruth. Therefore, instead of measuring the similarity in the pixel domain, the discriminative network projects the input to a low dimension manifold and measures the similarity there. The idea is similar to the <strong>perceptual loss</strong>. The difference is that the perceptual loss is computed from a pre-trained classification network on natural images whereas the adversarial loss is computed from a network that trained adaptively during the evolvement of the generator.</p><p>通常，研究人员使用<a href="####%E5%83%8F%E7%B4%A0%E7%BA%A7%E6%88%96%E4%BD%93%E7%B4%A0%E9%9B%86">像素级或体素级</a>的损失，如交叉熵进行分割。尽管U-net（Ronneberger et al.，2015）被用于结合低层和高层特征，但无法保证最终分割图的空间一致性。传统上，通常采用条件随机场（CRF）和图切割方法，通过结合空间相关性进行分割细化。它们的局限性在于，它们只考虑了在低对比度区域可能导致严重边界泄漏的<a href="####%E4%BA%8C%E5%85%83%E5%8A%BF%E5%87%BD%E6%95%B0">二元势函数<code>pair-wise potentials</code></a>。另一方面，判别器引入的对抗性损失可以考虑<a href="####%E9%AB%98%E9%98%B6%E5%8A%BF%E5%87%BD%E6%95%B0">高阶势函数<code>high order potentials</code></a>（Yang等人，2017a）。在这种情况下，判别器可被视为形状调节器。当感兴趣的对象具有紧凑的形状时，这种正则化效果更为显著，例如用于肺和*心脏面罩(???)*，但对于可变形对象（如血管和导管）不太有用。该调节效应也可应用于分割器的内部特征，以实现域（不同扫描仪、成像协议、模态）不变性（Kamnitsas等人，2017年；Dou等人，2018年）。对抗性损失也可以被视为分割输出和正确标注数据之间的自适应学习相似性度量。因此，区别网络不是在像素域中测量相似性，而是将输入投影到低维流形并在那里测量相似性。这种想法类似于<a href="####%E6%84%9F%E7%9F%A5%E6%8D%9F%E5%A4%B1">感知损失</a>。不同之处在于，感知损失是通过对自然图像进行预训练的分类网络计算的，而对抗损失是通过在生成器演化过程中进行自适应训练的网络计算的。</p><p>Xue et al. (2018) used a multi-scale $L_1$ loss in the discriminator where features coming from different depths are compared. This was demonstrated to be effective in enforcing the multiscale spatial constraints on segmentation maps and the system achieved state-of-the-art performance in the BRATS 13 and 15 challenges. Zhang et al. (2017c) proposed to use both annotated and unan- notated images in the segmentation pipeline. The annotated images are used in the same way as in Xue et al. (2018) and Son et al. (2017) where both element-wise loss and adversarial loss are applied. The unannotated images on the other hand are only used to compute a segmentation map to confuse the discriminator. Li and Shen (2018) combined pix2pix with ACGAN for segmentation of fluorescent microscopy images of different cell types. They found that the introduction of the auxiliary classifier branch provides regulation to both the discriminator and the segmentor.</p><p>Xue et al.（2018）在判别器中使用多尺度$L_1$损失，比较来自不同深度的特征。这被证明是有效的，在分割地图上实施多尺度空间约束，系统在BRAT 13和15挑战中实现了最先进的性能。Zhang等人（2017c）建议在分割管道中同时使用注释图像和非注释图像。注释图像的使用方式与Xue et al.（2018）和Son et al.（2017）中相同，其中元素损失和对抗损失均适用。另一方面，未标注的图像仅用于计算分割图以混淆判别器。Li和Shen（2018）将pix2pix与ACGAN相结合，对不同细胞类型的荧光显微镜图像进行分割。他们发现，辅助分类器分支的引入为判别器和分割器提供了调节。</p><p>Unlike these aforementioned segmentation works where adversarial training is used to ensure higher order structure consistency on the final segmentation maps, the adversarial training scheme in Zhu et al. (2018) enforces network invariance to small perturbations of the training samples in order to reduce overfitting on small dataset. Papers related to medical image segmentation are summarized in Table 8 .</p><p>与上述使用对抗性训练确保最终分割图上的高阶结构一致性的分割工作不同，Zhu等人（2018）的对抗性训练方案对训练样本的小扰动实施网络不变性，以减少小数据集上的过度拟合。表8总结了与医学图像分割相关的论文。</p><p><img src="https://i.loli.net/2021/10/11/wUQx8pWIi1dlaGM.png" alt="image-20211011184615605"></p><h3 id="3-4-Classification"><a href="#3-4-Classification" class="headerlink" title="3.4 Classification"></a>3.4 Classification</h3><p>Classification is arguably one of the most successful tasks where deep learning has been applied. Hierarchical image features can be extracted from a deep neural network discriminatively trained with image-wise class labels. GANs have been used for classification problems as well, either using part of the generator and discriminator as a feature extractor or directly using the discriminator as a classifier (by adding an extra class corresponding to the generated images). Hu et al. (2018) used combined WGAN and InfoGAN for unsupervised cell-level feature representation learning in histopathology images whereas Yi et al. (2018) combined WGAN and CatGAN for unsupervised and semi-supervised feature representation learning for dermoscopy images. Both works extract features from the discriminator and build a classifier on top. Madani et al. (2018b) , Lahiri et al. (2017) and Lecouat et al. (2018) adopted the semi- supervised training scheme of GAN for chest abnormality classification, patch-based retinal vessel classification and cardiac disease diagnosis respectively. They found that the semi-supervised GAN can achieve performance comparable with a traditional supervised CNN with an order of magnitude less labeled data. Furthermore, Madani et al. (2018b) have also shown that the adversarial loss can reduce domain overfitting by simply supplying unlabeled test domain images to the discriminator in identifying cardiac abnormalities in chest X-ray. A similar work in addressing domain variance in whole slide images (WSI) has been conducted by Ren et al. (2018) .</p><p>分类可以说是应用深度学习的最成功的任务之一。分层图像特征可以从深度神经网络中提取，深度神经网络通过图像分类标签进行区分训练。GANs也用于分类问题，或者使用生成器和判别器的一部分作为特征提取器，或者直接使用判别器作为分类器（通过添加与生成的图像相对应的额外类）。Hu et al.（2018）将WGAN和InfoGAN组合用于组织病理学图像的无监督细胞级特征表示学习，而Yi et al.（2018）将WGAN和CatGAN组合用于皮肤镜图像的无监督和半监督特征表示学习。这两项工作都从判别器中提取特征，并在顶部构建分类器。Madani et al.（2018b）、Lahiri et al.（2017）和Lecouat et al.（2018）分别采用GAN的半监督训练方案进行胸部异常分类、基于斑片的视网膜血管分类和心脏病诊断。他们发现，半监督GAN可以实现与传统监督CNN相当的性能，标记数据数量级更少。此外，Madani等人（2018b）还表明，对抗性丢失可以通过简单地向判别器提供未标记的测试域图像来减少域过度拟合，从而识别胸部X射线中的心脏异常。Ren等人（2018年）在解决整张幻灯片图像中的域差异（WSI）方面进行了类似的工作。</p><p>Most of the other works that used GANs to generate new training samples have been already mentioned in Section 3.2.1 . These studies applied a two stage process, with the first stage learned to augment the images and the second stage learned to perform classification by adopting the traditional classification network. The two stages are trained disjointedly without any communication in between. The advantage is that these two components can be replaced easily if more advanced unconditional synthesis architectures are proposed whereas the downside is that the generation has to be conducted for each class separately (N models for N classes), which is not memory and computation efficient. A single model that is capable of performing conditional synthesis of mul- tiple categories is an active research direction ( Brock et al., 2018 ). Surprisingly, Frid-Adar et al. (2018) found that using separate GAN (DCGAN) for each lesion class resulted in better performance in lesion classification than using a unified GAN (ACGAN) for all classes. The underlying reason remains to be explored. Furthermore, Finlayson et al. (2018) argue that images generated from GANs may serve as an effective augmentation in the medium-data regime, but may not be helpful in a high or low-data regime.</p><p>第3.2.1节已经提到了使用GANs生成新训练样本的大多数其他工作。这些研究采用了两个阶段的过程，第一阶段学习增强图像，第二阶段学习采用传统分类网络进行分类。这两个阶段是分开训练的，中间没有任何交流。优点是，如果提出更高级的无条件合成体系结构，这两个组件可以很容易地被替换，而缺点是必须对每个类分别进行生成（N个类的N个模型），这不利于内存和计算效率。能够对多个类别进行条件合成的单一模型是一个积极的研究方向（Brock等人，2018年）。令人惊讶的是，Frid Adar等人（2018年）发现，对每个病变类别使用单独的GAN（DCGAN）比对所有类别使用统一的GAN（ACGAN）在病变分类方面表现更好。根本原因仍有待探讨。此外，Finlayson等人（2018年）认为，从GANs生成的图像可以作为中等数据区域的有效增强，但在高或低数据区域可能没有帮助。</p><h3 id="3-5-Detection"><a href="#3-5-Detection" class="headerlink" title="3.5 Detection"></a>3.5 Detection</h3><p>The discriminator of GANs can be utilized to detect abnormalities such as lesions by learning the probability distribution of training images depicting normal pathology. Any image that falls out of this distribution can be deemed as abnormal. Schlegl et al. (2017) used the exact idea to learn a manifold of normal anatomical variability and proposed a novel anomaly scoring scheme based on the fitness of the test image’s latent code to the learned manifold. The learning process was conducted in an unsupervised fashion and effectiveness was demonstrated by state- of-the-art performance of anomaly detection on optical coherence tomography (OCT) images. Alex et al. (2017) used GAN for brain lesion detection on MR images. The generator was used to model the distribution of normal patches and the trained discriminator was used to compute a posterior probability of <strong>patches centered on every pixel</strong> in the test image. Chen and Konukoglu (2018) used an adversarial auto-encoder to learn the data distribution of healthy brain MR images. The lesion image was then mapped to an image without a lesion by exploring the learned latent space, and the lesion could be highlighted by computing the residual of these two images. We can see that all the detection studies targeted for abnormalities that are hard to enumerate.</p><p>通过学习描述正常病理学的训练图像的概率分布，GANs判别器可用于检测异常，如病变。任何不符合此分布的图像都可以被视为异常。Schlegl等人（2017年）利用准确的想法学习了一个正常解剖变异的流形，并基于测试图像的潜在编码与学习的流形的适合度，提出了一种新的异常评分方案。学习过程以无监督的方式进行，光学相干断层扫描（OCT）图像异常检测的最新性能证明了学习过程的有效性。Alex等人（2017年）使用GAN在MR图像上检测脑损伤。该生成器用于模拟正态面片的分布，训练的判别器用于计算以测试图像中每个像素为中心的面片的后验概率。Chen和Konukoglu（2018）使用对抗式自动编码器学习健康大脑MR图像的数据分布。然后，通过探索学习到的潜在空间，将病变图像映射到没有病变的图像，并通过计算这两个图像的残差来突出病变。我们可以看到，所有的检测研究都针对难以列举的异常。</p><p>In the image reconstruction section, it has been observed that if the target distribution is formed from medical images without pathology, lesions within an image could be removed in the CycleGAN-based unpaired image transfer due to the distribution matching effect. However, it can be seen here that if the target and source domain are of the same imaging modality differing only in terms of normal and abnormal tissue, this adverse effect can actually be exploited for abnormality detection ( Sun et al., 2018 ).</p><p>在图像重建部分，已经观察到，如果目标分布是由没有病理学的医学图像形成的，则由于分布匹配效应，可以在基于CycleGAN的非配对图像传输中去除图像内的病变。然而，可以看出，如果目标域和源域具有相同的成像模式，仅在正常和异常组织方面有所不同，则这种不利影响实际上可以用于异常检测（Sun等人，2018）。</p><h3 id="3-6-Registration"><a href="#3-6-Registration" class="headerlink" title="3.6 Registration"></a>3.6 Registration</h3><p>cGAN can also be used for multi-modal or uni-modal image registration. The generator in this case will either generate transformation parameters, e.g. 12 numbers for 3D affine transformation, deformation field for non-rigid transformation or directly generate the transformed image. The discriminator then discriminates aligned image pairs from unaligned image pairs.<br>A spatial transformation network ( Jaderberg et al., 2015 ) or a deformable transformation layer ( Fan et al., 2018 ) is usually plugged in between these two networks to enable end-to-end training. Yan et al. (2018b) performed prostate MR to transrectal ultrasound (TRUS) image registration using this framework. The paired training data was obtained through manual registration by experts. Yan et al. (2018b) employed a discriminator to regularize the displacement field computed by the generator and found this approach to be more effective than the other regularizers in MR to TRUS registration. Mahapatra et al. (2018a) used Cycle- GAN for multi-modal (retinal) and uni-modal (MR) deformable registration where the generator produces both the transformed image and the deformation field. Mahapatra et al. (2018c) took one step further and explored the idea of joint segmentation and registration with CycleGAN and found their method per- forms better than the separate approaches for lung X-ray images. Tanner et al. (2018) employed CycleGAN for deformable image registration between MR and CT by first transforming the source domain image to the target domain and then employing a mono- modal image similarity measure for the registration. They found this method can achieve at best similar performance with the traditional multi-modal deformable registration methods.</p><p>cGAN还可用于多模态或单峰图像配准。在这种情况下，生成器将生成变换参数，例如，用于3D仿射变换的12个数字，用于非刚性变换的变形场，或者直接生成变换后的图像。判别器然后将对齐的图像对与未对齐的图像对区分开来。<br>空间变换网络（Jaderberg et al.，2015）或可变形变换层（Fan et al.，2018）通常插入这两个网络之间，以实现端到端训练。Yan等人（2018b）使用该框架进行前列腺MR到经直肠超声（TRUS）图像配准。配对训练数据由专家手动登记获得。Yan等人（2018b）使用判别器对生成器计算的位移场进行正则化，并发现该方法比MR-to-TRU配准中的其他正则化方法更有效。Mahapatra等人（2018a）使用Cycle-GAN进行多模（视网膜）和单模（MR）可变形配准，其中生成器生成变换图像和变形场。Mahapatra等人（2018c）更进一步，探索了联合分割和CycleGAN配准的想法，发现他们的方法比肺X射线图像的单独方法更好。Tanner等人（2018年）采用CycleGAN进行MR和CT之间的变形图像配准，首先将源域图像变换为目标域，然后采用单峰图像相似性度量进行配准。他们发现，这种方法最多可以达到与传统的多模态变形配准方法相似的性能。</p><h3 id="3-7-Other-works"><a href="#3-7-Other-works" class="headerlink" title="3.7 Other works"></a>3.7 Other works</h3><p>In addition to the tasks described in the aforementioned sections, GANs have also been applied in other tasks discussed here. For instance, cGAN has been used for modelling patient specific motion distribution based on a single preoperative image ( Hu et al., 2017c ), highlighting regions most accountable for a disease ( Baumgartner et al., 2017 ) and recolorization of endoscopic video data ( Ross et al., 2018 ). In Mahmood et al. (2018) pix2pix was used for treatment planning in radiotherapy by predicting the dose distribution map from CT image. WGAN has also been used for modelling the progression of Alzheimer’s disease (AD) in MRI. This is achieved by isolating the latent encoding of AD and performing arithmetic operation in the latent space ( Bowles et al., 2018b ).</p><p>除了上述章节中描述的任务外，GANs还应用于本文讨论的其他任务。例如，cGAN已用于基于单个术前图像（Hu等人，2017c）对患者特定的运动分布进行建模，突出对疾病最负责的区域（Baumgartner等人，2017年）和内窥镜视频数据的重新定位（Ross等人，2018年）。Mahmood等人（2018年）通过从CT图像预测剂量分布图，将pix2pix用于放射治疗计划。WGAN还被用于在MRI中模拟阿尔茨海默病（AD）的进展。这是通过隔离AD的潜在编码并在潜在空间中执行算术运算来实现的（Bowles等人，2018b）。</p><h2 id="4-Discussion"><a href="#4-Discussion" class="headerlink" title="4. Discussion"></a>4. Discussion</h2><p>In the years 2017 and 2018, the number of studies applying GANs has risen significantly. The list of these papers reviewed for our study can be found on our 1 GitHub repository.</p><p>2017年和2018年，应用GANs的研究数量显著增加。为我们的研究而审查的这些论文的列表可以在我们的GitHub存储库中找到。</p><p>About 46% of these papers studied image synthesis, with cross modality image synthesis being the most important application of GANs. MR is ranked as the most common imaging modality explored in the GAN related literature. We believe one of the reasons for the significant interest in applying GANs for MR image analysis is due to the excessive amount of time spent on the acquisition of multiple sequences. GANs hold the potential to reduce MR acquisition time by faithfully generating certain sequences from already acquired ones. A recent study in image synthesis across different MR sequences using CollaGAN shows the irreplaceable nature of exogenous contrast sequence, but reports the synthesis of endogenous contrast such as T1, T2, from each other with high fidelity ( Lee et al., 2019 ). A second reason for the popularity of GANs in MR might be because of large number of publicly available MR datasets as shown in Table 7 .</p><p>大约46%的论文研究了图像合成，其中跨模态图像合成是GANs最重要的应用。MR被列为最常见的成像方式，在相关文献中探讨。我们认为，将GANs应用于MR图像分析的一个重要原因是在获取多个序列上花费了过多的时间。通过从已经获取的序列忠实地生成特定序列，GANs有可能缩短MR获取时间。最近一项使用CollaGAN的跨不同MR序列的图像合成研究表明，外源性对比度序列具有不可替代的性质，但报告了内源性对比度（如T1、T2）的合成，它们彼此之间具有高保真度（Lee et al.，2019）。GANs在MR中受欢迎的第二个原因可能是，如表7所示，有大量公开的MR数据集。</p><p>Another 37% of these studies fall into the group of reconstruction and segmentation due to the popularity of image-to-image translation frameworks. Adversarial training in these cases imposes a strong shape and texture regulation on the generator’s output which makes it very promising in these two tasks. For example, in liver segmentation from 3D CT volumes, the incorporation of adversarial loss significantly improves the segmentation performance on non-contrast CT (has fuzzy liver boundary) than graph cut and CRF ( Yang et al., 2017a ).</p><p>由于图像到图像翻译框架的流行，另外37%的研究属于重建和分割组。在这些情况下，对抗性训练对生成器的输出施加了强大的形状和纹理调节，这使得它在这两项任务中非常有希望。例如，在从3D CT体积进行肝脏分割时，与graph cut和CRF（Yang等人，2017a）相比，在非对比CT（肝脏边界模糊）上引入对抗性丢失显著提高了分割性能。</p><p>Further 8% of these studies are related to classification. In these studies, the most effective use case was to combat domain shift. For the studies that used GAN for data augmentation in classification, most focused on generating tiny objects that can be easily aligned, such as nodules, lesions and cells. We believe it is partly due to the relatively smaller content variation of these images compared to the full context image which makes the training more stable with the current technique. Another reason might be related to the computation budget of the re- search since training on high resolution images requires a lot<br>of GPU time. Although there are studies that applied GAN on synthesizing whole chest-X-ray ( Madani et al., 2018a; 2018b ), the effectiveness has only been shown on fairly easy tasks, e.g. cardiac abnormality classification and on a medium size data regime, e.g. a couple of thousand images. With the advent of large volume labeled datasets, such as the CheXpert ( Irvin et al., 2019 ), it seems there is diminishing return in the employment of GANs for image generation, especially for classification. We would like to argue that GANs are still useful in the following two cases. First, nowadays the training of a deep neural network heavily relies on data augmentation to improve the network’s generalizability on unseen test data and reduce overfitting. However, existing data augmentation operations are all manually designed operations, e.g. rotation, color jittering, and can not cover the whole variation of the data. Cubuk et al. (2018) recently proposed to learn an augmentation policy with reinforcement learning but the search space still consisted of basic hand-crafted image processing operations.</p><p>另外8%的研究与分类有关。在这些研究中，最有效的用例是对抗领域转移。在使用GAN进行分类数据增强的研究中，大多数集中于生成易于对齐的微小对象，如结节、病变和细胞。我们认为，这部分是由于与全背景图像相比，这些图像的内容变化相对较小，这使得当前技术下的训练更加稳定。另一个原因可能与研究的计算预算有关，因为在高分辨率图像上进行训练需要大量的GPU时间。尽管有研究将GAN应用于合成整个胸部X射线（Madani et al.，2018a；2018b），但其有效性仅在相当简单的任务上显示，例如心脏异常分类和中等大小的数据区域，例如数千张图像。随着大容量标记数据集的出现，如CheXpert（Irvin et al.，2019），使用GANs生成图像（尤其是分类）的回报似乎越来越小。我们认为，在以下两种情况下，GAN仍然有用。首先，目前深度神经网络的训练在很大程度上依赖于数据扩充，以提高网络对未知测试数据的泛化能力并减少过拟合。然而，现有的数据增强操作都是手动设计的操作，例如旋转、颜色抖动，不能覆盖数据的全部变化。Cubuk等人（2018年）最近提议学习强化学习的心理策略，但搜索空间仍然包括基本的手工图像处理操作。</p><p>GANs, however, can allow us to sample the whole data distribution which offers much more flexibility in augmenting the training data ( Bowles et al., 2018a ). For example, styleGAN, is able to generate high resolution realistic face images with unprecedented level of details. This could be readily applied to chest X-ray datasets to generate images of a pathology class that has sufficient number of cases. Second, it is well known that medical data distribution is highly skewed with its largest mass centered on common diseases. It is impossible to accumulate enough training data for rare diseases, such as rheumatoid arthritis, sickle cell disease. But radiologists have been trained to detect these diseases in the long tail. Thus, another potential of GANs will be in synthesizing uncommon pathology cases, most likely through conditional generation with the conditioned information being specified by medical experts either through text description or hand drawn figures. The remaining studies pertaining to detection, registration and other applications are so limited that it is hard to draw any conclusion.</p><p>然而，GANs可以让我们对整个数据分布进行采样，这在增加训练数据方面提供了更大的灵活性（Bowles等人，2018a）。例如，styleGAN能够生成具有前所未有细节水平的高分辨率真实人脸图像。这可以很容易地应用于胸部X射线数据集，以生成具有足够病例数的病理学类别的图像。第二，众所周知，医疗数据分布高度倾斜，其最大质量集中在常见疾病上。对于类风湿性关节炎、镰状细胞病等罕见疾病，不可能积累足够的训练数据。但是放射科医生已经接受了在长尾中检测这些疾病的培训。因此，GANs的另一个潜力是合成不常见的病理病例，最有可能通过条件生成，条件信息由医学专家通过文本描述或手绘图形指定。其余与检测、注册和其他应用相关的研究非常有限，很难得出任何结论。</p><h3 id="4-1-Future-challenges"><a href="#4-1-Future-challenges" class="headerlink" title="4.1 Future challenges"></a>4.1 Future challenges</h3><p>Alongside many positive utilities of GANs, there are still challenges that need to be resolved for their employment to medical imaging. In image reconstruction and cross modality image synthesis, most works still adopt traditional shallow reference metrics such as MAE, PSNR, or SSIM for quantitative evaluation. These measures, however, do not correspond to the visual quality of the image. For example, direct optimization of pixel-wise loss pro- duces a suboptimal (blurry) result but provides higher numbers than using adversarial loss. It becomes increasingly difficult to interpret these numbers in horizontal comparison of GAN-based works especially when extra losses as shown in Table 2 are incorporated. One way to alleviate this problem is to use down stream tasks such as segmentation or classification to validate the quality of the generated sample. Another way is to recruit domain experts but this approach is expensive, time consuming and hard to scale. Recently, Zhang et al. (2018b) proposed learned perceptual image path similarity (LPIPS), which outperforms previous metrics in terms of agreement with human judgements. It has been adopted in MedGAN ( Armanious et al., 2018c ) for evaluation of the generated image quality but it would be interesting to see its effectiveness for different types of medical images as compared to subjective measures from experienced human observers in a more extensive study. For natural images, the unconditional generated sample quality and diversity is usually measured by inception score ( Salimans et al., 2016 ), the mean MS-SSIM metric among randomly chosen synthetic sample pairs ( Odena et al., 2017 ), or Fréchet Inception distance (FID) ( Heusel et al., 2017 ). The validity of these metrics for medical images remains to be explored.</p><p>除了GANs的许多积极用途外，还存在一些需要解决的挑战，以使其应用于医学成像。在图像重建和跨模态图像合成中，大多数工作仍然采用传统的浅层参考度量，如MAE、PSNR或SSIM进行定量评估。然而，这些度量与图像的视觉质量不符。例如，像素级损耗的直接优化会产生次优（模糊）结果，但比使用对抗性损耗提供更高的数值。在GAN基工程的横向比较中，尤其是在表2所示的额外损耗被纳入时，解释这些数字变得越来越困难。缓解此问题的一种方法是使用下游任务（如分割或分类）来验证生成样本的质量。另一种方法是招募领域专家，但这种方法成本高昂、耗时且难以扩展。最近，Zhang等人（2018b）提出了学习感知图像路径相似性（LPIPS），它在与人类判断一致性方面优于以前的度量。MedGAN（Armanious et al.，2018c）已采用该方法对生成的图像质量进行评估，但在更广泛的研究中，与经验丰富的人类观察者的主观测量相比，它对不同类型的医学图像的有效性将是有趣的。对于自然图像，无条件生成的样本质量和多样性通常通过初始分数（Salimans et al.，2016）、随机选择的合成样本对中的平均MS-SSIM度量（Odena et al.，2017）或Fréchet初始距离（FID）（Heusel et al.，2017）进行测量。这些指标对于医学图像的有效性还有待探索。</p><p>Cross domain image-to-image translation can be achieved with both paired and unpaired training data and it offers many prospective applications in medical imaging as has already been seen in Section 3.2.2 . Unpaired training does not have the data fidelity loss term therefore there is no guarantee of preservation of small abnormality regions during the translation process. Cohen et al. (2018) warn against the use of generated images for direct interpretation by doctors. They observe that trained CycleGAN networks (for unpaired data) can be subject to bias due to matching the generated data to the distribution of the target domain. This system bias comes into being when target domain images in the training set have an over or under representation of certain classes. As an example of exploitation of this effect, Mirsky et al. (2019) demonstrate the possibility of malicious tampering of 3D medical imaging using 3D conditional GANs to remove and inject solitary pulmonary nodule into patient’s CT scans. This system bias also exists in paired cross domain image-to-image translation with the data fidelity loss but only happens when the model was trained on normal images but tested on abnormal images. Cautions should be taken in training of the translation model and new methods should be proposed to faithfully preserve local abnormal regions.</p><p>跨域图像到图像的转换可以通过成对和不成对的训练数据来实现，它在医学成像中提供了许多潜在的应用，如第3.2.2节所述。未配对训练没有数据保真度损失项，因此无法保证在翻译过程中保留小的异常区域。Cohen等人（2018年）警告医生不要使用生成的图像进行直接解释。他们观察到，经过训练的CycleGAN网络（用于未配对数据）由于将生成的数据与目标域的分布相匹配，可能会产生偏差。当训练集中的目标域图像对某些类别的表示过度或不足时，就会产生这种系统偏差。作为利用这种效应的一个例子，Mirsky等人（2019年）证明了利用3D条件性GANs移除并将孤立性肺结节注射到患者CT扫描中恶意篡改3D医学成像的可能性。这种系统偏差也存在于成对的跨域图像到图像的转换中，数据保真度损失，但仅当模型在正常图像上训练，但在异常图像上测试时才会发生。在训练翻译模型时应注意，并应提出新的方法来忠实地保留局部异常区域。</p><h3 id="4-2-Interesting-future-applications"><a href="#4-2-Interesting-future-applications" class="headerlink" title="4.2 Interesting future applications"></a>4.2 Interesting future applications</h3><p>Similar to other deep learning neural network models, various applications of GANs demonstrated in this paper have direct bearing on improving radiology workflow and patient care. The strength of GANs however lies in their ability to learn in an unsupervised and/or weakly-supervised fashion. In particular, we perceive that image-to-image translation achieved by cGANs can have various other useful applications in medical imaging. For example, restoration of MR images acquired with certain artifacts such as motion, especially in a pediatric setting, may help reduce the number of repeated exams.</p><p>与其他深度学习神经网络模型类似，本文演示的GANs的各种应用对改进放射工作流程和患者护理有直接影响。然而，GAN的优势在于他们能够以无监督和/或弱监督的方式学习。特别是，我们认为CGAN实现的图像到图像的转换可以在医学成像中有各种其他有用的应用。例如，特别是在儿科环境中，恢复使用某些伪影（如运动）获取的MR图像可能有助于减少重复检查的次数。</p><p>Exploring GANs for image captioning task ( Dai et al., 2017a; Shetty et al., 2017; Melnyk et al., 2018; Fedus et al., 2018 ) may lead to semi-automatic generation of medical imaging re- ports ( Jing et al., 2017 ) potentially reducing image reporting times. Success of adversarial text classification ( Liu et al., 2017b ) also prompts potential utility of GANs in improving performance of such systems for automatic MR protocol generation from free-text clinical indications ( Sohn et al., 2017 ). Automated systems may improve MRI wait times which have been on the rise ( CIHI, 2017 ) as well as enhance patient care. cGANs, specifically CycleGAN applications, such as <strong>makeup removal(???)</strong> ( Chang et al., 2018 ), can be extended to medical imaging with applications in improving bone x-ray images by removal of artifacts such as casts to facilitate enhanced viewing. This may aid radiologists in assessing fine bony detail, potentially allowing for enhanced detection of initially occult fractures and helping assess the progress of bone healing more efficiently. The success of GANs in unsupervised anomaly detection ( Schlegl et al., 2017 ) can help achieve the task of detecting abnormalities in medical images in an unsupervised manner. This has the potential to be further extended for detection of implanted devices, e.g. staples, wires, tubes, pacemaker and artificial valves on X-rays. Such an algorithm can also be used for prioritizing radiologists’ work lists, thus reducing the turnaround time for reporting critical findings ( Gal Yaniv, 2018 ).</p><p>探索图像描述生成任务的GANs（Dai等人，2017a；Shetty等人，2017；Melnyk等人，2018；Fedus等人，2018）可能会导致医疗图像报告的半自动生成（Jing等人，2017），从而潜在地缩短图像报告时间。对抗性文本分类的成功（Liu等人，2017b）也提示了GANs在提高此类系统性能方面的潜在效用，以便根据自由文本临床指征自动生成MR协议（Sohn等人，2017）。自动化系统可以改善不断增加的MRI等待时间（CIHI，2017），并加强患者护理。CGAN，特别是CycleGAN应用，如卸妆（Chang et al.，2018），可以扩展到医学成像，通过去除石膏等伪影来改善骨x射线图像，以促进增强的视觉效果。这可能有助于放射科医生评估细微的骨骼细节，有可能增强对最初隐匿性骨折的检测，并有助于更有效地评估骨愈合的进展。GANs在无监督异常检测方面的成功（Schlegl等人，2017年）有助于以无监督方式检测医学图像中的异常。这有可能进一步扩展到植入设备的检测，例如X射线上的钉、线、管、起搏器和人工瓣膜。这种算法也可用于确定放射科医生工作清单的优先级，从而缩短报告关键发现的周转时间（Gal Yaniv，2018）。</p><p>We also expect to witness the utility of GANs in medical image synthesis from text descriptions ( Bodnar, 2018 ), especially for rare cases, so as to fill in the gap of training samples required for training supervised neural networks for medical image classification tasks. The recent work on styleGAN shows the capability to control ( Karras et al., 2019 ) the high level attributes of the synthesized image by manipulating the scale and bias parameters of the AdaIN layer ( Huang and Belongie, 2017 ). Similarly, the SPADE ( Park et al., 2019 ) controls the semantic layout of the synthesized image by a spatially adaptive normalization layer. Imagine in the future the desired attribute can be customized and specified in prior and manipulated in a localized fashion. We may then be able to predict the progression of disease, measure the impact of drug trial as suggested in Bowles et al. (2018b) but with more fine-grained controls.</p><p>我们还希望看到GANs在基于文本描述的医学图像合成中的应用（Bodnar，2018），特别是在罕见的情况下，以填补训练监督神经网络用于医学图像分类任务所需训练样本的空白。styleGAN的最新研究表明，通过操纵AdaIN层的比例和偏差参数，可以控制合成图像的高级属性（Karras等人，2019）（Huang和Belongie，2017）。类似地，SPADE（Park等人，2019）通过空间自适应归一化层控制合成图像的语义布局。设想将来所需的属性可以在Previor中自定义和指定，并以本地化方式进行操作。然后，我们可以预测疾病的进展，测量药物试验的影响，如Bowles等人（2018b）所建议的，但采用更精细的对照。</p><p>Different imaging modalities work by exploiting tissue response to a certain physical media, such as x-rays or a magnetic field, and thus can provide complementary diagnostic information to each other. As a common practice in supervised deep learning, images of one modality type are labelled to train a network to accomplish a desired task. This process is repeated when switching modalities even if the underlying anatomical structure is the same, resulting in a waste of human effort. Adversarial training, or more specifically unpaired cross modality translation, enables reuse of the labels in all modalities and opens new ways for unsupervised transfer learning ( Dou et al., 2018; Ying et al., 2019 ).</p><p>不同的成像模式通过利用组织对特定物理介质（如x射线或磁场）的反应来工作，因此可以相互提供补充的诊断信息。作为监督深度学习中的一种常见做法，一种模态类型的图像被标记以训练网络完成所需的任务。即使基础解剖结构相同，在切换模式时也会重复此过程，从而浪费人力。对抗性训练，或者更具体地说，非配对跨模态翻译，能够在所有模态中重复使用标签，并为无监督迁移学习开辟了新途径（Dou等人，2018年；Ying等人，2019年）。</p><p>Finally, we would like to point out that, although there have many promising results reported in the literature, the adoption of GANs in medical imaging is still in its infancy and there is currently no breakthrough application as yet adopted clinically for GANs-based methods.</p><p>最后，我们想指出的是，尽管文献中报告了许多有希望的结果，但在医学成像中采用GANs仍处于起步阶段，目前还没有基于GANs的方法在临床上得到突破性应用。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h4 id="最大对数似然目标"><a href="#最大对数似然目标" class="headerlink" title="最大对数似然目标"></a>最大对数似然目标</h4><h4 id="鞍点优化"><a href="#鞍点优化" class="headerlink" title="鞍点优化"></a>鞍点优化</h4><h4 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a>JS散度</h4><h4 id="模式崩溃"><a href="#模式崩溃" class="headerlink" title="模式崩溃"></a>模式崩溃</h4><h4 id="f散度"><a href="#f散度" class="headerlink" title="f散度"></a>f散度</h4><h4 id="铰链损失"><a href="#铰链损失" class="headerlink" title="铰链损失"></a>铰链损失</h4><h4 id="Wasserstein距离"><a href="#Wasserstein距离" class="headerlink" title="Wasserstein距离"></a>Wasserstein距离</h4><h4 id="自动编码器架构"><a href="#自动编码器架构" class="headerlink" title="自动编码器架构"></a>自动编码器架构</h4><h4 id="完全卷积采样"><a href="#完全卷积采样" class="headerlink" title="完全卷积采样"></a>完全卷积采样</h4><h4 id="分割掩模"><a href="#分割掩模" class="headerlink" title="分割掩模"></a>分割掩模</h4><h4 id="像素级或体素级"><a href="#像素级或体素级" class="headerlink" title="像素级或体素级"></a>像素级或体素级</h4><h4 id="二元势函数"><a href="#二元势函数" class="headerlink" title="二元势函数"></a>二元势函数</h4><h4 id="高阶势函数"><a href="#高阶势函数" class="headerlink" title="高阶势函数"></a>高阶势函数</h4><h4 id="感知损失"><a href="#感知损失" class="headerlink" title="感知损失"></a>感知损失</h4>]]></content>
      
      
      
        <tags>
            
            <tag> GAN; 生成对抗网络; Medical imaging; 医学图像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习相关名词解释</title>
      <link href="/2021/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"/>
      <url>/2021/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p>机器学习<code>Machine Learning</code>：机器学习致力于研究如何通过计算的手段，利用经验来改善自身性能。也即在计算机上从数据中产生“模型”<code>model</code>的算法，即学习算法<code>learning algorithm</code></p><p>经验：通常以数据形式存在的训练集</p><p>模型<code>model</code>：泛指从数据中学习到的结果。有时用“模型”指全局性的结果（如一棵决策树），而用“模式”指代局部性结果（如一条规则）</p><p>数据集<code>data set</code>：数据的集合，每一条记录是关于一个事件或对象的描述，称为一个示例<code>instance</code>或样本<code>sample</code>，反应事件或对象在某一方面的表现或性质的事项，称为属性<code>attribute</code>或特征<code>feature</code>；属性上的取值称为“属性值”<code>attribute value</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> 名词解释, 机器学习, 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构笔记（基于浙大MOOC）</title>
      <link href="/2021/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E4%BA%8E%E6%B5%99%E5%A4%A7MOOC%EF%BC%89/"/>
      <url>/2021/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E4%BA%8E%E6%B5%99%E5%A4%A7MOOC%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构（ZJU-MOOC）"><a href="#数据结构（ZJU-MOOC）" class="headerlink" title="数据结构（ZJU-MOOC）"></a>数据结构（ZJU-MOOC）</h1><h2 id="第一讲-基本概念"><a href="#第一讲-基本概念" class="headerlink" title="第一讲 基本概念"></a>第一讲 基本概念</h2><h3 id="1-1-什么是数据结构"><a href="#1-1-什么是数据结构" class="headerlink" title="1.1 什么是数据结构"></a>1.1 什么是数据结构</h3><ul><li><p>数据结构是计算机中存储、组织数据的方式。通常情况下，精心准备的数据结构可以带来最有效率的算法。</p></li><li><p>通常来说代码的效率与数据的规模直接挂钩，通过将大规模的问题缩小到小规模的问题的方法，往往有奇效。</p></li><li><p>递归对于空间的占用是极为恐怖的。</p></li><li><p>时间库&lt;time.h&gt;的使用方法</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">clock_t</span> start, stop;</span><br><span class="line"><span class="comment">/* clock_t 是clock()函数返回的变量类型 */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> duration;</span><br><span class="line"><span class="comment">/* 用来记录运行时间，以秒为单位 */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* 不在测试范围之前的准备工作写在clock()调用之前 */</span></span><br><span class="line">    start = <span class="built_in">clock</span>(); <span class="comment">//开始计时</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">MyFunction</span>(); <span class="comment">//把测试函数写在这里</span></span><br><span class="line"></span><br><span class="line">    stop = <span class="built_in">clock</span>();</span><br><span class="line">    duration = ((<span class="keyword">double</span>)(stop - start))/CLK_TCK;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 其他不在测试范围的处理写在后面，例如输出duration的值 */</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>数据结构是数据对象在计算机中的组织方式，数据对象一定与一系列加在其之上的操作相关联，完成这些操作所用的方法就是算法</p></li><li><p>线性结构 1 to 1</p><p>树形结构 1 to n</p><p>图      n to n</p></li><li><p>抽象数据类型</p><p>数据对象集</p><p>数据集合相关联的操作集</p></li></ul><h3 id="1-2-什么是算法"><a href="#1-2-什么是算法" class="headerlink" title="1.2 什么是算法"></a>1.2 什么是算法</h3><ul><li><p>算法的定义（一个有限的指令集，输入输出，在有限的步骤后停止，每一条指令都必须有明确的目标且不存在歧义，在计算机处理范围内，描述应不依赖于任何一种计算机语言以及具体的实现手段）</p></li><li><p>算法的评价指标</p><ul><li>空间复杂度$S(n)$</li><li>时间复杂度$O(n)$</li></ul></li><li><p>乘除法的时间消耗比加减法高很多，在时间复杂度计算的过程中权重更高</p></li><li><p>在分析一般算法的效率时，我们经常关注下面两种复杂度</p><ul><li>最坏情况复杂度$T_{worst}(n)$</li><li>平均复杂度$T_{avg}(n)$</li></ul><p>$T_{avg}(n)\le T_{worst}(n)$</p></li><li><p>复杂度的渐进表示法</p><p><img src="https://i.loli.net/2021/10/02/6HAYQLJvOD5ySVB.png" alt="image-20211002111912317"></p><p><img src="https://i.loli.net/2021/10/02/FqSpLcZAVo8aYs7.png" alt="image-20211002115340535"></p></li></ul><h3 id="1-3-应用实例：最大子列和问题"><a href="#1-3-应用实例：最大子列和问题" class="headerlink" title="1.3 应用实例：最大子列和问题"></a>1.3 应用实例：最大子列和问题</h3><p>问题描述：给定$N$个整数的序列${A_1,A_2,\dots,A_N}$,求函数$f(i,j)=max{0,\sum^j_{k=1}A_k}$的最大值</p><ul><li><p>算法一：暴力搜索，计算出所有子列和，$O(n^3)$</p><p><img src="https://i.loli.net/2021/10/02/ntKsqudSzQR4f6G.png" alt="image-20211002120659001"></p></li><li><p>算法二：利用前缀和，减少一层循环，$O(n^2)$</p><p><img src="https://i.loli.net/2021/10/02/nmvij4yx1sAQH3Y.png" alt="image-20211002120712907"></p></li><li><p>算法三：分治思想，分成两段分别寻找最大子列和，然后合并寻找最大子列和，$O(n\log{n})$</p><p><img src="https://i.loli.net/2021/10/02/Hh5RUOaZevdwBLu.png" alt="image-20211002120637483"></p></li><li><p>算法四：在线处理（指每输入一个数据就进行即时处理，在任何一个地方中止输入，算法都能正确给出当前解），$O(N)$</p><p><img src="https://i.loli.net/2021/10/02/XU7zn6tJTfe9YaG.png" alt="image-20211002121207191"></p></li></ul><h2 id="第二讲-线性结构"><a href="#第二讲-线性结构" class="headerlink" title="第二讲 线性结构"></a>第二讲 线性结构</h2><h3 id="2-1-线性表及其实现"><a href="#2-1-线性表及其实现" class="headerlink" title="2.1 线性表及其实现"></a>2.1 线性表及其实现</h3><h4 id="2-1-1-多项式的表示"><a href="#2-1-1-多项式的表示" class="headerlink" title="2.1.1 多项式的表示"></a>2.1.1 多项式的表示</h4><p>一元多项式$f(x)=a_0+a_1x+\dots+a_{n-1}x^{n-1}+a_n x^n$及其计算（多项式相加、相减、相乘）</p><ul><li><p>方法一：顺序存储结构直接表示（每一位固定存储对应的指数级的系数）</p><p>造成大量浪费，诸如$x+3x^{2000}$</p></li><li><p>方法二：顺序存储结构表示非零项（使用结构数组表示，数组分量表示系数和指数，按照指数大小有序存储即可方便计算）</p></li><li><p>方法三：链表结构存储非零项（链表中每个节点存储多项式的一个非零项，包括系数和指数两个数据域以及一个指针域用于指向下一个节点）</p></li></ul><p>多项式表示问题的启示：</p><ul><li>同一个问题可以有不同的表示、存储方式</li><li>有一类共性问题：有序线性序列的组织和管理</li></ul><h4 id="2-1-2-线性表的实现"><a href="#2-1-2-线性表的实现" class="headerlink" title="2.1.2 线性表的实现"></a>2.1.2 线性表的实现</h4><p><strong>线性表</strong>(<code>Linear List</code>)：由同类型数据元素构成的有序序列的线性结构</p><ul><li>表中元素个数称为长度</li><li>线性表没有元素时，称为空表</li><li>表起始位置称表头，结束位置称表尾</li></ul><p><strong>线性表的抽象数据类型描述</strong></p><p><img src="https://i.loli.net/2021/10/02/2Ub1f9BJqPeAwig.png" alt="image-20211002123339372"></p><p><strong>主要操作的实现</strong></p><ul><li><p>数组方式</p><ul><li><p>插入</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(j=PtrL-&gt;Last;j&gt;=i<span class="number">-1</span>;j--)</span><br><span class="line">    PtrL-&gt;Data[j+<span class="number">1</span>]=PtrL-&gt;Data[j];  <span class="comment">/*将a[i]~a[n]倒序向后移动*/</span></span><br><span class="line">PtrL-&gt;Data[i<span class="number">-1</span>]=X;<span class="comment">/*新元素插入*/</span></span><br><span class="line">PtrL-&gt;Last++;<span class="comment">/*Last依然指向最后元素*/</span></span><br></pre></td></tr></table></figure></li><li><p>删除</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(j=i;j&lt;=PtrL-&gt;Last;j++)</span><br><span class="line">    PtrL-&gt;Data[j<span class="number">-1</span>]=PtrL-&gt;Data[j];  <span class="comment">/*将a[i+1]~a[n]顺序向后移动*/</span></span><br><span class="line">PtrL-&gt;Last--;<span class="comment">/*Last依然指向最后元素*/</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>链表方式</p><ul><li><p>组织形式</p><p><img src="https://i.loli.net/2021/10/02/nJbxkDp5NFKoAGU.png" alt="image-20211002125029064"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span> *<span class="title">List</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">LNode</span>&#123;</span></span><br><span class="line">ElementType Data;</span><br><span class="line">List Next;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Lnode</span> <span class="title">L</span>;</span></span><br><span class="line">List PtrL;</span><br></pre></td></tr></table></figure></li><li><p>求表长（遍历一遍）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Length</span><span class="params">(List PtrL)</span></span>&#123;</span><br><span class="line">    List p=PtrL;<span class="comment">/*p指向表的第一个节点*/</span></span><br><span class="line">    <span class="keyword">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(p)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        j++;<span class="comment">/*当前p指向的是第j个节点*/</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查找</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*按照序号查找*/</span></span><br><span class="line"><span class="function">List <span class="title">FindKth</span><span class="params">(<span class="keyword">int</span> K,List PtrL)</span></span>&#123;</span><br><span class="line">    List p=PtrL;</span><br><span class="line">    <span class="keyword">int</span> i=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>&amp;&amp;i&lt;K)&#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i==K)<span class="keyword">return</span> p;<span class="comment">/*找到第K个，返回指针*/</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">NULL</span>;<span class="comment">/*否则返回空*/</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*按照数据值进行查找*/</span></span><br><span class="line"><span class="function">List <span class="title">Find</span><span class="params">(List PtrL,ElementType X)</span></span>&#123;</span><br><span class="line">    List p=PtrL; <span class="comment">/* p指向L的第1个结点 */</span></span><br><span class="line">    <span class="keyword">while</span> (p!=<span class="literal">NULL</span>&amp;&amp;p-&gt;Data!=X)</span><br><span class="line">        p=p-&gt;Next;</span><br><span class="line">    <span class="comment">/* 下列语句可以用 return p; 替换 */</span></span><br><span class="line">    <span class="keyword">if</span>(p)<span class="keyword">return</span> p;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>插入</p><ul><li>先构造一个新节点，用s指向；</li><li>再找到链表的第$i-1$个节点，用p指向；</li><li>然后修改指针，插入节点（p之后插入新节点s）。</li></ul><p><img src="https://i.loli.net/2021/10/02/ajxRqbdByVm7Hf2.png" alt="image-20211002130707569"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">List <span class="title">Insert</span><span class="params">(ElementType X,<span class="keyword">int</span> i,List PtrL)</span></span>&#123;</span><br><span class="line">    List p,s;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">1</span>)&#123; <span class="comment">/*新节点插入在表头*/</span></span><br><span class="line">        s=(List)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct LNode));<span class="comment">/*申请、装填节点*/</span></span><br><span class="line">        s-&gt;Data=X;</span><br><span class="line">        s-&gt;Next=PtrL;</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line">    p=<span class="built_in">FindKth</span>(i<span class="number">-1</span>,PtrL);<span class="comment">/*查找第i-1个节点*/</span></span><br><span class="line">    <span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;<span class="comment">/*第i-1个节点不存在*/</span></span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        s=(List)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct LNode));</span><br><span class="line">        s-&gt;Data=X;</span><br><span class="line">        s-&gt;Next=p-&gt;Next;<span class="comment">/*新节点插入在第i-1个节点之后*/</span></span><br><span class="line">        p-&gt;Next=s;</span><br><span class="line">        <span class="keyword">return</span> PtrL;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>删除</p><ul><li>先找到链表的第$i-1$个节点，用p指向；</li><li>再用指针s指向要被删除的节点（p的下一个节点）；</li><li>然后修改指针，删除s所指节点；</li><li>最后释放s所指的节点的空间。</li></ul><p><img src="https://i.loli.net/2021/10/02/3nHPFRsdqlWigmI.png" alt="image-20211002134056397"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">List <span class="title">Dlete</span><span class="params">(<span class="keyword">int</span> i,List PtrL)</span></span>&#123;</span><br><span class="line">    List p,s;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">1</span>)&#123;</span><br><span class="line">        s=PtrL;</span><br><span class="line">        <span class="keyword">if</span>(PtrL!=<span class="literal">NULL</span>)PtrL=PtrL-&gt;Next;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        <span class="built_in">free</span>(s);</span><br><span class="line">        <span class="keyword">return</span> PtrL;</span><br><span class="line">    &#125;</span><br><span class="line">    p=<span class="built_in">FindKth</span>(i<span class="number">-1</span>,PtrL);</span><br><span class="line">    <span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;第%d个节点不存在&quot;</span>,i<span class="number">-1</span>);<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(p-&gt;next==<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;第%d个节点不存在&quot;</span>,i);<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        s=p-&gt;Next;<span class="comment">/*s指向第i个节点*/</span></span><br><span class="line">        p-&gt;Next=s-&gt;Next;<span class="comment">/*从链表中删除*/</span></span><br><span class="line">        <span class="built_in">free</span>(s);<span class="comment">/*释放被删除节点空间*/</span></span><br><span class="line">        <span class="keyword">return</span> PtrL;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="2-1-3-广义表"><a href="#2-1-3-广义表" class="headerlink" title="2.1.3 广义表"></a>2.1.3 广义表</h4><p>广义表是线性表的推广，对于线性表来说，n个元素都是基本的单元素，广义表中，这些元素不仅可以是单元素也可以是另一个广义表。</p><p>双向链表、多重链表</p><p>矩阵尤其是稀疏矩阵，使用多重链表中的十字链表进行存储更有利于节省存储空间</p><h3 id="2-2-堆栈"><a href="#2-2-堆栈" class="headerlink" title="2.2 堆栈"></a>2.2 堆栈</h3><h4 id="2-2-1-什么是堆栈"><a href="#2-2-1-什么是堆栈" class="headerlink" title="2.2.1 什么是堆栈"></a>2.2.1 什么是堆栈</h4><p>堆栈<code>Stack</code>：具有一定操作约束的线性表，只能在一端（栈顶，top）做插入和删除（先进后出<code>Last In First Out</code>）</p><p>插入数据：入栈<code>Push</code>，删除数据：出栈<code>Pop</code></p><p><strong>堆栈的抽象数据类型</strong>描述：</p><p><img src="https://i.loli.net/2021/10/02/nfKcALD5XTYZqav.png" alt="image-20211002140528389"></p><h4 id="2-2-2-堆栈的实现"><a href="#2-2-2-堆栈的实现" class="headerlink" title="2.2.2 堆栈的实现"></a>2.2.2 堆栈的实现</h4><ul><li><p>数组实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">SNode</span> *<span class="title">Stack</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SNode</span>&#123;</span></span><br><span class="line">    ElementType Data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> Top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Push</span><span class="params">(Stack PtrS,ElementType item)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(PtrS-&gt;Top==MaxSize<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Full&quot;</span>);<span class="keyword">return</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        PtrS-&gt;Data[++(PtrS-&gt;Top)]=item;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ElementType <span class="title">Pop</span><span class="params">(Stack PtrS)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(PtrS-&gt;Top==<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Empty&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;<span class="keyword">else</span></span><br><span class="line">        <span class="built_in"><span class="keyword">return</span></span> (PtrS-&gt;Data[(PtrS-&gt;Top)--]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>链表实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SNode</span>&#123;</span></span><br><span class="line">    ElementType Data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">SNode</span> *<span class="title">Next</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">Stack <span class="title">CreateStack</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Stack S;</span><br><span class="line">    S=(Stack)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct SNode));</span><br><span class="line">    S-&gt;Next=<span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">IsEmpty</span><span class="params">(Stack S)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (S-&gt;Next==<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Push</span><span class="params">(ElementType item,Stack S)</span></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">SNode</span> *<span class="title">TmpCell</span>;</span></span><br><span class="line">    TmpCell=(struct SNode *)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct SNode));</span><br><span class="line">    TmpCell-&gt;Element=item;</span><br><span class="line">    TmpCell-&gt;Next=S-&gt;Next;</span><br><span class="line">    S-&gt;Next=TmpCell;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*可以看到链表的堆栈是以链表头为栈顶，在此处进行插入和删除实现的*/</span></span><br><span class="line"><span class="function">ElementType <span class="title">Pop</span><span class="params">(Stack S)</span></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">SNode</span> *<span class="title">FirstCell</span>;</span></span><br><span class="line">    ElementType TopElem;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">IsEmpty</span>(S))&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Empty&quot;</span>);<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        FirstCell=S-&gt;Next;</span><br><span class="line">        S-&gt;Next=FirstCell-&gt;Next;</span><br><span class="line">        TopElem=FirstCell-&gt;Element;</span><br><span class="line">        <span class="built_in">free</span>(FirstCell);</span><br><span class="line">        <span class="keyword">return</span> TopElem;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-2-3-表达式求值"><a href="#2-2-3-表达式求值" class="headerlink" title="2.2.3 表达式求值"></a>2.2.3 表达式求值</h4><p><img src="https://i.loli.net/2021/10/02/wmiGW92ZqKet83b.png" alt="image-20211002142758551"></p><p>中缀表达式：$a+b*c-d/e$</p><p>后缀表达式：$abc*+de/-$</p><p>后缀表达式求值策略：从左向右“扫描”，逐个处理运算数和运算符号；遇到运算数时压栈，遇到运算符号时从堆栈中弹出适当的运算数，计算结构后入栈；最后栈顶元素就是表达式的结果。 </p><p><strong>中缀表达式转后缀表达式</strong></p><p><img src="https://i.loli.net/2021/10/02/Yru9Zg8AlFS4LJb.png" alt="image-20211002142833489"></p><h3 id="2-3-队列"><a href="#2-3-队列" class="headerlink" title="2.3 队列"></a>2.3 队列</h3><h4 id="2-3-1-什么是队列"><a href="#2-3-1-什么是队列" class="headerlink" title="2.3.1 什么是队列"></a>2.3.1 什么是队列</h4><p>队列<code>Queue</code>：具有一定操作约束的线性表，只能在一端插入，另一端删除，即先进先出。</p><p>数据插入：入队列<code>AddQ</code>，数据删除：出队列<code>DeleteQ</code>，先进先出<code>FIFO</code></p><p><strong>队列的抽象数据类型描述</strong></p><p><img src="https://i.loli.net/2021/10/03/DoVUj2NelJuFtfI.png" alt="image-20211003101155512"></p><h4 id="2-3-2-队列的实现"><a href="#2-3-2-队列的实现" class="headerlink" title="2.3.2 队列的实现"></a>2.3.2 队列的实现</h4><ul><li><p>数组实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">QNode</span>&#123;</span></span><br><span class="line">    ElementType Data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> rear;</span><br><span class="line">    <span class="keyword">int</span> front;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span> *<span class="title">Queue</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//思考循环链表判断队列空和满的条件</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">AddQ</span><span class="params">(Queue PtrQ,ElementType item)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(PtrQ-&gt;rear+<span class="number">1</span>==MaxSize)&#123;</span><br><span class="line">        <span class="comment">//(PtrQ-&gt;rear+1)%MaxSize==PtrQ-&gt;front</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Full&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//PtrQ-&gt;rear=(PtrQ-&gt;rear+1)%MaxSize;</span></span><br><span class="line">    <span class="comment">//PtrQ-&gt;Data[PtrQ-&gt;rear]=item;</span></span><br><span class="line">    PtrQ-&gt;Data[++PtrQ-&gt;rear]=item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ElementType <span class="title">DeleteQ</span><span class="params">(Queue PtrQ)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(PtrQ-&gt;front==PtrQ-&gt;rear)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Empty&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//PtrQ-&gt;front=(PtrQ-&gt;front+1)%MaxSize;</span></span><br><span class="line">        <span class="comment">//return PtrQ-&gt;Data[PtrQ-&gt;front];</span></span><br><span class="line">        <span class="keyword">return</span> PtrQ[PtrQ-&gt;front++];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>链表实现</p><p><img src="https://i.loli.net/2021/10/03/zeiPoKyNdLw5H7W.png" alt="image-20211003102506254"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">    ElementType Data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Node</span> *<span class="title">Next</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">QNode</span>&#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Node</span> *<span class="title">rear</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Node</span> *<span class="title">front</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span> *<span class="title">Queue</span>;</span></span><br><span class="line">Queue PtrQ;</span><br><span class="line"></span><br><span class="line"><span class="function">ElementType <span class="title">DeleteQ</span><span class="params">(Queue PtrQ)</span></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Node</span> *<span class="title">FrontCell</span>;</span></span><br><span class="line">    ElementType FrontElem;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(PtrQ-&gt;front==<span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Empty&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    FrontCell=PtrQ-&gt;front;</span><br><span class="line">    <span class="keyword">if</span>(PtrQ-&gt;front==PtrQ-&gt;rear)<span class="comment">//若队列只有一个元素</span></span><br><span class="line">        PtrQ-&gt;front=PtrQ-&gt;rear=<span class="literal">NULL</span>;<span class="comment">//删除后置队列为空</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        PtrQ-&gt;front=PtrQ-&gt;front-&gt;Next;</span><br><span class="line">    FrontElem=FrontCell-&gt;Data;</span><br><span class="line">    <span class="built_in">free</span>(FrontCell);<span class="comment">//释放被删除节点空间</span></span><br><span class="line">    <span class="keyword">return</span> FrontElem;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="第三章-树"><a href="#第三章-树" class="headerlink" title="第三章 树"></a>第三章 树</h2><h3 id="3-1-树与树的表示"><a href="#3-1-树与树的表示" class="headerlink" title="3.1 树与树的表示"></a>3.1 树与树的表示</h3><h4 id="3-1-1-查找"><a href="#3-1-1-查找" class="headerlink" title="3.1.1 查找"></a>3.1.1 查找</h4><p>查找<code>Searching</code>：根据某个给定的关键词K，从集合R中找到关键字与K相同的记录</p><p>静态查找：集合中记录是固定的，没有插入和删除操作，只有查找</p><p>动态查找：集合中记录是动态变化的；除查找，还可能发生插入和删除</p><p><strong>静态查找方法</strong></p><ul><li><p>方法一：顺序查找$O(n)$</p></li><li><p>方法二：二分查找$O(log{n})$</p><p>假设n个数据元素的关键字满足<strong>有序</strong>，如$k_1&lt;k_2&lt;\cdots&lt;k_n$，并且是连续存放（数组），那么可以进行二分查找</p><p>$mid=(left+right)/2$</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">BinarySearch</span><span class="params">(List Tbl,ElementType K)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left,right,mid,NotFound=<span class="number">-1</span>;</span><br><span class="line">    left=<span class="number">1</span>;</span><br><span class="line">    right=Tbl-&gt;Length;</span><br><span class="line">    <span class="keyword">while</span>(left&lt;=right)&#123;</span><br><span class="line">        mid=(left&lt;=right)/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(K&lt;Tbl-&gt;Element[mid])right=mid<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(K&gt;Tbl-&gt;Element[mid])left=mid+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> NotFound;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/10/03/qCHwAgDP8dk2YU4.png" alt="image-20211003143047176"></p></li></ul><h4 id="3-1-2-树的基础"><a href="#3-1-2-树的基础" class="headerlink" title="3.1.2 树的基础"></a>3.1.2 树的基础</h4><p>树<code>Tree</code>：$n$个节点构成的有限集合。当$n=0$时，称为空树；对于任一非空树$n&gt;0$，它具备如下特征：</p><ul><li>树中有一个称为根<code>Root</code>节点的特殊节点，用r表示；</li><li>其余节点可以分为$m(m&gt;0)$个互不相交的有限集$T_1,T_2,\dots,T_m$，其中每个集合本身又是一棵树，称为原来树的“子树<code>SubTree</code>”</li></ul><p><strong>树的一些基本术语</strong></p><ol><li>结点的度<code>Degree</code>：结点的子树个数</li><li>树的度：树的所有节点中最大的度数</li><li>叶结点<code>Leaf</code>：度为0的结点</li><li>父结点<code>Parent</code>：有子树的结点是其子树的根结点的父结点</li><li>子结点<code>Child</code>：若A结点是B结点的父结点，则称B结点是A结点的子结点</li><li>兄弟结点<code>Siblings</code>：具有同一父结点的各结点彼此是兄弟结点</li><li>路径和路径长度：从结点$n_1$到结点$n_k$的路径为一个结点序列$n_1,n_2,\dots,n_k$，$n_i$是$n_{i+1}$的父结点。路径所包含的边的个数为路径的长度。</li><li>祖先结点<code>Ancestor</code>：沿树根到某一结点路径上的所有结点都是这个结点的祖先结点。</li><li>子孙结点<code>Descendant</code>：某一结点的子树中所有结点是这个结点的子孙。</li><li>结点的层次<code>Level</code>：规定根结点在1层，其他任一结点的层数是其父结点的层数加1。</li><li>树的深度<code>Depth</code>：树中所有结点中最大层次是这棵树的深度</li></ol><p><strong>树相关的计算</strong></p><p>规律1：（节点个数）m=（边数）n+1<br>规律2： 度为节点的子女个数，可以看作几个出边就是几个度，叶子节点没有度</p><p><strong>树的表示</strong></p><ul><li><p>儿子兄弟表示法</p><p><img src="https://i.loli.net/2021/10/03/Cy73TKJzsPctYpg.png" alt="image-20211003153247387"></p><p>实际上此方法就构造了一棵新的二叉树，也即实现了二叉树的表示即可表示任意树。</p></li></ul><h3 id="3-2-二叉树及存储结构"><a href="#3-2-二叉树及存储结构" class="headerlink" title="3.2 二叉树及存储结构"></a>3.2 二叉树及存储结构</h3><h4 id="3-2-1-二叉树的定义"><a href="#3-2-1-二叉树的定义" class="headerlink" title="3.2.1 二叉树的定义"></a>3.2.1 二叉树的定义</h4><p>二叉树$T$：一个有穷的结点集合，这个结点可以为空，若不为空，则它是由根结点和称为其左子树$T_L$和右子树$T_R$的两个不相交的二叉树组成。其中每个结点的度最大为2。</p><ul><li><p>二叉树的子树有左右顺序之分</p></li><li><p>二叉树的五种基本形态</p><p><img src="https://i.loli.net/2021/10/03/5IPq7shkOrE4jA2.png" alt="image-20211003154726945"></p></li><li><p>特殊二叉树</p><ul><li><p>斜二叉树<code>Skewed Binary Tree</code></p><p><img src="https://i.loli.net/2021/10/03/4eqsA2lmYnydjzO.png" alt="image-20211003154825176"></p></li><li><p>完全二叉树<code>Complete Binary Tree</code></p><p>有n个结点的二叉树，对树中结点按从上至下、从左到右顺序进行编号，编号为$i (1\le i \le n)$结点与满二叉树中编号为i结点在二叉树中位置相同</p></li><li><p>完美二叉树<code>Perfect Binary Tree</code>、满二叉树<code>Full Binary Tree</code></p><p><img src="https://i.loli.net/2021/10/03/v5oWs7NMQcCgDEK.png" alt="image-20211003155852826"></p></li></ul></li></ul><h4 id="3-2-2-二叉树的几个重要性质"><a href="#3-2-2-二叉树的几个重要性质" class="headerlink" title="3.2.2 二叉树的几个重要性质"></a>3.2.2 二叉树的几个重要性质</h4><ul><li><p>一个二叉树第$i$层最大结点数为：$2^{i-1},i\ge 1$</p></li><li><p>深度为$k$的二叉树有最大结点数为：$2^k-1,k\ge1$</p></li><li><p>对任何非空二叉树$T$，若$n_0$表示叶结点的个数、$n_2$是度为2的非叶结点的个数，那么两者的关系满足$n_0=n_2+1$</p></li><li><p>$n$个结点的二叉树一共多少种？</p><p>$f(n)=\frac{(2n)!}{n!(n+1)!}$</p></li><li><p>$n$层二叉树的第$n$层最多有多少个结点？</p><p>$f(n)=2^{n-1}$</p></li><li><p>一个有$n$个结点的完全二叉树的深度为？</p><p>$h(n)=log_2n+1$</p></li><li><p>一个完全二叉树的结点为$n$，则该二叉树的叶子结点为多少？</p><p>$f(n)=n-(n/2)$</p></li></ul><h4 id="3-2-3-二叉树的表示和实现"><a href="#3-2-3-二叉树的表示和实现" class="headerlink" title="3.2.3 二叉树的表示和实现"></a>3.2.3 二叉树的表示和实现</h4><p><strong>二叉树的抽象表示</strong></p><p><img src="https://i.loli.net/2021/10/03/7Pzga3UrwY2WDjF.png" alt="image-20211003161147938"></p><p><strong>二叉树的存储结构</strong></p><ol><li><p><strong>顺序存储结构</strong></p><p>完全二叉树：按从上至下、从左到右顺序存储</p><p>$n$个结点的完全二叉树的结点父子关系：</p><ul><li>非根结点（序号$i&gt;1$）的父结点的序号是$\lfloor i \rfloor$</li><li>结点（序号为$i$）的左孩子结点的序号是$2i$（$2i\le n$，否则没有左孩子）</li><li>结点（序号为$i$）的右孩子结点的序号是$2i+1$（$2i+1\le n$，否则没有左孩子）</li></ul><p><img src="https://i.loli.net/2021/10/03/aGwoOLUbhe5Ay1K.png" alt="image-20211003161841643"></p><p><img src="https://i.loli.net/2021/10/03/fDRFlQwJt7kTpcy.png" alt="image-20211003161851011"></p><p>对于一般的二叉树也可以使用这种结构，但会造成很高的空间浪费</p></li><li><p><strong>链表存储</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">TreeNode</span> *<span class="title">BinTree</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> BinTree Position;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TreeNode</span>&#123;</span></span><br><span class="line">    ElementType Data;</span><br><span class="line">    BinTree Left;</span><br><span class="line">    BinTree Right;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/10/03/6uWiYyUDK7RlFpA.png" alt="image-20211003162138544"></p><p><img src="https://i.loli.net/2021/10/03/27Qe9J5phEuKbrI.png" alt="image-20211003162149228"></p></li><li><p><strong>静态链表</strong></p><p>使用结构数组构建“链表形式”的“静态链表”，其中左右孩子指示位存储的是左右孩子所对应的下标</p><p><img src="https://i.loli.net/2021/10/03/ST1XvNLK2cOwu3y.png" alt="image-20211003194829854"></p></li></ol><h3 id="3-3-二叉树的遍历"><a href="#3-3-二叉树的遍历" class="headerlink" title="3.3 二叉树的遍历"></a>3.3 二叉树的遍历</h3><p>先序、中序、后序遍历过程中经过节点的路线一样，只是访问各结点的实际不同。</p><h4 id="3-3-1-先序遍历"><a href="#3-3-1-先序遍历" class="headerlink" title="3.3.1 先序遍历"></a>3.3.1 先序遍历</h4><p>访问根结点、先序遍历其左子树、先序遍历其右子树</p><p><img src="https://i.loli.net/2021/10/03/uLGN2IbQHOPiED5.png" alt="image-20211003182747329"></p><p>   <strong>先序遍历非递归遍历</strong>算法：使用<strong>堆栈</strong></p><ul><li>遇到一个结点，就把它输入然后压栈，并去遍历其左子树</li><li>当左子树遍历结束后，按照其右指针再去中序遍历该结点的右子树</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preOrder2</span><span class="params">(BinTree *root)</span>     <span class="comment">//非递归前序遍历</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    stack&lt;BinTree*&gt; s;</span><br><span class="line">    BinTree *p=root;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>||!s.<span class="built_in">empty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            cout&lt;&lt;p-&gt;data&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">            s.<span class="built_in">push</span>(p);</span><br><span class="line">            p=p-&gt;lchild;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!s.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            p=s.<span class="built_in">top</span>();</span><br><span class="line">            s.<span class="built_in">pop</span>();</span><br><span class="line">            p=p-&gt;rchild;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-3-2-中序遍历"><a href="#3-3-2-中序遍历" class="headerlink" title="3.3.2 中序遍历"></a>3.3.2 中序遍历</h4><p>中序遍历其左子树、访问根结点、中序遍历其右子树</p><p><img src="https://i.loli.net/2021/10/03/ux5Bjhp9LlSfGac.png" alt="image-20211003182824443"></p><p><strong>中序遍历非递归遍历</strong>算法：使用<strong>堆栈</strong></p><ul><li>遇到一个结点，就把它压栈，并去遍历其左子树</li><li>当左子树遍历结束后，从栈顶弹出此结点并访问之</li><li>然后按照其右指针再去中序遍历该结点的右子树</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">inOrder2</span><span class="params">(BinTree *root)</span>      <span class="comment">//非递归中序遍历</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    stack&lt;BinTree*&gt; s;</span><br><span class="line">    BinTree *p=root;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>||!s.<span class="built_in">empty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            s.<span class="built_in">push</span>(p);</span><br><span class="line">            p=p-&gt;lchild;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!s.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            p=s.<span class="built_in">top</span>();</span><br><span class="line">            cout&lt;&lt;p-&gt;data&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">            s.<span class="built_in">pop</span>();</span><br><span class="line">            p=p-&gt;rchild;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-3-3-后序遍历"><a href="#3-3-3-后序遍历" class="headerlink" title="3.3.3 后序遍历"></a>3.3.3 后序遍历</h4><p>后序遍历其左子树、后序遍历其右子树、访问根节点</p><p><img src="https://i.loli.net/2021/10/03/BoU5hHz8NS6wxRW.png" alt="image-20211003182916552"></p><p><strong>后序遍历非递归</strong>遍历算法：使用堆栈</p><ul><li><p>第一种思路：对于任一结点P，将其入栈，然后沿其左子树一直往下搜索，直到搜索到没有左孩子的结点，此时该结点出现在栈顶，但是此时不能将其出栈并访问， 因此其右孩子还为被访问。所以接下来按照相同的规则对其右子树进行相同的处理，当访问完其右孩子时，该结点又出现在栈顶，此时可以将其出栈并访问。这样就 保证了正确的访问顺序。可以看出，在这个过程中，每个结点都两次出现在栈顶，只有在第二次出现在栈顶时，才能访问它。因此<em>需要多设置一个变量标识该结点是 否是第一次出现在栈顶</em>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">postOrder2</span><span class="params">(BinTree *root)</span> <span class="comment">//非递归后序遍历</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    stack&lt;BTNode*&gt; s;</span><br><span class="line">    BinTree *p=root;</span><br><span class="line">    BTNode *temp;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>||!s.<span class="built_in">empty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span>(p!=<span class="literal">NULL</span>) <span class="comment">//沿左子树一直往下搜索，直至出现没有左子树的结点</span></span><br><span class="line">        &#123;</span><br><span class="line">            BTNode *btn=(BTNode *)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(BTNode));</span><br><span class="line">            btn-&gt;btnode=p;</span><br><span class="line">            btn-&gt;isFirst=<span class="literal">true</span>;</span><br><span class="line">            s.<span class="built_in">push</span>(btn);</span><br><span class="line">            p=p-&gt;lchild;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!s.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            temp=s.<span class="built_in">top</span>();</span><br><span class="line">            s.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="keyword">if</span>(temp-&gt;isFirst==<span class="literal">true</span>) <span class="comment">//表示是第一次出现在栈顶</span></span><br><span class="line">             &#123;</span><br><span class="line">                temp-&gt;isFirst=<span class="literal">false</span>;</span><br><span class="line">                s.<span class="built_in">push</span>(temp);</span><br><span class="line">                p=temp-&gt;btnode-&gt;rchild; <span class="comment">//访问其右子树</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="comment">//第二次出现在栈顶</span></span><br><span class="line">            &#123;</span><br><span class="line">                cout&lt;&lt;temp-&gt;btnode-&gt;data&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">                p=<span class="literal">NULL</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>第二种思路：要保证根结点在左孩子和右孩子访问之后才能访问，因此对于任一结点P，先将其入栈。如果P不存在左孩子和右孩子，则可以直接访问它；或者P存 在左孩子或者右孩子，但是其左孩子和右孩子都已被访问过了，则同样可以直接访问该结点。若非上述两种情况，则将P的右孩子和左孩子依次入栈，这样就保证了 每次取栈顶元素的时候，左孩子在右孩子前面被访问，左孩子和右孩子都在根结点前面被访问。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">postOrder3</span><span class="params">(BinTree *root)</span> <span class="comment">//非递归后序遍历</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    stack&lt;BinTree*&gt; s;</span><br><span class="line">    BinTree *cur; <span class="comment">//当前结点</span></span><br><span class="line">    BinTree *pre=<span class="literal">NULL</span>; <span class="comment">//前一次访问的结点</span></span><br><span class="line">    s.<span class="built_in">push</span>(root);</span><br><span class="line">    <span class="keyword">while</span>(!s.<span class="built_in">empty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        cur=s.<span class="built_in">top</span>();</span><br><span class="line">        <span class="keyword">if</span>((cur-&gt;lchild==<span class="literal">NULL</span>&amp;&amp;cur-&gt;rchild==<span class="literal">NULL</span>)||</span><br><span class="line">           (pre!=<span class="literal">NULL</span>&amp;&amp;(pre==cur-&gt;lchild||pre==cur-&gt;rchild)))</span><br><span class="line">        &#123;</span><br><span class="line">            cout&lt;&lt;cur-&gt;data&lt;&lt;<span class="string">&quot; &quot;</span>; <span class="comment">//如果当前结点没有孩子结点或者孩子节点都已被访问过</span></span><br><span class="line">              s.<span class="built_in">pop</span>();</span><br><span class="line">            pre=cur;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(cur-&gt;rchild!=<span class="literal">NULL</span>)</span><br><span class="line">                s.<span class="built_in">push</span>(cur-&gt;rchild);</span><br><span class="line">            <span class="keyword">if</span>(cur-&gt;lchild!=<span class="literal">NULL</span>)</span><br><span class="line">                s.<span class="built_in">push</span>(cur-&gt;lchild);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-3-4-层次遍历"><a href="#3-3-4-层次遍历" class="headerlink" title="3.3.4 层次遍历"></a>3.3.4 层次遍历</h4><p>二叉树遍历的核心问题：二维结构的线性化</p><ul><li>从结点访问其左、右儿子结点</li><li>访问左儿子后，右儿子结点需要一个存储结构（堆栈、队列）保存暂时不访问的结点</li></ul><p><img src="https://i.loli.net/2021/10/03/m4rj3PxYsC5gaek.png" alt="image-20211003192402457"></p><p><strong>层序遍历的实现</strong>：利用<strong>队列</strong>，遍历从根节点开始，首先将根结点入队，然后开始执行循环：结点出队、访问该结点、其左右儿子入队</p><p><img src="https://i.loli.net/2021/10/03/ke18YHGotfQIrhb.png" alt="image-20211003192702163"></p><h4 id="3-3-5-遍历二叉树算法的应用"><a href="#3-3-5-遍历二叉树算法的应用" class="headerlink" title="3.3.5 遍历二叉树算法的应用"></a>3.3.5 遍历二叉树算法的应用</h4><ul><li><p>输出二叉树中的叶子结点：在二叉树的遍历算法中增加检测结点“左右子树是否都为空”的判断语句。</p></li><li><p>求二叉树的高度：二叉树的高度为其左子树和右子树高度最大值+1</p><p><img src="https://i.loli.net/2021/10/03/AHuw3xQI4lf6pga.png" alt="image-20211003193034277"></p><p><img src="https://i.loli.net/2021/10/03/mrRnDlUBsH4KYAM.png" alt="image-20211003193100014"></p></li><li><p>二元运算表达式树及其遍历</p><p><img src="https://i.loli.net/2021/10/03/jlXLYTpcgxVA1nJ.png" alt="image-20211003193911595"></p></li><li><p>由两种遍历序列确定二叉树（<strong>必须要有中序序列</strong>）</p></li><li><p>判别两个二叉树是否同构</p><p><img src="https://i.loli.net/2021/10/05/KeXUScZgn3szuQ8.png" alt="image-20211005130722242"></p><p><img src="https://i.loli.net/2021/10/05/eNasRGHiCxMf67j.png" alt="image-20211005130750318"></p></li></ul><h3 id="3-4-二叉搜索树"><a href="#3-4-二叉搜索树" class="headerlink" title="3.4 二叉搜索树"></a>3.4 二叉搜索树</h3><h4 id="3-4-1-什么是二叉搜索树"><a href="#3-4-1-什么是二叉搜索树" class="headerlink" title="3.4.1 什么是二叉搜索树"></a>3.4.1 什么是二叉搜索树</h4><p>组织动态查找时，若将数据按照一定的规则在二叉树中进行存储，则每次的搜索的效率取决于树的深度$h(n)=log_2n+1$，即得到一种高效的算法。</p><p>二叉搜索树<code>BST,Binary Search Tree</code>，也称二叉排序树或二叉查找树。为一棵非空二叉树，且满足如下三条性质：</p><ul><li>非空左子树的所有键值小于其根结点的键值；</li><li>非空右子树的所有键值大于其根结点的键值；</li><li>左、右子树都是二叉搜索树。</li></ul><h4 id="3-4-2-二叉搜索树的抽象表示和实现"><a href="#3-4-2-二叉搜索树的抽象表示和实现" class="headerlink" title="3.4.2 二叉搜索树的抽象表示和实现"></a>3.4.2 二叉搜索树的抽象表示和实现</h4><p><strong>二叉搜索树的抽象表示</strong></p><p><img src="https://i.loli.net/2021/10/05/WGpoKJB1r8Hwtdf.png" alt="image-20211005132237855"></p><p><strong>二叉搜索树的查找操作Find</strong></p><ul><li><p>查找从根结点开始，如果树为空，返回<code>NULL</code></p></li><li><p>若搜索树非空，则根结点关键字和<code>X</code>进行比较，并进行不同处理：</p><ul><li>若<code>X</code>小于根结点键值，只需要在左子树中继续搜索</li><li>若<code>X</code>大于根结点键值，在右子树中进行继续搜索</li><li>若两者比较结果相等，搜索完成，返回指向此节点的指针</li></ul></li><li><p>递归实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Position <span class="title">Find</span><span class="params">(ElementType X,BinTree BST)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!BST)<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">if</span>(X&gt;BST-&gt;Data)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">Find</span>(X,BST-&gt;Right);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(X&lt;BST-&gt;Data)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">Find</span>(X,BST-&gt;Left);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>非递归（循环）实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Position <span class="title">IterFind</span><span class="params">(ElementType X,BinTree BST)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(BST)&#123;</span><br><span class="line">        <span class="keyword">if</span>(X&gt;BST-&gt;Data)</span><br><span class="line">            BST=BST-&gt;Right;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(X&lt;BST-&gt;Data)</span><br><span class="line">            BST=BST-&gt;Left;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> BST;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>查找最大和最小元素</strong></p><ul><li><p>最大元素一定在树的最右分枝的端结点上，最小元素一定在树的最左分枝的端结点上</p><p><img src="https://i.loli.net/2021/10/05/ueM9ht7maRIDbdz.png" alt="image-20211005133330268"></p></li><li><p>查找最大/小元素实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Position <span class="title">FindMin</span><span class="params">(BinTree BST)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!BST)<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(!BST-&gt;Left)</span><br><span class="line">        <span class="keyword">return</span> BST;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">FindMin</span>(BST-&gt;Left);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Position <span class="title">FindMax</span><span class="params">(BinTree BST)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(BST)</span><br><span class="line">        <span class="keyword">while</span>(BST-&gt;Right)BST=BST-&gt;Right;</span><br><span class="line">    <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>二叉搜索树的插入</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BinTree <span class="title">Insert</span><span class="params">(ElementType X,BinTree BST)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!BST)&#123;</span><br><span class="line">    <span class="comment">//若原树为空，生成并返回一个结点的二叉搜索树</span></span><br><span class="line">        BST=<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct TreeNode));</span><br><span class="line">        BST-&gt;Data=X;</span><br><span class="line">        BST-&gt;Left=BST-&gt;Right=<span class="literal">NULL</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span>(X&lt;BST-&gt;Data) <span class="comment">//递归插入左子树</span></span><br><span class="line">        BST-&gt;Left=<span class="built_in">Insert</span>(X,BST-&gt;Left);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(X&gt;BST-&gt;Data) <span class="comment">//递归插入右子树</span></span><br><span class="line">        BST-&gt;Right=<span class="built_in">Insert</span>(X,BST-&gt;Right);</span><br><span class="line">    <span class="comment">//X已经存在，查找到原址</span></span><br><span class="line">    <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>二叉搜索树的删除</strong></p><p>考虑三种情况：</p><ul><li><p>要删除的是叶结点：直接删除并修改其父节点指针——置为NULL</p></li><li><p>要删除的节点只有一个孩子结点：将其父结点的指针指向要删除的结点的孩子结点</p><p><img src="https://i.loli.net/2021/10/05/b7wca1zp8rB54Ed.png" alt="image-20211005135027150"></p></li><li><p>要删除的结点有左、右子树：用另一个结点替代被删除节点，通常是左子树的最大元素或右子树的最小元素</p><center class="half"><img src="https://i.loli.net/2021/10/05/wuAUOPrlg7yVZcS.png" alt="image-20211005135557796" style="zoom:50%;" /><img src="https://i.loli.net/2021/10/05/gfwtDoRcKVAY3O7.png" alt="image-20211005135622821" style="zoom:50%;" /><img src="https://i.loli.net/2021/10/05/NA7QDyCEPqBthLJ.png" alt="image-20211005140009082" style="zoom:50%;" /><img src="C:\Users\Farewellswind\AppData\Roaming\Typora\typora-user-images\image-20211005140052019.png" alt="image-20211005140052019" style="zoom:50%;" /></center></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BinTree <span class="title">Delete</span><span class="params">(ElementType X,BinTree BST)</span></span>&#123;</span><br><span class="line">    Position Tmp;</span><br><span class="line">    <span class="keyword">if</span>(!BST)<span class="built_in">printf</span>(<span class="string">&quot;Unfindable!&quot;</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(X&lt;BST-&gt;Data)</span><br><span class="line">        BST-&gt;Left=<span class="built_in">Delete</span>(X,BST-&gt;Left); <span class="comment">//左子树递归删除</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(X&gt;BST-&gt;Data)</span><br><span class="line">        BST-&gt;Right=<span class="built_in">Delete</span>(X,BST-&gt;Right); <span class="comment">//右子树递归删除</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(BST-&gt;Left &amp;&amp; BST-&gt;Right)&#123;</span><br><span class="line">        <span class="comment">//找到了被删除节点，且点有左右两个子结点</span></span><br><span class="line">        <span class="comment">//在右子树中找到最小元素</span></span><br><span class="line">        Tmp=<span class="built_in">FindMin</span>(BST-&gt;Right); </span><br><span class="line">        <span class="comment">//将找到的最小值赋值给被删除结点</span></span><br><span class="line">        BST-&gt;Data=Tmp-&gt;Data;</span><br><span class="line">        BST-&gt;Right=<span class="built_in">Delete</span>(BST-&gt;Data,BST-&gt;Right); </span><br><span class="line">        <span class="comment">//在删除节点的右子树中删除最小元素</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123; <span class="comment">//被删除结点有一个或无子结点</span></span><br><span class="line">        Tmp=BST;</span><br><span class="line">        <span class="keyword">if</span>(!BST-&gt;Left) <span class="comment">// 有右孩子或无子结点</span></span><br><span class="line">            BST=BST-&gt;Right;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(!BST-&gt;Right) <span class="comment">// 有左孩子或无子结点</span></span><br><span class="line">            BST=BST-&gt;Left;</span><br><span class="line">        <span class="built_in">free</span>(Tmp);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-4-3-判别是否是同一棵二叉搜索树"><a href="#3-4-3-判别是否是同一棵二叉搜索树" class="headerlink" title="3.4.3 判别是否是同一棵二叉搜索树"></a>3.4.3 判别是否是同一棵二叉搜索树</h4><ul><li><p>分别两个输入序列构造两棵二叉搜索树，然后判别是否相同</p></li><li><p>不建树的判别方法，根据序列，通过定位根节点位置进行判断</p><p><img src="https://i.loli.net/2021/10/05/BcZGRdhWjwHyQYN.png" alt="image-20211005152929723"></p></li><li><p>建一棵树，再判别其他序列是否与该树一致</p><ul><li><p>搜索树的表示</p><p><img src="https://i.loli.net/2021/10/05/N9UovASgp5hBjbM.png" alt="image-20211005153337874"></p></li><li><p>建搜索树</p><p><img src="https://i.loli.net/2021/10/05/cMNbiIVW6yDOhsQ.png" alt="image-20211005153350501"></p><p><img src="https://i.loli.net/2021/10/05/xCXqEcDa2nIUzrT.png" alt="image-20211005153424558"></p></li><li><p>判别一序列是否与搜索树$T$一致</p><p><img src="https://i.loli.net/2021/10/05/Pxuh8mvDQSdOrzj.png" alt="image-20211005153500459"></p><p><img src="https://i.loli.net/2021/10/05/8JG5IVShalLCWQA.png" alt="image-20211005153526915"></p><p><img src="https://i.loli.net/2021/10/05/KBk46Es9yJxVSri.png" alt="image-20211005153537810"></p></li></ul></li></ul><h3 id="3-5-平衡二叉树"><a href="#3-5-平衡二叉树" class="headerlink" title="3.5 平衡二叉树"></a>3.5 平衡二叉树</h3><h4 id="3-5-1-什么是平衡二叉树"><a href="#3-5-1-什么是平衡二叉树" class="headerlink" title="3.5.1 什么是平衡二叉树"></a>3.5.1 什么是平衡二叉树</h4><p>搜索树结点不同的插入次序，将导致不同的深度和平均查找长度<code>ASL</code>的不同</p><p><img src="https://i.loli.net/2021/10/05/A6q7bGdSuYc4gP9.png" alt="image-20211005141319219"></p><p>平衡因子<code>Balance Factor(BF)</code>：$BF(T)=h_L-h_R$，其中$h_L$和$h_R$分别为$T$的左子树和右子树的高度</p><p>平衡二叉树<code>Balanced Binary Tree</code>/<code>AVL Tree</code>：空树或者任一结点左右子树高度差的绝对值不超过1，即$|BF(T)|\le 1$</p><p><img src="https://i.loli.net/2021/10/05/opd5KiryJb3c2C1.png" alt="image-20211005141627202"></p><h4 id="3-5-2-平衡二叉树的调整"><a href="#3-5-2-平衡二叉树的调整" class="headerlink" title="3.5.2 平衡二叉树的调整"></a>3.5.2 平衡二叉树的调整</h4><p><img src="https://i.loli.net/2021/10/05/fKX2QoUetuHxi61.gif" alt="right rotate"  /><img src="https://i.loli.net/2021/10/05/ZmF5w6kNKu4fShd.gif" alt="left rotate"  /></p><ul><li><p>RR旋转：不平衡的“发现者”是A，“麻烦结点”在发现者<strong>右</strong>子树的<strong>右</strong>边，因此成为RR插入，需要RR旋转（右单旋）</p><p><img src="https://i.loli.net/2021/10/05/ONnJLiGt9lXsjUv.png" alt="image-20211005143113571"></p></li><li><p>LL旋转：不平衡的“发现者”是A，“麻烦结点”在发现者<strong>左</strong>子树的<strong>左</strong>边，因此称为LL插入，需要LL旋转（左单旋）</p><p><img src="https://i.loli.net/2021/10/05/acBSZzGjt6l7FbH.png" alt="image-20211005143352536"></p></li><li><p>LR旋转：不平衡的“发现者”是A，“麻烦结点”在<strong>左</strong>子树的<strong>右</strong>边，因此叫做LR插入，需要LR旋转</p><p><img src="https://i.loli.net/2021/10/05/LqBR3FzQpHaNPn9.png" alt="image-20211005143920004"></p></li><li><p>RL旋转：与LR旋转类似</p><p><img src="https://i.loli.net/2021/10/05/85soJvICwX4qgEU.png" alt="image-20211005144242923"></p></li><li><p>PS：有的时候插入元素即使不需要调整结构，也可能需要重新计算平衡因子</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">T key;</span><br><span class="line">Node&lt;T&gt;* lchild;</span><br><span class="line">Node&lt;T&gt;* rchild;</span><br><span class="line">Node&lt;T&gt;(T k) : <span class="built_in">key</span>(k), <span class="built_in">lchild</span>(<span class="literal">nullptr</span>), <span class="built_in">rchild</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AVLTree</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">Node&lt;T&gt;* root;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">AVLTree</span>() :<span class="built_in">root</span>(<span class="literal">nullptr</span>) &#123;&#125;;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">getRoot</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> root; &#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printTree</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">llRotation</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">lrRotation</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">rrRotation</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">rlRotation</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">balance</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">const</span> T&amp;)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">remove</span><span class="params">(Node&lt;T&gt;*, Node&lt;T&gt;*, T)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getDepth</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getBalanceFactor</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">findMin</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">findMax</span><span class="params">(Node&lt;T&gt;*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">fixUp</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Node&lt;T&gt;* <span class="title">find</span><span class="params">(Node&lt;T&gt;* node, T key)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">void</span> AVLTree&lt;T&gt;::<span class="built_in">printTree</span>() &#123;  <span class="comment">//层次遍历</span></span><br><span class="line">Node&lt;T&gt;* pos = root;  <span class="comment">//当前位置</span></span><br><span class="line">Node&lt;T&gt;* flag = root;  <span class="comment">//层末标识</span></span><br><span class="line"></span><br><span class="line">queue&lt;Node&lt;T&gt;*&gt; q;</span><br><span class="line">q.<span class="built_in">push</span>(root);  <span class="comment">//根节点入队</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;  <span class="comment">//队列非空</span></span><br><span class="line">Node&lt;T&gt;* node = q.<span class="built_in">front</span>();</span><br><span class="line">q.<span class="built_in">pop</span>();  <span class="comment">//弹出队首</span></span><br><span class="line">cout &lt;&lt; node-&gt;key &lt;&lt; <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (node-&gt;lchild != <span class="literal">nullptr</span>) &#123;  <span class="comment">//左孩子非空则入队</span></span><br><span class="line">q.<span class="built_in">push</span>(node-&gt;lchild);</span><br><span class="line">pos = node-&gt;lchild;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (node-&gt;rchild != <span class="literal">nullptr</span>) &#123;  <span class="comment">//右孩子非空则入队</span></span><br><span class="line">q.<span class="built_in">push</span>(node-&gt;rchild);</span><br><span class="line">pos = node-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (node == flag) &#123;  <span class="comment">//抵达层末</span></span><br><span class="line">flag = pos;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">void</span> AVLTree&lt;T&gt;::<span class="built_in">insert</span>(<span class="keyword">const</span> T&amp; key) &#123;</span><br><span class="line">Node&lt;T&gt;* node = <span class="keyword">new</span> Node&lt;T&gt;(key);</span><br><span class="line"><span class="keyword">if</span> (root == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">root = node;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">Node&lt;T&gt;* pos = root;</span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;  <span class="comment">//查找插入位置</span></span><br><span class="line"><span class="keyword">if</span> (node-&gt;key &lt; pos-&gt;key) &#123;</span><br><span class="line"><span class="keyword">if</span> (pos-&gt;lchild == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">pos-&gt;lchild = node;</span><br><span class="line"><span class="built_in">fixUp</span>();</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;   <span class="comment">//end if</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">pos = pos-&gt;lchild;</span><br><span class="line">&#125;  <span class="comment">//end if</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (node-&gt;key &gt; pos-&gt;key) &#123;</span><br><span class="line"><span class="keyword">if</span> (pos-&gt;rchild == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">pos-&gt;rchild = node;</span><br><span class="line"><span class="built_in">fixUp</span>();</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;  <span class="comment">//end if</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">pos = pos-&gt;rchild;</span><br><span class="line">&#125;  <span class="comment">//end if</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span>;  <span class="comment">//树中已有此节点则无操作</span></span><br><span class="line">&#125;  <span class="comment">//end while</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">int</span> AVLTree&lt;T&gt;::<span class="built_in">getDepth</span>(Node&lt;T&gt;* node) &#123;</span><br><span class="line"><span class="keyword">if</span> (node == <span class="literal">nullptr</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">max</span>(<span class="built_in">getDepth</span>(node-&gt;lchild), <span class="built_in">getDepth</span>(node-&gt;rchild)) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">int</span> AVLTree&lt;T&gt;::<span class="built_in">getBalanceFactor</span>(Node&lt;T&gt;* node) &#123;  <span class="comment">//平衡因子 = 左子树高-右子树高</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">getDepth</span>(node-&gt;lchild) - <span class="built_in">getDepth</span>(node-&gt;rchild);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">void</span> AVLTree&lt;T&gt;::<span class="built_in">balance</span>(Node&lt;T&gt;* node) &#123;</span><br><span class="line"><span class="keyword">int</span> bf = <span class="built_in">getBalanceFactor</span>(node);</span><br><span class="line"><span class="keyword">if</span> (bf &gt; <span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getBalanceFactor</span>(node-&gt;lchild) &gt; <span class="number">0</span>)</span><br><span class="line">root = <span class="built_in">llRotation</span>(node);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">root = <span class="built_in">lrRotation</span>(node);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (bf &lt; <span class="number">-1</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getBalanceFactor</span>(node-&gt;rchild) &gt; <span class="number">0</span>)</span><br><span class="line">root = <span class="built_in">rlRotation</span>(node);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">root = <span class="built_in">rrRotation</span>(node);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//LL</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">llRotation</span>(Node&lt;T&gt;* node) &#123;  <span class="comment">//插入节点在左子树左边，右旋</span></span><br><span class="line">Node&lt;T&gt;* temp = node-&gt;lchild;</span><br><span class="line">node-&gt;lchild = temp-&gt;rchild;</span><br><span class="line">temp-&gt;rchild = node;</span><br><span class="line"><span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//LR</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">lrRotation</span>(Node&lt;T&gt;* node) &#123;  <span class="comment">//插入节点在左子树右边</span></span><br><span class="line">Node&lt;T&gt;* temp = node-&gt;lchild;</span><br><span class="line">node-&gt;lchild = <span class="built_in">rrRotation</span>(temp);</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">llRotation</span>(node);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//RL</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">rlRotation</span>(Node&lt;T&gt;* node) &#123;  <span class="comment">//插入节点在右子树左边</span></span><br><span class="line">Node&lt;T&gt;* temp = node-&gt;rchild;</span><br><span class="line">node-&gt;rchild = <span class="built_in">llRotation</span>(temp);</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">rrRotation</span>(node);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//RR</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">rrRotation</span>(Node&lt;T&gt;* node) &#123;  <span class="comment">//插入节点在右子树右边，左旋</span></span><br><span class="line">Node&lt;T&gt;* temp = node-&gt;rchild;</span><br><span class="line">node-&gt;rchild = temp-&gt;lchild;</span><br><span class="line">temp-&gt;lchild = node;</span><br><span class="line"><span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">bool</span> AVLTree&lt;T&gt;::<span class="built_in">remove</span>(Node&lt;T&gt;* node, Node&lt;T&gt;* parent, T key) &#123;</span><br><span class="line">Node&lt;T&gt;* temp = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">if</span> (node == <span class="literal">nullptr</span>)  <span class="comment">// 未找到目标节点</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (key &lt; node-&gt;key)</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;lchild, node, key);</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (key &gt; node-&gt;key)</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;rchild, node, key);</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (node-&gt;lchild &amp;&amp; node-&gt;rchild) &#123;  <span class="comment">//删除节点有左子树也有右子树</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getDepth</span>(node-&gt;lchild) &gt; <span class="built_in">getDepth</span>(node-&gt;rchild)) &#123;  <span class="comment">//左子树高，前驱替代</span></span><br><span class="line">temp = <span class="built_in">findMax</span>(node-&gt;lchild);</span><br><span class="line">node-&gt;key = temp-&gt;key;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;lchild,node, node-&gt;key);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;  <span class="comment">//右子树不比左子树矮，后驱替代</span></span><br><span class="line">temp = <span class="built_in">findMin</span>(node-&gt;rchild);</span><br><span class="line">node-&gt;key = temp-&gt;key;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;rchild, node, node-&gt;key);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> ((node-&gt;lchild &amp;&amp; node-&gt;rchild == <span class="literal">nullptr</span>)) &#123;  <span class="comment">//删除节点有左孩子无右孩子</span></span><br><span class="line">temp = <span class="built_in">findMax</span>(node-&gt;lchild);</span><br><span class="line">node-&gt;key = temp-&gt;key;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;lchild, node, node-&gt;key);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (node-&gt;rchild &amp;&amp; node-&gt;lchild == <span class="literal">nullptr</span>) &#123;  <span class="comment">//删除节点有右孩子无左孩子</span></span><br><span class="line">temp = <span class="built_in">findMin</span>(node-&gt;rchild);</span><br><span class="line">node-&gt;key = temp-&gt;key;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">remove</span>(node-&gt;rchild, node, node-&gt;key);</span><br><span class="line">&#125;  <span class="comment">//end if</span></span><br><span class="line"><span class="keyword">else</span> &#123;  <span class="comment">//删除节点最终递归到删除叶子节点</span></span><br><span class="line"><span class="keyword">if</span> (node == parent-&gt;lchild)  <span class="comment">//父节点指针置空</span></span><br><span class="line">parent-&gt;lchild = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">parent-&gt;rchild = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">delete</span> node;  <span class="comment">//释放子节点</span></span><br><span class="line">node = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">fixUp</span>();</span><br><span class="line">&#125;</span><br><span class="line">&#125;  <span class="comment">//end else</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="keyword">void</span> AVLTree&lt;T&gt;::<span class="built_in">fixUp</span>() &#123;</span><br><span class="line">Node&lt;T&gt;* temp = <span class="keyword">this</span>-&gt;root;  <span class="comment">//自顶向下调整树</span></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>)  <span class="comment">//寻找失衡的节点</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getBalanceFactor</span>(temp) == <span class="number">2</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">fabs</span>(<span class="built_in">getBalanceFactor</span>(temp-&gt;lchild)) == <span class="number">1</span>)</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">temp = temp-&gt;lchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">getBalanceFactor</span>(temp) == <span class="number">-2</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">fabs</span>(<span class="built_in">getBalanceFactor</span>(temp-&gt;rchild)) == <span class="number">1</span>)</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">temp = temp-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">balance</span>(temp);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">find</span>(Node&lt;T&gt;* node, T key) &#123;</span><br><span class="line"><span class="keyword">while</span> (node != <span class="literal">nullptr</span> &amp;&amp; key != node-&gt;key) &#123;  <span class="comment">//迭代查找</span></span><br><span class="line"><span class="keyword">if</span> (key &lt; node-&gt;key)</span><br><span class="line">node = node-&gt;lchild;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">node = node-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (node == <span class="literal">nullptr</span>)</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;Element &quot;</span> &lt;&lt; key &lt;&lt; <span class="string">&quot; doesn&#x27;t exist!&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">cout &lt;&lt; <span class="string">&quot;Element &quot;</span> &lt;&lt; key &lt;&lt; <span class="string">&quot; exists.&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">findMax</span>(Node&lt;T&gt;* node) &#123;</span><br><span class="line"><span class="keyword">if</span> (node != <span class="literal">nullptr</span>) &#123;</span><br><span class="line"><span class="keyword">while</span> (node-&gt;rchild)</span><br><span class="line">node = node-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line">Node&lt;T&gt;* AVLTree&lt;T&gt;::<span class="built_in">findMin</span>(Node&lt;T&gt;* node) &#123;</span><br><span class="line"><span class="keyword">if</span> (node != <span class="literal">nullptr</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (node-&gt;lchild == <span class="literal">nullptr</span>)  <span class="comment">//左孩子为空，当前节点已是最左下</span></span><br><span class="line"><span class="keyword">return</span> node;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">findMin</span>(node-&gt;lchild);  <span class="comment">//左孩子不为空，往左子树遍历</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nullptr</span>;  <span class="comment">//空树返回nullptr</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> arr[]&#123; <span class="number">7</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">6</span>&#125;;<span class="comment">//ll:738512建树;rr:7385129删除2;rl:7385124删除4;lr:748516建树</span></span><br><span class="line">AVLTree&lt;<span class="keyword">int</span>&gt; avl;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">6</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">avl.<span class="built_in">insert</span>(arr[i]);</span><br><span class="line">&#125;</span><br><span class="line">avl.<span class="built_in">printTree</span>();</span><br><span class="line">avl.<span class="built_in">find</span>(avl.<span class="built_in">getRoot</span>(),<span class="number">8</span>);</span><br><span class="line">avl.<span class="built_in">remove</span>(avl.<span class="built_in">getRoot</span>(), <span class="literal">nullptr</span>, <span class="number">8</span>);</span><br><span class="line">avl.<span class="built_in">printTree</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://www.cnblogs.com/kite97/p/13431904.html">Above Code from [kite97]</a></p><h3 id="3-6-堆"><a href="#3-6-堆" class="headerlink" title="3.6 堆"></a>3.6 堆</h3><h4 id="3-6-1-什么是堆"><a href="#3-6-1-什么是堆" class="headerlink" title="3.6.1 什么是堆"></a>3.6.1 什么是堆</h4><p>优先队列<code>Priority Queue</code>：特殊的队列，取出元素的顺序是按照元素的优先权（关键字）大小，而不是元素进入队列的先后顺序。</p><p>堆<code>Heap</code>即为优先队列的完全二叉树表示，堆的两个特性：</p><ul><li>结构性：用数组表示的<strong>完全二叉树</strong>；</li><li>有序性：任一结点的关键字是其子树所有结点的最大值（或最小值）<ul><li>最大堆<code>MaxHeap</code>也称“大顶堆”：最大值</li><li>最小堆<code>MinHeap</code>也称“小顶堆”：最小值</li></ul></li></ul><p><img src="https://i.loli.net/2021/10/05/CkGU6YNpHtmF5BO.png" alt="image-20211005194016661"></p><h4 id="3-6-2-堆的表示和实现"><a href="#3-6-2-堆的表示和实现" class="headerlink" title="3.6.2 堆的表示和实现"></a>3.6.2 堆的表示和实现</h4><p><strong>堆抽象数据结构描述</strong></p><p><img src="https://i.loli.net/2021/10/05/sgDbZMKTGiHnUrp.png" alt="image-20211005194052919"></p><p><strong>最大堆的操作：创建、插入、删除、维护</strong></p><ul><li><p>定义</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">HNode</span> *<span class="title">Heap</span>;</span> <span class="comment">/* 堆的类型定义 */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">HNode</span> &#123;</span></span><br><span class="line">    ElementType *Data; <span class="comment">/* 存储元素的数组 */</span></span><br><span class="line">    <span class="keyword">int</span> Size;          <span class="comment">/* 堆中当前元素个数 */</span></span><br><span class="line">    <span class="keyword">int</span> Capacity;      <span class="comment">/* 堆的最大容量 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> Heap MaxHeap; <span class="comment">/* 最大堆 */</span></span><br><span class="line"><span class="keyword">typedef</span> Heap MinHeap; <span class="comment">/* 最小堆 */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXDATA 1000  <span class="comment">/* 该值应根据具体情况定义为大于堆中所有可能元素的值 */</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MaxHeap <span class="title">CreateHeap</span><span class="params">( <span class="keyword">int</span> MaxSize )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 创建容量为MaxSize的空的最大堆 */</span></span><br><span class="line"></span><br><span class="line">    MaxHeap H = (MaxHeap)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct HNode));</span><br><span class="line">    H-&gt;Data = (ElementType *)<span class="built_in">malloc</span>((MaxSize+<span class="number">1</span>)*<span class="built_in"><span class="keyword">sizeof</span></span>(ElementType));</span><br><span class="line">    H-&gt;Size = <span class="number">0</span>;</span><br><span class="line">    H-&gt;Capacity = MaxSize;</span><br><span class="line">    H-&gt;Data[<span class="number">0</span>] = MAXDATA; <span class="comment">/* 定义&quot;哨兵&quot;为大于堆中所有可能元素的值*/</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> H;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>插入</p><p>通过一个示例来理解堆插入的过程，将<code>16</code>插入到下面的堆中</p><center class="half"><img src="https://upload-images.jianshu.io/upload_images/4064751-51fd43a2d2191488.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:80%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-7dd89da71927acb8.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:80%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-785a7a6cd104f775.png?imageMogr2/auto-orient/strip|imageView2/2/w/204/format/webp" alt="img" style="zoom:80%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-d7dae273e1f5a0ba.png?imageMogr2/auto-orient/strip|imageView2/2/w/192/format/webp" alt="img" style="zoom:80%;" /></center>  `16` 被添加最后一行的第一个空位。不行的是，现在堆属性不满足，因为 `2` 在 `16` 的上面，我们需要将大的数字在上面（这是一个最大堆）为了恢复堆属性，我们需要交换 `16` 和 `2`。现在还没有完成，因为 `10` 也比 `16` 小。我们继续交换我们的插入元素和它的父节点，直到它的父节点比它大或者我们到达树的顶部。这就是所谓的 **shift-up**，每一次插入操作后都需要进行。它将一个太大或者太小的数字“浮起”到树的顶部。<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsFull</span><span class="params">( MaxHeap H )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (H-&gt;Size == H-&gt;Capacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//将新增结点插入到从其父结点到根节点的有序序列中</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Insert</span><span class="params">( MaxHeap H, ElementType X )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 将元素X插入最大堆H，其中H-&gt;Data[0]已经定义为哨兵 */</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> ( <span class="built_in">IsFull</span>(H) ) &#123; </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;最大堆已满&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    i = ++H-&gt;Size; <span class="comment">/* i指向插入后堆中的最后一个元素的位置 */</span></span><br><span class="line">    <span class="comment">//哨兵起到一个边界判定的作用，若是没有在data[0]设置哨兵元素则判定条件应为 H-&gt;Data[i/2] &lt; X &amp;&amp; i&gt;1</span></span><br><span class="line">    <span class="keyword">for</span> ( ; H-&gt;Data[i/<span class="number">2</span>] &lt; X; i/=<span class="number">2</span> ) <span class="comment">//当父结点小于当前结点时进行交换</span></span><br><span class="line">        H-&gt;Data[i] = H-&gt;Data[i/<span class="number">2</span>]; <span class="comment">/* 上滤X */</span></span><br><span class="line">    H-&gt;Data[i] = X; <span class="comment">/* 将X插入 */</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>删除</p><center class="half"><img src="https://upload-images.jianshu.io/upload_images/4064751-7eb32c6486a44f73.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:75%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-71783aa7bd24a51f.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:75%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-c28b15dc371b8e97.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:75%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-bfc42e89b5411f9b.png?imageMogr2/auto-orient/strip|imageView2/2/w/190/format/webp" alt="img" style="zoom:75%;" /><img src="https://upload-images.jianshu.io/upload_images/4064751-8b04275965f88961.png?imageMogr2/auto-orient/strip|imageView2/2/w/208/format/webp" alt="img" style="zoom:75%;" /></center><p>我们将这个树中的 <code>10</code> 删除，但在删除后顶部空出了一个节点，很自然的我们要从下面找到合适的结点来维持堆的属性。</p><p>当插入节点的时候，我们将新的值返给数组的尾部。现在我们来做相反的事情：我们取出数组中的最后一个元素，将它放到树的顶部，然后再修复堆属性。</p><p>现在来看怎么 <strong>shift-down</strong>。为了保持最大堆的堆属性，我们需要树的顶部是最大的数据。现在有两个数字可用于交换 <code>7</code> 和 <code>2</code>。我们选择这两者中的较大者称为最大值放在树的顶部，所以交换 <code>7</code> 和 <code>1</code>。</p><p>继续堆化直到该节点没有任何子节点或者它比两个子节点都要大为止。对于我们的堆，我们只需要再有一次交换就恢复了堆属性。</p><p>实质的核心思想就是：已知左子树是一个堆，右子树也是一个堆，对于一个新的元素，要如何将其调整为一个堆。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ERROR -1 <span class="comment">/* 错误标识应根据具体情况定义为堆中不可能出现的元素值 */</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsEmpty</span><span class="params">( MaxHeap H )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (H-&gt;Size == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ElementType <span class="title">DeleteMax</span><span class="params">( MaxHeap H )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 从最大堆H中取出键值为最大的元素，并删除一个结点 */</span></span><br><span class="line">    <span class="keyword">int</span> Parent, Child;</span><br><span class="line">    ElementType MaxItem, X;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( <span class="built_in">IsEmpty</span>(H) ) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;最大堆已为空&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MaxItem = H-&gt;Data[<span class="number">1</span>]; <span class="comment">/* 取出根结点存放的最大值 */</span></span><br><span class="line">    <span class="comment">/* 用最大堆中最后一个元素从根结点开始向上过滤下层结点 */</span></span><br><span class="line">    X = H-&gt;Data[H-&gt;Size--]; <span class="comment">/* 取最后一个结点，且注意当前堆的规模要减小 */</span></span><br><span class="line">    <span class="comment">//将最后一个元素假定为最大值，之后找出其左右儿子中较大的那个替换位置</span></span><br><span class="line">    <span class="comment">//之后重复操作到找不到左右儿子，则此时堆的顺序维护完成</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>( Parent=<span class="number">1</span>; Parent*<span class="number">2</span>&lt;=H-&gt;Size; Parent=Child ) &#123;</span><br><span class="line">        Child = Parent * <span class="number">2</span>; <span class="comment">//Child先指向左儿子</span></span><br><span class="line">        <span class="keyword">if</span>( (Child!=H-&gt;Size) <span class="comment">//child!=H-&gt;Size意味着一定存在右儿子</span></span><br><span class="line">           &amp;&amp; (H-&gt;Data[Child]&lt;H-&gt;Data[Child+<span class="number">1</span>]) )</span><br><span class="line">            Child++;  <span class="comment">/* Child指向左右子结点的较大者 */</span></span><br><span class="line">        <span class="keyword">if</span>( X &gt;= H-&gt;Data[Child] ) <span class="keyword">break</span>; <span class="comment">/* 找到了合适位置 */</span></span><br><span class="line">        <span class="keyword">else</span>  <span class="comment">/* 下滤X */</span></span><br><span class="line">            H-&gt;Data[Parent] = H-&gt;Data[Child];</span><br><span class="line">    &#125;</span><br><span class="line">    H-&gt;Data[Parent] = X;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MaxItem;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li><li><p>给定n个元素进行创建</p><ul><li>方法一：通过插入操作，将N个元素一个个相继插入到一个初始为空的堆中去，其时间代价最大为$O(Nlog{N})$</li><li>方法二：在线性时间复杂度下建立最大堆。<ul><li>将N个元素按照输入顺序存入，先满足完全二叉树的结构特性；</li><li>调整各结点位置，以满足最大堆的有序特性。调整堆时采用删除操作中的方法进行调整，但从下往上进行调整，满足左右子树为堆+1结点的条件。故从最后一个非叶子节点也即最后一个父结点进行调整。</li></ul></li></ul>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*----------- 建造最大堆 -----------*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">PercDown</span><span class="params">( MaxHeap H, <span class="keyword">int</span> p )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 下滤：将H中以H-&gt;Data[p]为根的子堆调整为最大堆 */</span></span><br><span class="line">    <span class="keyword">int</span> Parent, Child;</span><br><span class="line">    ElementType X;</span><br><span class="line"></span><br><span class="line">    X = H-&gt;Data[p]; <span class="comment">/* 取出根结点存放的值 */</span></span><br><span class="line">    <span class="keyword">for</span>( Parent=p; Parent*<span class="number">2</span>&lt;=H-&gt;Size; Parent=Child ) &#123;</span><br><span class="line">        Child = Parent * <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>( (Child!=H-&gt;Size) &amp;&amp; (H-&gt;Data[Child]&lt;H-&gt;Data[Child+<span class="number">1</span>]) )</span><br><span class="line">            Child++;  <span class="comment">/* Child指向左右子结点的较大者 */</span></span><br><span class="line">        <span class="keyword">if</span>( X &gt;= H-&gt;Data[Child] ) <span class="keyword">break</span>; <span class="comment">/* 找到了合适位置 */</span></span><br><span class="line">        <span class="keyword">else</span>  <span class="comment">/* 下滤X */</span></span><br><span class="line">            H-&gt;Data[Parent] = H-&gt;Data[Child];</span><br><span class="line">    &#125;</span><br><span class="line">    H-&gt;Data[Parent] = X;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BuildHeap</span><span class="params">( MaxHeap H )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 调整H-&gt;Data[]中的元素，使满足最大堆的有序性  */</span></span><br><span class="line">  <span class="comment">/* 这里假设所有H-&gt;Size个元素已经存在H-&gt;Data[]中 */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 从最后一个结点的父节点（也即最后一个非叶子结点）开始，到根结点1 */</span></span><br><span class="line">    <span class="keyword">for</span>( i = H-&gt;Size/<span class="number">2</span>; i&gt;<span class="number">0</span>; i-- )</span><br><span class="line">        <span class="built_in">PercDown</span>( H, i );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-7-哈夫曼树和哈夫曼编码"><a href="#3-7-哈夫曼树和哈夫曼编码" class="headerlink" title="3.7 哈夫曼树和哈夫曼编码"></a>3.7 哈夫曼树和哈夫曼编码</h3><h4 id="3-7-1-什么是哈夫曼树"><a href="#3-7-1-什么是哈夫曼树" class="headerlink" title="3.7.1 什么是哈夫曼树"></a>3.7.1 什么是哈夫曼树</h4><p>带权路径长度<code>WPL</code>：设二叉树有n个叶子结点，每个叶子结点带有权值$W_k$，从根结点到每个叶子结点的长度为$l_k$，则每个叶子结点的带权路径长度之和就是：$WPL=\sum^n_{k=1}w_kl_k$</p><p>最优二叉树/哈夫曼树：WPL最小的二叉树</p><h4 id="3-7-2-哈夫曼树的构造"><a href="#3-7-2-哈夫曼树的构造" class="headerlink" title="3.7.2 哈夫曼树的构造"></a>3.7.2 哈夫曼树的构造</h4><p>每次把权值最小的两棵二叉树合并（利用构造最小堆可以很好地实现）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">TreeNode</span> *<span class="title">HuffmanTree</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TreeNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> Weight;</span><br><span class="line">    HuffmanTree Left,Right;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">HuffmanTree <span class="title">Huffman</span><span class="params">(MinHeap H)</span></span>&#123;</span><br><span class="line">    <span class="comment">//假设H-&gt;Size个权值已经存在H-&gt;Elements[]-&gt;Weight里</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    HuffmanTree T;</span><br><span class="line">    <span class="built_in">BuildMinHeap</span>(H); <span class="comment">//将H-&gt;Elements[]按照权值调整为最小堆</span></span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;H-&gt;Size;i++)&#123; <span class="comment">//做H-&gt;Size-1次合并</span></span><br><span class="line">        T=<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct TreeNode));</span><br><span class="line">        T-&gt;Left=<span class="built_in">DeleteMin</span>(H);</span><br><span class="line">        T-&gt;Right=<span class="built_in">DeleteMin</span>(H); <span class="comment">//从最小堆中取出两个最小的节点作为左右节点</span></span><br><span class="line">        T-&gt;Weight=T-&gt;Left-&gt;Weight+T-&gt;Right-&gt;Weight; <span class="comment">//重新计算权值</span></span><br><span class="line">        <span class="built_in">Insert</span>(H,T); <span class="comment">//将新的T插入到最小堆中</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-7-3-哈夫曼树的特点"><a href="#3-7-3-哈夫曼树的特点" class="headerlink" title="3.7.3 哈夫曼树的特点"></a>3.7.3 哈夫曼树的特点</h4><ul><li>没有度为1的结点</li><li>n个叶子结点的哈夫曼树共有2n-1个结点</li><li>哈夫曼树的任意非叶节点的左右子树交换后仍是哈夫曼树</li><li>对同一组权值${w_1,w_2,\dots,w_n}$，存在不同构的哈夫曼树，但WPL值是一样的</li></ul><h4 id="3-7-4-哈夫曼编码"><a href="#3-7-4-哈夫曼编码" class="headerlink" title="3.7.4 哈夫曼编码"></a>3.7.4 哈夫曼编码</h4><p>给定一段字符串，使用哈夫曼编码进行编码（不等长编码）可以使得该字符串的编码存储空间最小</p><p>在不等长编码中，为避免二义性，需要满足前缀码<code>prefix code</code>要求（任何字符的编码都不是另一字符编码的前缀），用二叉树表示编码即可完美避免二义性</p><h3 id="3-8-集合及运算"><a href="#3-8-集合及运算" class="headerlink" title="3.8 集合及运算"></a>3.8 集合及运算</h3><h4 id="3-8-1-集合的表示"><a href="#3-8-1-集合的表示" class="headerlink" title="3.8.1 集合的表示"></a>3.8.1 集合的表示</h4><ul><li><p>集合运算：交、并、补、差，判定一个元素是否属于某一集合</p></li><li><p>并查集：集合并、查某元素属于什么集合</p></li><li><p>并查集问题中使用树的结构存储集合，树的每一个结点代表一个集合元素</p><p><img src="https://i.loli.net/2021/10/05/6sCTXAVmzJc9Wvg.png" alt="image-20211005211118299"></p></li></ul><h4 id="3-8-2-并查集的实现"><a href="#3-8-2-并查集的实现" class="headerlink" title="3.8.2 并查集的实现"></a>3.8.2 并查集的实现</h4><ul><li><p>采用数组存储形式</p><p><img src="https://i.loli.net/2021/10/05/AETuNp6BUaklXHJ.png" alt="image-20211005211442798"></p></li><li><p>查找某个元素所在的集合（用根结点表示）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXN 1000                  <span class="comment">/* 集合最大元素个数 */</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElementType;           <span class="comment">/* 默认元素可以用非负整数表示 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> SetName;               <span class="comment">/* 默认用根结点的下标作为集合名称 */</span></span><br><span class="line"><span class="keyword">typedef</span> ElementType SetType[MAXN]; <span class="comment">/* 假设集合元素下标从0开始 */</span></span><br><span class="line"></span><br><span class="line"><span class="function">SetName <span class="title">Find</span><span class="params">( SetType S, ElementType X )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 默认集合元素全部初始化为-1 */</span></span><br><span class="line">    <span class="keyword">if</span> ( S[X] &lt; <span class="number">0</span> ) <span class="comment">/* 找到集合的根 */</span></span><br><span class="line">        <span class="keyword">return</span> X;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> S[X] = <span class="built_in">Find</span>( S, S[X] ); <span class="comment">/* 路径压缩 */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//循环实现</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Find</span><span class="params">(SetType S[],ElementType X)</span></span>&#123;</span><br><span class="line">    <span class="comment">//在数组S中查找值为X的元素所对应的集合</span></span><br><span class="line">    <span class="comment">//MaxSize是全局变量，为数组S的最大长度</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;MaxSize &amp;&amp; S[i].Data!=X;i++);</span><br><span class="line">    <span class="keyword">if</span>(i&gt;=MaxSize)<span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">//未找到X，返回-1</span></span><br><span class="line">    <span class="keyword">for</span>(;S[i].Parent&gt;=<span class="number">0</span>;i=S[i].Parent);</span><br><span class="line">    <span class="keyword">return</span> i; <span class="comment">//找到x所属集合，返回树根结点在数组S中的下标</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>集合的并运算</p><ul><li>分别找到X1和X2两个元素所在的集合树的根结点</li><li>如果他们不同根，则将其中一个根节点的父结点指针设置为另一个根结点的数组下标</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Union</span><span class="params">(SetType S[],ElementType X1,ElementType X2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> Root1,Root2;</span><br><span class="line">    Root1=<span class="built_in">Find</span>(S,X1);</span><br><span class="line">    Root2=<span class="built_in">Find</span>(S,X2);</span><br><span class="line">    <span class="keyword">if</span>(Root1!=Root2)S[Root2].Parent=Root1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//这种固定将root2挂在root1下的方式会导致树的深度越来越深，影响find的效率</span></span><br><span class="line"><span class="comment">//于是通过负数判定是否为根结点，而负数的绝对值则表示节点的个数，通过简单的修改，在判断时对两个集合的个数进行修改即可更具效率</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Union</span><span class="params">( SetType S, SetName Root1, SetName Root2 )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 这里默认Root1和Root2是不同集合的根结点 */</span></span><br><span class="line">    <span class="comment">/* 保证小集合并入大集合 */</span></span><br><span class="line">    <span class="keyword">if</span> ( S[Root2] &lt; S[Root1] ) &#123; <span class="comment">/* 如果集合2比较大 */</span></span><br><span class="line">        S[Root2] += S[Root1];     <span class="comment">/* 集合1并入集合2  */</span></span><br><span class="line">        S[Root1] = Root2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;                         <span class="comment">/* 如果集合1比较大 */</span></span><br><span class="line">        S[Root1] += S[Root2];     <span class="comment">/* 集合2并入集合1  */</span></span><br><span class="line">        S[Root2] = Root1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="第四章-图"><a href="#第四章-图" class="headerlink" title="第四章 图"></a>第四章 图</h2><h3 id="3-1-什么是图"><a href="#3-1-什么是图" class="headerlink" title="3.1 什么是图"></a>3.1 什么是图</h3><p>图<code>Graph</code>表示多对多的关系，包含一组顶点（通常用$V(Vertex)$）表示顶点集合，一组边（通常用$E(Edge)$）表示边的集合：</p><ul><li>边是顶点对：$(v,w)\in E$，其中$v,w\in V$</li><li>有向边$&lt;v,w&gt;$表示从$v$指向$w$的边（单向）</li><li>不考虑重边和自回路</li></ul><p><strong>抽象数据类型定义</strong></p><p><img src="https://i.loli.net/2021/10/06/UhvN78oTbS3OncG.png" alt="image-20211006100951316"></p><p><strong>图的表示</strong></p><ul><li><p>邻接矩阵$G[N][N]$，$N$个定点从0到$N-1$的编号<br>$$<br>G[i][j]=\left{<br>\begin{aligned}<br>1 &amp;&amp; 若&lt;v_i,v_j&gt;是G中的边 \<br>0 &amp;&amp; 否则<br>\end{aligned}<br>\right.<br>$$<br><img src="https://i.loli.net/2021/10/06/6MAHl5WPEkhK1Lt.png" alt="image-20211006101530542"></p><p>对于无向图，可以使用一个长度为$N(N+1)/2$的一维数组$A$存储${G_{00},G_{10},G_{11},\dots,G_{n-1 \ 0},\dots,G_{n-1 \ n-1}}$，则$G_{ij}$在$A$中而对应的下标是$(i*(i+1)/2+j)$</p><p>邻接矩阵的优点：</p><ul><li>简单直观好理解</li><li>方便检查任意一队顶点间是否存在边</li><li>方便找任一顶点的所有“邻接点”（有边直接相连的顶点）</li><li>方便计算任一顶点的“度”（从该点发出的边数为“出度”，指向该点的边数为“入度”）。无向图的度为对应行/列的非零元素个数；有向图对应行非零元素个数为出度，对应列非零元素个数为入度</li></ul><p>邻接矩阵的缺点：</p><ul><li>浪费空间：对于稀疏图（点很多，边很少）有大量无效元素，而对于稠密图（特别是完全图）还是很合算的</li><li>浪费时间：统计稀疏图一共有多少条边</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 图的邻接矩阵表示法 */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxVertexNum 100    <span class="comment">/* 最大顶点数设为100 */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INFINITY 65535        <span class="comment">/* ∞设为双字节无符号整数的最大值65535*/</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> Vertex;         <span class="comment">/* 用顶点下标表示顶点,为整型 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> WeightType;        <span class="comment">/* 边的权值设为整型 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> DataType;        <span class="comment">/* 顶点存储的数据类型设为字符型 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 边的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ENode</span> *<span class="title">PtrToENode</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ENode</span>&#123;</span></span><br><span class="line">    Vertex V1, V2;      <span class="comment">/* 有向边&lt;V1, V2&gt; */</span></span><br><span class="line">    WeightType Weight;  <span class="comment">/* 权重 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> PtrToENode Edge;</span><br><span class="line">       </span><br><span class="line"><span class="comment">/* 图结点的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">GNode</span> *<span class="title">PtrToGNode</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> Nv;  <span class="comment">/* 顶点数 */</span></span><br><span class="line">    <span class="keyword">int</span> Ne;  <span class="comment">/* 边数   */</span></span><br><span class="line">    WeightType G[MaxVertexNum][MaxVertexNum]; <span class="comment">/* 邻接矩阵 */</span></span><br><span class="line">    DataType Data[MaxVertexNum];      <span class="comment">/* 存顶点的数据 */</span></span><br><span class="line">    <span class="comment">/* 注意：很多情况下，顶点无数据，此时Data[]可以不用出现 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> PtrToGNode MGraph; <span class="comment">/* 以邻接矩阵存储的图类型 */</span></span><br><span class="line"></span><br><span class="line"><span class="function">MGraph <span class="title">CreateGraph</span><span class="params">( <span class="keyword">int</span> VertexNum )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 初始化一个有VertexNum个顶点但没有边的图 */</span></span><br><span class="line">    Vertex V, W;</span><br><span class="line">    MGraph Graph;</span><br><span class="line">    </span><br><span class="line">    Graph = (MGraph)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct GNode)); <span class="comment">/* 建立图 */</span></span><br><span class="line">    Graph-&gt;Nv = VertexNum;</span><br><span class="line">    Graph-&gt;Ne = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">/* 初始化邻接矩阵 */</span></span><br><span class="line">    <span class="comment">/* 注意：这里默认顶点编号从0开始，到(Graph-&gt;Nv - 1) */</span></span><br><span class="line">    <span class="keyword">for</span> (V=<span class="number">0</span>; V&lt;Graph-&gt;Nv; V++)</span><br><span class="line">        <span class="keyword">for</span> (W=<span class="number">0</span>; W&lt;Graph-&gt;Nv; W++)  </span><br><span class="line">            Graph-&gt;G[V][W] = INFINITY;</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> Graph; </span><br><span class="line">&#125;</span><br><span class="line">       </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InsertEdge</span><span class="params">( MGraph Graph, Edge E )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="comment">/* 插入边 &lt;V1, V2&gt; */</span></span><br><span class="line">     Graph-&gt;G[E-&gt;V1][E-&gt;V2] = E-&gt;Weight;    </span><br><span class="line">     <span class="comment">/* 若是无向图，还要插入边&lt;V2, V1&gt; */</span></span><br><span class="line">     Graph-&gt;G[E-&gt;V2][E-&gt;V1] = E-&gt;Weight;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">MGraph <span class="title">BuildGraph</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    MGraph Graph;</span><br><span class="line">    Edge E;</span><br><span class="line">    Vertex V;</span><br><span class="line">    <span class="keyword">int</span> Nv, i;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;Nv);   <span class="comment">/* 读入顶点个数 */</span></span><br><span class="line">    Graph = <span class="built_in">CreateGraph</span>(Nv); <span class="comment">/* 初始化有Nv个顶点但没有边的图 */</span> </span><br><span class="line">    </span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;(Graph-&gt;Ne));   <span class="comment">/* 读入边数 */</span></span><br><span class="line">    <span class="keyword">if</span> ( Graph-&gt;Ne != <span class="number">0</span> ) &#123; <span class="comment">/* 如果有边 */</span> </span><br><span class="line">        E = (Edge)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct ENode)); <span class="comment">/* 建立边结点 */</span> </span><br><span class="line">        <span class="comment">/* 读入边，格式为&quot;起点 终点 权重&quot;，插入邻接矩阵 */</span></span><br><span class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;Graph-&gt;Ne; i++) &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d %d %d&quot;</span>, &amp;E-&gt;V1, &amp;E-&gt;V2, &amp;E-&gt;Weight); </span><br><span class="line">            <span class="comment">/* 注意：如果权重不是整型，Weight的读入格式要改 */</span></span><br><span class="line">            <span class="built_in">InsertEdge</span>( Graph, E );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 如果顶点有数据的话，读入数据 */</span></span><br><span class="line">    <span class="keyword">for</span> (V=<span class="number">0</span>; V&lt;Graph-&gt;Nv; V++) </span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot; %c&quot;</span>, &amp;(Graph-&gt;Data[V]));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Graph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>邻接表：$G[N]$为指针数组，对应矩阵每行一个链表，只存非零元素</p><p><img src="https://i.loli.net/2021/10/06/eMtvDYJ4ymHg2dA.png" alt="image-20211006102551238"></p><p>邻接表优点：</p><ul><li>方便找任一顶点的所有邻接点</li><li>节约稀疏图的空间：需要N个头指针+2E个结点（每个指针至少两个域）</li><li>对于无向图方便计算任一顶点的度；而对于有向图则只能计算出度，需要构造逆邻接表来方便计算出度</li></ul><p>邻接表缺点：不方便检查任意一对顶点间是否存在边</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 图的邻接表表示法 */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxVertexNum 100    <span class="comment">/* 最大顶点数设为100 */</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> Vertex;         <span class="comment">/* 用顶点下标表示顶点,为整型 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> WeightType;        <span class="comment">/* 边的权值设为整型 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> DataType;        <span class="comment">/* 顶点存储的数据类型设为字符型 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 边的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ENode</span> *<span class="title">PtrToENode</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ENode</span>&#123;</span></span><br><span class="line">    Vertex V1, V2;      <span class="comment">/* 有向边&lt;V1, V2&gt; */</span></span><br><span class="line">    WeightType Weight;  <span class="comment">/* 权重 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> PtrToENode Edge;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 邻接点的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">AdjVNode</span> *<span class="title">PtrToAdjVNode</span>;</span> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AdjVNode</span>&#123;</span></span><br><span class="line">    Vertex AdjV;        <span class="comment">/* 邻接点下标 */</span></span><br><span class="line">    WeightType Weight;  <span class="comment">/* 边权重 */</span></span><br><span class="line">    PtrToAdjVNode Next;    <span class="comment">/* 指向下一个邻接点的指针 */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 顶点表头结点的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Vnode</span>&#123;</span></span><br><span class="line">    PtrToAdjVNode FirstEdge;<span class="comment">/* 边表头指针 */</span></span><br><span class="line">    DataType Data;            <span class="comment">/* 存顶点的数据 */</span></span><br><span class="line">    <span class="comment">/* 注意：很多情况下，顶点无数据，此时Data可以不用出现 */</span></span><br><span class="line">&#125; AdjList[MaxVertexNum];    <span class="comment">/* AdjList是邻接表类型 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 图结点的定义 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">GNode</span> *<span class="title">PtrToGNode</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GNode</span>&#123;</span>  </span><br><span class="line">    <span class="keyword">int</span> Nv;     <span class="comment">/* 顶点数 */</span></span><br><span class="line">    <span class="keyword">int</span> Ne;     <span class="comment">/* 边数   */</span></span><br><span class="line">    AdjList G;  <span class="comment">/* 邻接表 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> PtrToGNode LGraph; <span class="comment">/* 以邻接表方式存储的图类型 */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">LGraph <span class="title">CreateGraph</span><span class="params">( <span class="keyword">int</span> VertexNum )</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* 初始化一个有VertexNum个顶点但没有边的图 */</span></span><br><span class="line">    Vertex V;</span><br><span class="line">    LGraph Graph;</span><br><span class="line">    </span><br><span class="line">    Graph = (LGraph)<span class="built_in">malloc</span>( <span class="built_in"><span class="keyword">sizeof</span></span>(struct GNode) ); <span class="comment">/* 建立图 */</span></span><br><span class="line">    Graph-&gt;Nv = VertexNum;</span><br><span class="line">    Graph-&gt;Ne = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">/* 初始化邻接表头指针 */</span></span><br><span class="line">    <span class="comment">/* 注意：这里默认顶点编号从0开始，到(Graph-&gt;Nv - 1) */</span></span><br><span class="line">       <span class="keyword">for</span> (V=<span class="number">0</span>; V&lt;Graph-&gt;Nv; V++)</span><br><span class="line">        Graph-&gt;G[V].FirstEdge = <span class="literal">NULL</span>;</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> Graph; </span><br><span class="line">&#125;</span><br><span class="line">       </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InsertEdge</span><span class="params">( LGraph Graph, Edge E )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PtrToAdjVNode NewNode;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 插入边 &lt;V1, V2&gt; */</span></span><br><span class="line">    <span class="comment">/* 为V2建立新的邻接点 */</span></span><br><span class="line">    NewNode = (PtrToAdjVNode)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct AdjVNode));</span><br><span class="line">    NewNode-&gt;AdjV = E-&gt;V2;</span><br><span class="line">    NewNode-&gt;Weight = E-&gt;Weight;</span><br><span class="line">    <span class="comment">/* 将V2插入V1的表头 */</span></span><br><span class="line">    NewNode-&gt;Next = Graph-&gt;G[E-&gt;V1].FirstEdge;</span><br><span class="line">    Graph-&gt;G[E-&gt;V1].FirstEdge = NewNode;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">/* 若是无向图，还要插入边 &lt;V2, V1&gt; */</span></span><br><span class="line">    <span class="comment">/* 为V1建立新的邻接点 */</span></span><br><span class="line">    NewNode = (PtrToAdjVNode)<span class="built_in">malloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(struct AdjVNode));</span><br><span class="line">    NewNode-&gt;AdjV = E-&gt;V1;</span><br><span class="line">    NewNode-&gt;Weight = E-&gt;Weight;</span><br><span class="line">    <span class="comment">/* 将V1插入V2的表头 */</span></span><br><span class="line">    NewNode-&gt;Next = Graph-&gt;G[E-&gt;V2].FirstEdge;</span><br><span class="line">    Graph-&gt;G[E-&gt;V2].FirstEdge = NewNode;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">LGraph <span class="title">BuildGraph</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LGraph Graph;</span><br><span class="line">    Edge E;</span><br><span class="line">    Vertex V;</span><br><span class="line">    <span class="keyword">int</span> Nv, i;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;Nv);   <span class="comment">/* 读入顶点个数 */</span></span><br><span class="line">    Graph = <span class="built_in">CreateGraph</span>(Nv); <span class="comment">/* 初始化有Nv个顶点但没有边的图 */</span> </span><br><span class="line">    </span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;(Graph-&gt;Ne));   <span class="comment">/* 读入边数 */</span></span><br><span class="line">    <span class="keyword">if</span> ( Graph-&gt;Ne != <span class="number">0</span> ) &#123; <span class="comment">/* 如果有边 */</span> </span><br><span class="line">        E = (Edge)<span class="built_in">malloc</span>( <span class="built_in"><span class="keyword">sizeof</span></span>(struct ENode) ); <span class="comment">/* 建立边结点 */</span> </span><br><span class="line">        <span class="comment">/* 读入边，格式为&quot;起点 终点 权重&quot;，插入邻接矩阵 */</span></span><br><span class="line">        <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;Graph-&gt;Ne; i++) &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d %d %d&quot;</span>, &amp;E-&gt;V1, &amp;E-&gt;V2, &amp;E-&gt;Weight); </span><br><span class="line">            <span class="comment">/* 注意：如果权重不是整型，Weight的读入格式要改 */</span></span><br><span class="line">            <span class="built_in">InsertEdge</span>( Graph, E );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 如果顶点有数据的话，读入数据 */</span></span><br><span class="line">    <span class="keyword">for</span> (V=<span class="number">0</span>; V&lt;Graph-&gt;Nv; V++) </span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot; %c&quot;</span>, &amp;(Graph-&gt;G[V].Data));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Graph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li></li></ul><h3 id="3-2-图的遍历"><a href="#3-2-图的遍历" class="headerlink" title="3.2 图的遍历"></a>3.2 图的遍历</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构, 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数</title>
      <link href="/2021/09/18/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
      <url>/2021/09/18/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/09/18/hello-world/"/>
      <url>/2021/09/18/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
