{"meta":{"title":"Lethe","subtitle":"Farewellswind Blog","description":"Blog to record sth. powered by GitPages & Hexo","author":"Farewellswind","url":"http://lethewind.github.io","root":"/"},"pages":[{"title":"About","date":"2021-09-18T08:20:09.000Z","updated":"2021-09-18T08:21:42.988Z","comments":true,"path":"about/index.html","permalink":"http://lethewind.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-09-18T04:47:39.000Z","updated":"2021-09-18T04:47:55.806Z","comments":true,"path":"categories/index.html","permalink":"http://lethewind.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-09-18T04:46:33.000Z","updated":"2021-09-18T04:47:01.439Z","comments":true,"path":"tags/index.html","permalink":"http://lethewind.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Generative adversarial network in medical imaging A review","slug":"Generative adversarial network in medical imaging A review","date":"2021-10-11T05:41:49.000Z","updated":"2021-10-11T15:45:28.601Z","comments":true,"path":"2021/10/11/Generative adversarial network in medical imaging A review/","link":"","permalink":"http://lethewind.github.io/2021/10/11/Generative%20adversarial%20network%20in%20medical%20imaging%20A%20review/","excerpt":"","text":"Generative adversarial network in medical imaging: A reviewAbstractGenerative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross- modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique. 生成对抗网络在计算机视觉社区中获得了很多关注，因为它们无需对概率密度函数进行显式建模即可生成数据。判别器带来的对抗性损失提供了一种巧妙的方法，可以将未标记的样本纳入训练并施加更高阶的一致性。这已被证明在许多情况下都很有用，例如域适应、数据增强和图像到图像的转换。这些特性吸引了医学成像界的研究人员，我们已经看到在许多传统和新颖的应用中迅速采用，例如图像重建、分割、检测、分类和跨模态合成。 根据我们的观察，这种趋势将继续下去，因此我们对使用对抗性训练的医学成像的最新进展进行了整理，希望使对这项技术感兴趣的研究人员受益。 1. IntroductionWith the resurgence of deep learning in computer vision starting from 2012 ( Krizhevsky et al., 2012 ), the adoption of deep learning methods in medical imaging has increased dramatically. It is estimated that there were over 400 papers published in 2016 and 2017 in major medical imaging related conference venues and journals ( Litjens et al., 2017 ). The wide adoption of deep learning in the medical imaging community is due to its demonstrated potential to complement image interpretation and augment image representation and classification. In this article, we focus on one of the most interesting recent breakthroughs in the field of deep learning - generative adversarial networks (GANs) - and their potential applications in the field of medical imaging. 随着 2012 年计算机视觉深度学习的复苏（Krizhevsky et al., 2012），深度学习方法在医学成像中的应用急剧增加。 据估计，2016年和2017年在主要医学影像相关会议和期刊上发表的论文超过400篇（Litjens et al., 2017）。深度学习在医学成像界的广泛采用是由于其在补充图像解释和增强图像表示和分类方面表现出的潜力。在本文中，我们关注深度学习领域最近最有趣的突破之一——生成对抗网络 (GAN)——及其在医学成像领域的潜在应用。 GANs are a special type of neural network model where two networks are trained simultaneously, with one focused on image generation and the other centered on discrimination. The ad-versarial training scheme has gained attention in both academia and industry due to its usefulness in counteracting domain shift, and effectiveness in generating new image samples. This model has achieved state-of-the-art performance in many image generation tasks, including text-to-image synthesis ( Xu et al., 2017 ), super-resolution ( Ledig et al., 2017 ), and image-to-image translation ( Zhu et al., 2017 ). GAN 是一种特殊类型的神经网络模型，其中两个网络同时训练，一个专注于图像生成，另一个专注于判别。由于对抗域迁移的有用性和生成新图像样本的有效性，对抗性训练方案在学术界和业界都受到关注。该模型在许多图像生成任务中取得了最先进的性能，包括文本到图像合成（Xu et al., 2017）、超分辨率（Ledig et al., 2017）和图像到图像转换（Zhu et al., 2017）。 Unlike deep learning which has its roots traced back to the 1980s ( Fukushima and Miyake, 1982 ), the concept of ad- versarial training is relatively new with significant recent progress ( Goodfellow et al., 2014 ). This paper presents a gen- eral overview of GANs, describes their promising applications in medical imaging, and identifies some remaining challenges that need to be solved to enable their successful application in other medical imaging related tasks. 与起源于 1980 年代（Fukushima 和 Miyake，1982）的深度学习不同，对抗训练的概念相对较新，并且最近取得了重大进展（Goodfellow 等，2014）。 本文概述了 GAN，描述了它们在医学成像中的有前景的应用，并确定了一些需要解决的剩余挑战，以使其成功应用于其他医学成像相关任务。 To present a comprehensive overview of all relevant works on GANs in medical imaging, we searched databases including PubMed, arXiv, proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), SPIE Medical Imaging, IEEE International Symposium on Biomedical Imaging (ISBI), and International conference on Medical Imaging with Deep Learning (MIDL). We also incorporated cross referenced works not identified in the above search process. Since there are research publications coming out every month, without losing generality, we set the cut offtime of the search as January 1st, 2019. Works on arXiv that report only preliminary results are excluded from this review. Descriptive statistics of these papers based on task, imaging modality and year can be found in Fig. 1 . 为了全面概述医学成像中 GAN 的所有相关工作，我们检索了包括 PubMed、arXiv、医学图像计算和计算机辅助干预国际会议 (MICCAI)、SPIE 医学成像、IEEE 生物医学成像国际研讨会论文集在内的数据库 (ISBI) 和深度学习医学成像国际会议 (MIDL)。 我们还合并了上述搜索过程中未确定的交叉引用作品。 由于每个月都有研究发表，在不失一般性的情况下，我们将搜索截止时间设置为 2019 年 1 月 1 日。 arXiv 上仅报告初步结果的作品被排除在本次审查之外。 这些论文基于任务、成像方式和年份的描述性统计可以在图 1 中找到。 Fig. 1. (a) Categorization of GAN related papers according to canonical tasks. (b) Categorization of GAN related papers according to imaging modality. (c) Number of GAN related papers published from 2014. Note that some works performed various tasks and conducted evaluation on datasets with different modalities. We counted these works multiple times in plotting these graphs. Works related to cross domain image transfer were counted based on the source domain. The statistics presented in figure (a) and (b) are based on papers published on or before January 1st, 2019. 图1..（a） 根据规范任务对与GAN相关的论文进行分类。（b） 根据影像学形态分类与GAN相关的论文。（c） 2014年发表的与GAN相关的论文数量。请注意，一些工作执行了各种任务，并对不同模式的数据集进行了评估。在绘制这些图表时，我们对这些作品进行了多次计数。基于源域统计与跨域图像传输相关的工作。图（a）和（b）中的统计数据基于2019年1月1日或之前发表的论文。 The remainder of the paper is structured as follows. We begin with a brief introduction of the principles of GANs and some of its structural variants in Section 2 . It is followed by a com- prehensive review of medical image analysis tasks using GANs in Section 3 including but not limited to the fields of radiology, histopathology and dermatology. We categorize all the works according to canonical tasks: reconstruction, image synthesis, segmentation, classification, detection, registration, and others. Section 4 summarizes the review and discusses prospective applications and identifies open challenges. 本文其余部分的结构如下。在第2节中，我们首先简要介绍GANs的原理及其一些结构变体。第3节对使用GANs的医学图像分析任务进行了全面回顾，包括但不限于放射学、组织病理学和皮肤学领域。我们根据标准任务对所有工作进行分类：重建、图像合成、分割、分类、检测、配准等。第4节总结了审查，讨论了潜在的应用，并确定了存在的挑战。 2. Background2.1 Vanilla GANThe vanilla GAN ( Goodfellow et al., 2014 ) is a generative model that was designed for directly drawing samples from the desired data distribution without the need to explicitly model the underlying probability density function. It consists of two neural networks: the generator $G$ and the discriminator $D$. The input to $G$, $z$ is pure random noise sampled from a prior distribution $p(z)$, which is commonly chosen to be a Gaussian or a uniform distribution for simplicity. The output of $G$, $x_g$ is expected to have visual similarity with the real sample $x_r$ that is drawn from the real data distribution $p_r(x)$. We denote the non-linear mapping function learned by $G$ parametrized by $θ_g$ as $x_g=G(z;θ_g)$ . The input to $D$ is either a real or generated sample. The output of $D$, $y_1$ is a single value indicating the probability of the input being a real or fake sample. The mapping learned by $D$ parametrized by $θ_d$ is denoted as $y_1=D(x;θ_d) $. The generated samples form a distribution $p_g ( x )$ which is desired to be an approximation of $p_r( x )$ after successful training. The top of Fig. 2 shows an illustration of a vanilla GAN’s configuration. G in this example is generating a 2D CT slice depicting a lung nodule. Vanilla GAN（Goodfello et al.，2014）是一种生成模型，设计用于直接从所需数据分布中提取样本，而无需显式建模基础概率密度函数。它由两个神经网络组成：生成器$G$和判别器$D$。$G$的输入$z$是从先验分布$p(z)$中采样的纯随机噪声，为简单起见，通常选择高斯分布或均匀分布。$G$的输出$x_g$预期与从真实数据分布$p_r(x)$中提取的真实样本$x_r$具有视觉相似性。我们将$G$学习的非线性映射函数表示为$x_g=G(z;θ_G)$。$D$的输入要么是真实的样本，要么是生成的样本。$D$的输出$y_1$是一个单一值，表示输入为真实或虚假样本的概率。由$D$学习并由$θ_d$参数化的映射表示为$y_1=D(x;θ_D)$。生成的样本形成一个分布$p_g(x)$，在成功训练后，该分布期望是$p_r(x)$的近似值。图2的顶部示出了GAN的配置的图示。在本例中，G生成了一个描绘肺结节的2D CT切片。 Fig. 2. Schematic view of the vanilla GAN for synthesis of lung nodule on CT images. Top of the figure shows the network configuration. The part below shows the input, output and the internal feature representations of the generator $G$ and discriminator $D$. $G$ transforms a sample $z$ from $p ( z )$ into a generated nodule $x_g$ . $D$ is a binary classifier that differentiates the generated and real images of lung nodule formed by $x_g$ and $x_r$ respectively. 图2.CT图像上用于合成肺结节的香草甘的示意图。图的顶部显示了网络配置。下面的部分显示了生成器$G$和判别器$D$的输入、输出和内部特征表示。$G$将样本$z$从$p(z)$转换为生成的结节$x_g$，$D$是一个二值分类器，用于区分由$x_g$和$x_r$分别形成的肺结节的生成图像和真实图像。 $D$’s objective is to differentiate these two groups of images whereas the generator $G$ is trained to confuse the discriminator $D$ as much as possible. Intuitively, $G$ could be viewed as a forger trying to produce some quality counterfeit material, and $D$ could be regarded as the police officer trying to detect the forged items. In an alternative view, we can perceive $G$ as receiving a reward signal from $D$ depending upon whether the generated data is accurate or not. The gradient information is back propagated from $D$ to $G$, so $G$ adapts its parameters in order to produce an output image that can fool $D$. The training objectives of $D$ and $G$ can be expressed mathematically as: $D$的目标是区分这两组图像，而生成器$G$经过训练以尽可能混淆判别器$D$。直觉上，$G$可以被视为一个试图制造一些高质量假冒材料的伪造者，$D$可以被视为试图检测伪造物品的警官。在另一种观点中，我们可以将$G$视为从$D$接收到激励信号，这取决于生成的数据是否准确。梯度信息从$D$反向传播到$G$，因此$G$调整其参数，以产生可以愚弄$D$的输出图像。$D$和$G$的训练目标可以数学表示为： As can be seen, $D$ is simply a binary classifier with a maximum log likelihood objective. If the discriminator $D$ is trained to optimality before the next generator $G$ updates, then minimizing $\\cal{L}\\rm{^{GAN}_G}$ is proven to be equivalent to minimizing the Jensen–Shannon (JS) divergence between $p_r(x)$ and $p_g(x)$ ( Goodfellow et al., 2014 ). The desired outcome after training is that samples formed by $x_g$ should approximate the real data distribution $p_r(x)$. 可以看出，$D$只是一个具有最大对数似然目标的二分类器。如果在下一个生成器$G$更新之前，将判别器$D$训练为最优，那么最小化$\\cal{L}\\rm{^{GAN}_G}$被证明等同于最小化$p_r(x)$和$p_g(x)$之间的Jensen–Shannon(JS)散度（Goodfello等人，2014）。训练后的预期结果是，由$x_g$形成的样本应近似于实际数据分布$p_r(x)$。 2.2 Challenges in optimizing GANsThe above GAN training objective is regarded as a saddle point optimization problem ( Yadav et al., 2018 ) and the training is often accomplished by gradient-based methods. G and D are trained alternately from scratch so that they may evolve together. However, there is no guarantee of balance between the training of G and D with the JS divergence. As a consequence, one network may inevitably be more powerful than the other, which in most cases is D. When D becomes too strong as opposed to G, the generated samples become too easy to be separated from real ones, thus reaching a stage where gradients from D approach zero, providing no guidance for further training of G. This hap- pens more frequently when generating high resolution images due to the difficulty of generating meaningful high frequency details. 上述GAN训练目标被视为鞍点优化问题（Yadav等人，2018年），训练通常通过基于梯度的方法完成。G和D从零开始交替训练，以便它们可以一起进化。然而，不能保证G和D的训练与JS散度之间的平衡。因此，一个网络可能不可避免地比另一个网络更强大，在大多数情况下是D。当D相对于G变得太强时，生成的样本变得太容易与真实样本分离，从而达到D的梯度接近零的阶段，没有为G的进一步训练提供指导。由于难以生成有意义的高频细节，因此在生成高分辨率图像时，此种现象会出现地更加频繁。 Another problem commonly faced in training GANs is mode collapse, which, as the name indicates, is a case when the distribution $p_g(x)$ learned by G focuses on a few limited modes of the data distribution $p_r(x)$. Hence instead of producing diverse images, it generates a limited set of samples. 在训练GANs中通常面临的另一个问题是模式崩溃，顾名思义，这是G学习的分布$p_g(x)$关注数据分布$p_r(x)$的几个有限模式的情况。因此，它不是生成不同的图像，而是生成一组有限的样本。 2.3 Variants of GANs2.3.1 Varying objective of DIn order to stabilize training and also to avoid mode collapse, different losses for D have been proposed, such as f-divergence (f-GAN) ( Nowozin et al., 2016 ), least-square (LSGAN) ( Mao et al., 2017 ), hinge loss ( Miyato et al., 2018 ), and Wasserstein distance (WGAN, WGAN-GP) ( Arjovsky et al., 2017; Gulrajani et al., 2017 ). Among these, Wasserstein distance is arguably the most popular metric. As an alternative to the real/fake discrimination scheme, Springenberg (2015) proposed an entropy based objective where real data is encouraged to make confident class predictions (CatGAN, Fig. 3 b). In EBGAN ( Zhao et al., 2016 ) and BE- GAN ( Berthelot et al., 2017 ) ( Fig. 3 c), the commonly used encoder architecture for discriminator is replaced with an autoencoder architecture. D’s objective then becomes matching autoencoder loss distribution rather than data distribution. 为了稳定训练并避免模式崩溃，提出了D的不同损失，如f散度（f-GAN）（Nowozin等人，2016年）、最小二乘（LSGAN）（Mao等人，2017年）、铰链损失（Miyato等人，2018年）和Wasserstein距离（WGAN，WGAN-GP）（Arjovsky等人，2017年；Gularjani等人，2017年）。其中，Wasserstein距离可以说是最流行的度量。作为真/假鉴别方案的替代方案，Springenberg（2015）提出了一种基于熵的目标，其中鼓励真实数据进行置信的类别预测（CatGAN，图3 b）。在EBGAN（Zhao等人，2016年）和BE-GAN（Berthelot等人，2017年）（图3 c）中，用于判别器的常用编码器架构被自动编码器架构取代。D的目标是匹配自动编码器的损失分布，而不是数据分布。 GANs themselves lack the mechanism of inferencing the underlying latent vector that is likely to encode the input. Therefore, in ALI ( Dumoulin et al., 2016 ) and BiGAN ( Donahue et al., 2016 ) ( Fig. 3 d), a separate encoder network is incorporated. D’s objective then becomes separating joint samples $(x_g,z_g)$ and $(x_r,z_r)$. In InfoGAN ( Fig. 3 e), the discriminator outputs the latent vector that encodes part of the semantic features of the generated image. The discriminator maximizes the mutual information between the generated image and the latent attribute vector the generated image is conditioned upon. After successful training, InfoGAN can explore inherent data attributes and perform conditional data generation based on these attributes. The use of class labels has been shown to further improve generated image’s quality and this information can be easily incorporated into D by enforcing D to provide class probabilities and use cross entropy loss for optimization such as used in ACGAN ( Odena et al., 2017 ) ( Fig. 3 f). GANs本身缺乏推断潜在向量的机制，该潜在向量可能对输入进行编码。因此，在ALI（Dumoulin等人，2016）和BiGAN（Donahue等人，2016）（图3 d）中，合并了一个单独的编码器网络。D的目标是分离关节样本$(x_g,z_g)$和$(x_r,z_r)$。在InfoGAN（图3e）中，判别器输出对所生成图像的部分语义特征进行编码的潜在向量。判别器最大化生成图像和生成图像所基于的潜在属性向量之间的互信息。成功训练后，InfoGAN可以探索固有的数据属性，并基于这些属性执行条件数据生成。类标签的使用已被证明可进一步提高生成图像的质量，通过强制D提供类概率并使用交叉熵损失进行优化（如在ACGAN中使用的），该信息可容易地并入D中（Odena et al.，2017）（图3 f）。 2.3.2 Varying object of GIn the vanilla GAN, G transforms noise z to sample $x_g=G(z)$ . This is usually accomplished by using a decoder network to progressively increase the spatial size of the output until the desired resolution is achieved as shown in Fig. 2 . Larsen et al. (2015) proposed a variational autoencoder network (VAE) as the underlying architecture of G (VAEGAN, Fig. 3 g), where it can use pixel-wise reconstruction loss to enforce the decoder part of VAE to generate structures to match the real images. 在标准GAN中，$G$将噪声$z$转换为样本$x_g=G(z)$。这通常通过使用解码器网络来逐步增加输出的空间大小来实现，直到如图2所示实现所需的分辨率。Larsen et al.（2015）提出了一种变分自动编码器网络（VAE）作为G的底层架构（VAEGAN，图3 G），其中它可以使用像素级重建损失来强制VAE的解码器部分生成与真实图像匹配的结构。 The original setup of a GAN does not have any restrictions on the modes of data it can generate. However, if auxiliary information were provided during the generation, the GAN can be driven to output images with desired properties. A GAN in this scenario is usually referred as a conditional GAN (cGAN) and the generation process can be expressed as $x_g=G(z,c)$ . GAN的原始设置对其可以生成的数据模式没有任何限制。然而，如果在生成期间提供辅助信息，则可以驱动GAN以输出具有期望特性的图像。在这种情况下，GAN通常被称为条件GAN（cGAN），并且生成过程可以表示为$x_g=G(z,c)$。 One of the most common conditional inputs $c$ is an image. pix2pix, the first general purpose GAN based image-to-image translation framework was proposed by Isola et al. (2016) ( Fig. 4 a). Further, task related supervision was introduced to the generator. For example, reconstruction loss for image restoration and Dice loss ( Milletari et al., 2016 ) for segmentation. This form of supervision requires aligned training pairs. Zhu et al. (2017) and Kim et al. (2017) relaxed this constraint by stitching two generators together head to toe so that images can be translated between two sets of unpaired samples ( Fig. 4 b). For the sake of simplicity, we chose CycleGAN to represent this idea in the rest of this paper. Another model named UNIT ( Fig. 4 c) can also perform unpaired image-to-image transform by combining two VAEGANs together with each one responsible for one modality but sharing the same latent space ( Liu et al., 2017a ). These image-to-image translation frameworks are very popular in the medical imaging community due to their general applicability. 最常见的条件输入$c$之一是图像。pix2pix是第一个基于GAN的通用图像到图像转换框架，由Isola等人（2016）提出（图4a）。此外，还向生成器引入了与任务相关的监督。例如，用于图像恢复的重建损失和用于分割的骰子损失（Milleri等人，2016）。这种形式的监督需要成对的训练。Zhu et al.（2017）和Kim et al.（2017）通过将两个生成器从头到尾缝合在一起，从而放松了这一约束，从而可以在两组未配对样本之间转换图像（图4b）。为了简单起见，我们选择了CycleGAN在本文的其余部分中表示这个想法。另一个名为UNIT的模型（图4c）也可以通过将两个Vaegan组合在一起，每个Vaegan负责一个模态，但共享相同的潜在空间来执行未配对的图像到图像变换（Liu等人，2017a）。这些图像到图像的转换框架由于其普遍适用性而在医学成像界非常流行。 Other than image, the conditional input can be class labels (CGAN, Fig. 3 h) ( Mirza and Osindero, 2014 ), text descriptions ( Zhang et al., 2017a ), object locations ( Reed et al., 2016a; 2016b ), surrounding image context ( Pathak et al., 2016 ), or sketches ( Sangkloy et al., 2017 ). Note that ACGAN mentioned in the previous section also has a class conditional generator. 除了图像，条件输入可以是类别标签（CGAN，图3h）（Mirza和Osindero，2014）、文本描述（Zhang等人，2017a）、对象位置（Reed等人，2016a；2016b）、周围图像上下文（Pathak等人，2016）或草图（Sangkloy等人，2017）。请注意，上一节中提到的ACGAN还有一个类条件生成器。 2.3.3 Varying architectureFully connected layers were used as the building block in vanilla GAN but later on, were replaced by fully convolutional downsampling/upsampling layers in DCGAN ( Radford et al., 2015 ).DCGAN demonstrated better training stability hence quickly populated the literature. As shown in Fig. 2 , the generator in DCGAN architecture works on random input noise vector by successive upsampling operations eventually generating an image from it. Two of its important ingredients are BatchNorm ( Ioffe and Szegedy, 2015 ) for regulating the extracted feature scale, and LeakyRelu ( Maas et al., 2013 ) for preventing dead gradients. Very recently, Miyato et al. (2018) proposed a spectral normalization layer that normalized weights in the discriminator to regulate the scale of feature response values. With the training stability improved, some works have also incorporated residual connections into both the generator and discriminator and experimented with much deeper networks ( Gulrajani et al., 2017; Miyato et al., 2018 ).The work in Miyato and Koyama (2018) proposed a projection based way to incorporate the conditional information instead of direct concatenation and found it to be beneficial in improving the generated image’s quality. 全连接层被用作vanilla GAN中的构建块，但后来被DCGAN中的完全卷积下采样/上采样层所取代（Radford et al.，2015）。DCGAN表现出更好的训练稳定性，因此很快就在文献中出现。如图2所示，DCGAN结构中的生成器通过连续的上采样操作在随机输入噪声向量上工作，最终从中生成图像。它的两个重要成分是BatchNorm（Ioffe和Szegedy，2015），用于调节提取的特征尺度，以及LeakyRelu（Maas等人，2013），用于防止死梯度。最近，Miyato等人（2018）提出了一种频谱归一化层，该层对判别器中的权重进行归一化，以调节特征响应值的尺度。随着训练稳定性的提高，一些工作还将剩余连接纳入了生成器和判别器中，并对更深层次的网络进行了试验（Gullajani等人，2017年；Miyato等人，2018年）。Miyato和Koyama（2018）的工作提出了一种基于投影的方法来合并条件信息，而不是直接连接，并发现它有助于提高生成图像的质量。 Directly generating high resolution images from a noise vector is hard, therefore some works have proposed tackling it in a progressive manner. In LAPGAN ( Fig. 3 i), Denton et al. (2015) proposed a stack of GANs, each of which adds higher frequency details into the generated image. In SGAN, a cascade of GANs is also used but each GAN generates increasingly lower level representations ( Huang et al., 2017 ), which are compared with the hierarchical representations extracted from a discriminatively trained model. Karras et al. (2017) adopted an alternate way where they progressively grow the generator and discriminator by adding new layers to them rather than stacking another GAN on top of the preceding one (PGGAN). This progressive idea was also explored in conditional setting ( Wang et al., 2018 ). More recently, Karras et al. (2019) proposed a style-based generator architecture (styleGAN) where instead of directly feeding the latent code z to the input of the generator, they transformed this code first to an intermediate latent space and then use it to scale and shift the normalized image feature responses computed from each convolution layer. Similarly, Park et al. (2019) proposed SPADE where the segmentation mask was injected to the generator via a spatially adaptive normalization layer. This conditional setup was found to better preserve the semantic layout of the mask than directly feeding the mask to the generator. 从噪声矢量直接生成高分辨率图像是困难的，因此一些工作建议以渐进的方式处理它。在LAPGAN（图3 i）中，Denton等人（2015）提出了一组GANs，每个GANs都向生成的图像中添加了更高频率的细节。在SGAN中，也使用了级联的GAN，但每个GAN生成越来越低级别的表示（Huang等人，2017），这与从差别训练模型中提取的层次表示进行了比较。Karras等人（2017年）采用了另一种方法，即通过向生成器和判别器添加新层，而不是在前一层（PGGAN）的顶部堆叠另一层GAN，逐步增加生成器和判别器。这种进步的想法也在条件设置中得到了探索（Wang等人，2018年）。最近，Karras et al.（2019）提出了一种基于样式的生成器体系结构（styleGAN），其中不直接将潜在代码z提供给生成器的输入，他们首先将该代码转换为一个中间潜在空间，然后使用它来缩放和移动从每个卷积层计算的归一化图像特征响应。类似地，Park等人（2019）提出了SPADE，其中分割掩模通过空间自适应归一化层注入生成器。发现这种条件设置比直接将掩码提供给生成器更好地保留掩码的语义布局。 Schematic illustrations of the most representative GANs are shown in Fig. 3 . They are GAN, CatGAN, EBGAN/BEGAN, ALI/BiGAN, InfoGAN, ACGAN, VAEGAN, CGAN, LAPGAN, SGAN. Three popular image-to-image translation cGANs (pix2pix, CycleGAN, and UNIT) are shown in Fig. 4 . For a more in-depth review and empirical evaluation of these different variants of GAN, we refer the reader to Huang et al. (2018) , Creswell et al. (2018) and Kurach et al. (2018) . 图3显示了最具代表性的GAN的示意图。他们是GAN、CatGAN、EBGAN/Begin、ALI/BiGAN、InfoGAN、ACGAN、VAEGAN、CGAN、LAPGAN、SGAN。图4中显示了三种流行的图像到图像转换cgan（pix2pix、CycleGAN和UNIT）。为了更深入地回顾和实证评估这些不同的GAN变体，我们请读者参考Huang et al.（2018）、Creswell et al.（2018）和Kurach et al.（2018）。 Fig. 3. A schematic view of variants of GAN. c represents the conditional vector. In CGAN and ACGAN, c is the discrete categorical code (e.g. one hot vector) that encodes class labels and in InfoGAN it can also be continuous code that encodes attributes. $x_g$ generally refers to the generated image but can also be internal representations as inSGAN. 图3. GAN变体的示意图。c表示条件向量。在CGAN和ACGAN中，c是编码类标签的离散分类代码（例如，一个独热向量），在InfoGAN中，c也可以是编码属性的连续代码。$x_g$通常指生成的图像，但也可以是SGAN中的内部表示。 Fig. 4. cGAN frameworks for image-to-image translation. pix2pix requires aligned training data whereas this constraint is relaxed in CycleGAN but usually suffers from performance loss. Note that in (a), we chose reconstruction loss as an example of target consistency. This supervision is task related and can take many other different forms. (c) It consists of two VAEGANs with shared latent vector in the VAE part. 图4. 用于图像到图像翻译的CGA框架。pix2pix需要对齐的训练数据，而这种约束在CycleGAN中是放松的，但通常会受到性能损失的影响。注意，在(a)中，我们选择重建损失作为目标一致性的示例。这种监督与任务相关，可以采取许多其他不同形式。(c)它由两个在VAE部分具有共享潜在向量的Vaegan组成。 3. Applications in medical imagingThere are generally two ways GANs are used in medical imaging. The first is focused on the generative aspect, which can help in exploring and discovering the underlying structure of training data and learning to generate new images. This property makes GANs very promising in coping with data scarcity and patient privacy. The second focuses on the discriminative aspect, where the discriminator D can be regarded as a learned prior for normal images so that it can be used as regularizer or detector when presented with abnormal images. Fig. 5 provides examples of GAN related applications, with examples (a), (b), (c), (d), (e), (f) that focus on the generative aspect and example (g) that exploits the discriminative aspect. In the following subsections, in order to help the readers find applications of their interest, we categorized all the reviewed articles into canonical tasks: reconstruction, image synthesis, segmentation, classification, detection, registration, and others. 在医学成像中，GANs通常有两种使用方式。第一个重点是生成方面，这有助于探索和发现训练数据的底层结构，并学习生成新图像。这一特性使得GANs在应对数据稀缺和患者隐私方面非常有希望。第二个关注于鉴别方面，其中判别器D可以被视为正常图像的学习先验，以便当呈现异常图像时，它可以被用作正则化器或检测器。图5提供了GAN相关应用的示例，其中示例a、b、c、d、e、f侧重于生成方面，示例g利用区别方面。在下面的小节中，为了帮助读者找到他们感兴趣的应用程序，我们将所有已审阅的文章分类为规范任务：重建、图像合成、分割、分类、检测、配准等。 Fig. 5. Example applications using GANs. Figures are directly cropped from the corresponding papers. (a) Left side shows the noise contaminated low dose CT and right sideshows the denoised CT that well preserved the low contrast regions in the liver ( Yi and Babyn, 2018 ). (b) Left side shows the MR image and right side shows the synthesizedcorresponding CT. Bone structures were well delineated in the generated CT image ( Wolterink et al., 2017a ). (c) The generated retinal fundus image have the exact vesselstructures as depicted in the left vessel map ( Costa et al., 2017b ). (d) Randomly generated skin lesion from random noise (a mixture of malignant and benign) ( Yi et al.,2018 ). (e) An organ (lung and heart) segmentation example on adult chest X-ray. The shapes of lung and heart are regulated by the adversarial loss ( Dai et al., 2017b ). (f) Thethird column shows the domain adapted brain lesion segmentation result on SWI sequence without training with the corresponding manual annotation ( Kamnitsas et al.,2017 ). (g) Abnormality detection of optical coherence tomography images of the retina ( Schlegl et al., 2017 ). 图5。使用GANs的示例应用程序。数字是从相应的文件中直接裁剪出来的。(a)左侧显示噪声污染的低剂量CT，右侧显示去除噪声的CT，它很好地保留了肝脏中的低对比度区域（Yi和Babyn，2018）。(b)左侧显示MR图像，右侧显示相应的合成CT。在Wolterink等人的图像中描绘了骨骼结构。(c)生成的视网膜眼底图像具有左血管图所示的精确血管结构（Costa等人，2017b）。(d)随机噪声随机产生的皮肤损伤（恶性和良性混合）（Yi等人，2018年）。(e)成人胸部X光片上的器官（肺和心脏）分割示例。肺和心脏的形状受对抗性损失的影响（Dai等人，2017b）。(f)第三列显示了SWI序列上的域自适应脑损伤分割结果，无需使用相应的手动注释进行训练（Kamnitsas et al.，2017）。(g)视网膜光学相干断层扫描图像的异常检测（Schlegl等人，2017年）。 3.1 ReconstructionDue to constraints in clinical settings, such as radiation dose and patient comfort, the diagnostic quality of acquired medical images may be limited by noise and artifacts. In the last decade, we have seen a paradigm shift in reconstruction methods changing from analytic to iterative and now to machine learning based methods. These data-driven learning based methods either learn to transfer raw sensory inputs directly to output images or serve as a post processing step for reducing image noise and removing artifacts. Most of the methods reviewed in this section are borrowed directly from the computer vision literature that formulate post-processing as an image-to-image translation problem where the conditioned inputs of cGANs are compromised in certain forms, such as low spatial resolution, noise contamination, under-sampling, or aliasing. One exception is for MR images where the Fourier transform is used to incorporate the raw K-space data into the reconstruction. 由于临床环境的限制，如辐射剂量和患者舒适度，采集的医学图像的诊断质量可能受到噪声和伪影的限制。在过去十年中，我们看到重建方法的范式转变，从分析方法转变为迭代方法，现在转变为基于机器学习的方法。这些基于数据驱动的学习方法要么学习将原始感官输入直接传输到输出图像，要么作为减少图像噪声和消除伪影的后处理步骤。本节中回顾的大多数方法都是直接从计算机视觉文献中借来的，这些文献将后处理描述为图像到图像的转换问题，其中CGAN的条件输入以某些形式受到损害，例如低空间分辨率、噪声污染、欠采样或混叠。一个例外是MR图像，其中傅里叶变换用于将原始K空间数据合并到重建中。 The basic pix2pix framework has been used for low dose CT denoising ( Wolterink et al., 2017b ), MR reconstruction ( Chen et al., 2018b; Kim et al., 2018; Dar et al., 2018b; Shitrit and Raviv, 2017 ), and PET denoising ( Wang et al., 2018b ). A pretrained VGGnet ( Simonyan and Zisserman, 2014 ) was further incorporated into the optimization framework to ensure perceptual similarity ( Yang et al., 2018; Yu et al., 2017; Yang et al., 2018a; Armanious et al., 2018c; Mahapatra, 2017 ). Yi and Babyn (2018) introduced a pretrained sharpness detection network to explicitly constrain the sharpness of the denoised CT especially for low contrast regions. Mahapatra (2017) computed a local saliency map to highlight blood vessels in superresolution process of retinal fundus imaging. A similar idea was explored by Liao et al. (2018) in sparse view CT reconstruction. They compute a focus map to modulate the reconstructed output to ensure that the network focused on important regions. Besides ensuring image domain data fidelity, frequency domain data fidelity is also imposed when raw K-space data is available in MR reconstruction ( Quan et al., 2018; Mardani et al., 2017; Yang et al., 2018a ). 基本pix2pix框架已用于低剂量CT去噪（Wolterink等人，2017b）、MR重建（Chen等人，2018b；Kim等人，2018；Dar等人，2018b；Shitrit和Raviv，2017）和PET去噪（Wang等人，2018b）。预训练VGGnet（Simonyan和Zisserman，2014）进一步纳入优化框架，以确保感知相似性（Yang等人，2018；Yu等人，2017；Yang等人，2018a；Armanious等人，2018c；Mahapatra，2017）。Yi和Babyn（2018）引入了预训练锐度检测网络，以明确限制去噪CT的锐度，尤其是低对比度区域。Mahapatra（2017）计算了局部显著性图，以突出视网膜眼底成像超分辨率过程中的血管。Liao等人（2018）在稀疏视图CT重建中探索了类似的想法。他们计算一个聚焦图来调节重建的输出，以确保网络聚焦于重要区域。除了确保图像域数据保真度外，当原始K空间数据可用于MR重建时，还可施加频域数据保真度（Quan等人，2018年；Mardani等人，2017年；Yang等人，2018a）。 Losses of other kinds have been used to highlight local image structures in the reconstruction, such as the saliency loss to reweight each pixel’s importance based on its perceptual relevance ( Mahapatra, 2017 ) and the style-content loss in PET denoising ( Armanious et al., 2018c ). In image reconstruction of moving organs, paired training samples are hard to obtain. Therefore, Ravì et al. (2018) proposed a physical acquisition based loss to regulate the generated image structure for endomicroscopy super resolution and Kang et al. (2019) proposed to use CycleGAN together with an identity loss in the denoising of cardiac CT. Wolterink et al. (2017b) found that in low dose CT denoising, meaningful results can still be achieved when removing the image domain fidelity loss from the pix2pix framework, but the local image structure can be altered. Papers relating to medical image reconstruction are summarized in Table 1 . 其他类型的损失已用于强调重建中的局部图像结构，例如基于感知相关性重新加权每个像素重要性的显著性损失（Mahapatra，2017）和PET去噪中的样式内容损失（Armanious et al.，2018c）。在运动器官的图像重建中，配对训练样本难以获得。因此，Ravì等人（2018年）提出了一种基于物理采集的损失，以调节内窥镜超分辨率生成的图像结构，Kang等人（2019年）提出在心脏CT去噪中使用CycleGAN和身份损失。 Wolterink等人（2017b）发现，在低剂量CT去噪中，当从pix2pix框架中去除图像域保真度损失时，仍然可以获得有意义的结果，但局部图像结构可以改变。表1总结了与医学图像重建相关的论文。 It can be noticed that the underlying methods are almost the same for all the reconstruction tasks. MR is special case as it has a well defined forward and backward operation, i.e. Fourier transform, so that raw K-space data can be incorporated. The same methodology can potentially be applied to incorporate the sinogram data in the CT reconstruction process but we have not seen any research using this idea as yet probably because the sinogram data is hard to access. The more data used, either raw K-space or image from other sequence, the better are the reconstructed results. In general, using adversarial loss produces more visually appealing results than using pixel-wise reconstruction loss alone. But using adversarial loss to match the generated and real data distribution may make the model hallucinate unseen structures. Pixel-wise reconstruction loss helps to combat this problem if paired samples are available, and if the model was trained on all healthy images but employed to reconstruct images with pathologies, the hallucination problem will still exist due to domain mismatch. Cohen et al. (2018) have conducted extensive experiments to investigate this problem and suggest that reconstructed images should not be used for direct diagnosis by radiologists unless the model has been properly verified. 可以注意到，所有重建任务的基本方法几乎相同。MR是一种特殊情况，因为它具有定义良好的正向和反向操作，即傅里叶变换，因此可以合并原始K空间数据。同样的方法可以潜在地应用于将正弦图数据纳入CT重建过程中，但我们尚未看到任何使用此想法的研究，可能是因为正弦图数据难以访问。使用的数据越多，无论是原始K空间还是来自其他序列的图像，重建结果越好。一般来说，使用对抗性损失比单独使用像素级重建损失产生更具视觉吸引力的结果。但是，使用对抗性损失来匹配生成的和真实的数据分布可能会使模型产生看不见的结构的幻觉。如果成对样本可用，像素级重建损失有助于解决此问题，并且如果模型在所有健康图像上训练，但用于重建具有病理学的图像，则由于域不匹配，幻觉问题仍然存在。Cohen等人（2018年）进行了大量实验来研究这一问题，并建议重建图像不应用于放射科医生的直接诊断，除非模型已得到适当验证。 However, even though the dataset is carefully curated to match the training and testing distribution, there are other problems in further boosting performance. We have seen various different losses introduced to the pix2pix framework as shown in Table 2 to improve the reconstructed fidelity of local structures. There is, however, no reliable way of comparing their effectiveness except for relying on human observer or downstream image analysis tasks. Large scale statistical analysis by human observer is currently lacking for GAN based reconstruction methods. Furthermore, public datasets used for image reconstruction are not tailored towards further medical image analysis, which leaves a gap between upstream reconstruction and downstream analysis tasks. New reference standard datasets should be created for better comparison of these GAN-based methods. 然而，尽管数据集经过精心策划以匹配训练和测试分布，但在进一步提高性能方面还存在其他问题。我们已经看到pix2pix框架引入了各种不同的损失，如表2所示，以提高局部结构的重建保真度。然而，除了依靠人类观察者或下游图像分析任务外，没有可靠的方法来比较它们的有效性。目前，基于GAN的重建方法缺乏由人类观察者进行的大规模统计分析。此外，用于图像重建的公共数据集不适合进一步的医学图像分析，这在上游重建和下游分析任务之间留下了差距。应创建新的参考标准数据集，以便更好地比较这些基于GAN的方法。 3.2 Medical image synthesisDepending on institutional protocols, patient consent may be required if diagnostic images are intended to be used in a publication or released into the public domain ( Clinical Practice Committee, 20 0 0 ). GANs are widely for medical image synthesis. This helps overcome the privacy issues related to diagnostic medical image data and tackle the insufficient number of positive cases of each pathology. Lack of experts annotating medical images poses another challenge for the adoption of supervised training methods.Although there are ongoing collaborative efforts across multiple healthcare agencies aiming to build large open access datasets, e.g. Biobank, the National Biomedical Imaging Archive (NBIA), The Cancer Imaging Archive (TCIA) and Radiologist Society of North America (RSNA), this issue remains and constrains the number of images researchers might have access to ( Table 3 ). 根据机构协议，如果诊断图像拟用于出版物或发布到公共领域，则可能需要患者同意（临床实践委员会，20 0）。GANs广泛应用于医学图像合成。这有助于克服与诊断医学图像数据相关的隐私问题，并解决每个病理学的阳性病例数量不足的问题。缺乏对医学图像进行注释的专家对采用监督训练方法提出了另一个挑战。尽管多个医疗机构正在进行合作，以建立大型开放存取数据集，例如Biobank、国家生物医学成像档案馆（NBIA）、癌症成像档案馆（TCIA）和北美放射科医师协会（RSNA），这个问题仍然存在，并限制了研究人员可能获得的图像数量（表3）。 Traditional ways to augment training sample include scaling, rotation, flipping, translation, and elastic deformation ( Simard et al., 2003 ). However, these transformations do not account for variations resulting from different imaging protocols or sequences, not to mention variations in the size, shape, location and appearance of specific pathology. GANs provide a more generic solution and have been used in numerous works for augmenting training images with promising results. 增强训练样本的传统方法包括缩放、旋转、翻转、平移和弹性变形（Simard et al.，2003）。然而，这些转换并没有考虑到不同成像协议或序列导致的变化，更不用说特定病理学的大小、形状、位置和外观的变化了。GANs提供了一种更通用的解决方案，并已在许多工程中用于增强训练图像，取得了良好的效果。 3.2.1 Unconditional synthesisUnconditional synthesis refers to image generation from random noise without any other conditional information. Techniques commonly adopted in the medical imaging community include DCGAN, WGAN, and PGGAN due to their good training stability.The first two methods can handle an image resolution of up to 256 ×256 but if higher resolution images are desired, the progressive technique proposed in PGGAN is a choice. Realistic images can be generated by directly using the author released code base as long as the variations between images are not too large, for example, lung nodules and liver lesions. To make the generated images useful for downstream tasks, most studies trained a separate generator for each individual class; for example, Frid-Adar et al. (2018) used three DCGANs to generate synthetic samples for three classes of liver lesions (cysts, metastases, and hemangiomas); generated samples were found to be beneficial to the lesion classification task with both improved sensitivity and specificity when combined with real training data.Bermudez et al. (2018) claimed that neuroradiologists found generated MR images to be of comparable quality to real ones, however, there were discrepancies in anatomic accuracy. Papers related to unconditional medical image synthesis are summarized in Table 4 . 无条件合成是指在没有任何其他条件信息的情况下，从随机噪声中生成图像。医学成像界通常采用的技术包括DCGAN、WGAN和PGGAN，因为它们具有良好的训练稳定性。前两种方法可以处理高达256×256的图像分辨率，但如果需要更高分辨率的图像，则可以选择PGGAN中提出的渐进式技术。只要图像之间的差异不太大，例如肺结节和肝脏病变，就可以直接使用作者发布的代码库生成逼真的图像。为了使生成的图像对下游任务有用，大多数研究为每个单独的类训练了一个单独的生成器；例如，Frid Adar等人（2018年）使用三种DCG生成三类肝脏病变（囊肿、转移瘤和血管瘤）的合成样本；生成的样本被发现有利于病变分类任务，与真实训练数据相结合时，灵敏度和特异性都有所提高。Bermudez等人（2018年）声称，神经放射科医生发现生成的MR图像质量与真实图像相当，但在解剖准确性方面存在差异。表4总结了与无条件医学图像合成相关的论文。 3.2.2 Cross modality synthesisCross modality synthesis (such as generating CT-like images based on MR images) is deemed to be useful for multiple reasons, one of which is to reduce the extra acquisition time and cost.Another reason is to generate new training samples with the appearance being constrained by the anatomical structures delineated in the available modality. Most of the methods reviewed in this section share many similarities to those in Section 3.1 .pix2pix-based frameworks are used in cases where different image modality data can be co-registered to ensure data fidelity. 跨模态合成（例如基于MR图像生成CT样图像）被认为是有用的，原因有多种，其中之一是减少额外的采集时间和成本。另一个原因是生成新的训练样本，其外观受可用模式中描绘的解剖结构的约束。本节中回顾的大多数方法与第3.1节中的方法有许多相似之处。基于pix2pix的框架用于不同图像模态数据可以共同配准以确保数据保真度的情况。 CycleGAN-based frameworks are used to handle more general cases where registration is challenging such as in cardiac applications. In a study by Wolterink et al. (2017a) for brain CT image synthesis from MR image, the authors found that training using unpaired images was even better than using aligned images. This most likely resulted from the fact that rigid registration could not very well handle local alignment in the throat, mouth, vertebrae, and nasal cavities. Hiasa et al. (2018) further incorporated gradient consistency loss in the training to improve accuracy at the boundaries. Zhang et al. (2018d) found that using only cycle loss in the cross modality synthesis was insufficient to mitigate geometric distortions in the transformation. Therefore, they employed a shape consistency loss that is obtained from two segmentors (segmentation network). Each segmentor segments the corresponding image modality into semantic labels and provides implicit shape constraints on the anatomy during translation. To make the whole system end-to-end trainable, semantic labels of training images from both modalities are required. Zhang et al. (2018c) and Chen et al. (2018a) proposed using a segmentor also in the cycle transfer using labels in only one modality. Therefore, the segmentor is trained offline and fixed during the training of the image transfer network. As reviewed in Section 2 , UNIT and CycleGAN are two equally valid frameworks for unpaired cross modality synthesis. It was found that these two frameworks performed almost equally well for the transformation between T1 and T2-weighted MR images ( Welander et al., 2018 ). Papers related to cross modality medical image synthesis are summarized in Table 5 . 基于CycleGAN的框架用于处理配准具有挑战性的更一般情况，例如在心脏应用中。在Wolterink et al.（2017a）关于从MR图像合成大脑CT图像的研究中，作者发现使用未配对图像进行训练甚至比使用对齐图像更好。这很可能是因为刚性配准不能很好地处理咽喉、口腔、脊椎和鼻腔的局部对齐。Hiasa等人（2018年）进一步将梯度一致性损失纳入训练中，以提高边界的准确性。Zhang等人（2018d）发现，在交叉模态合成中仅使用循环损失不足以缓解变换中的几何失真。因此，他们采用了从两个分割器（分割网络）获得的形状一致性损失。每个切割器将相应的图像模态分割成语义标签，并在翻译过程中对解剖结构提供隐式形状约束。为了使整个系统端到端可训练，需要来自两种模式的训练图像的语义标签。Zhang et al.（2018c）和Chen et al.（2018a）建议在循环传输中也使用切割器，仅在一种模式中使用标签。因此，在图像传输网络的训练期间，切割器离线训练并固定。如第2节所述，UNIT和CycleGAN是两个同样有效的非配对跨模态综合框架。研究发现，这两种框架在T1和T2加权MR图像之间的转换中表现几乎相同（Welander et al.，2018）。表5总结了与跨模态医学图像合成相关的论文。 3.2.3 Other conditional synthesisMedical images can be generated by constraints on segmen- tation maps, text, locations or synthetic images etc. This is useful to synthesize images in uncommon conditions, such as lung nodules touching the lung border ( Jin et al., 2018 ). Moreover, the conditioned segmentation maps can also be generated from GANs ( Guibas et al., 2017 ) or from a pretrained segmentation net- work ( Costa et al., 2017a ), by making the generation a two stage process. Mok and Chung (2018) used cGAN to augment training images for brain tumour segmentation. The generator was condi- tioned on a segmentation map and generated brain MR images in a coarse to fine manner. To ensure the tumour was well delineated with a clear boundary in the generated image, they further forced the generator to output the tumour boundaries in the generation process. The full list of synthesis works is summarized in Table 6 . 医学图像可以通过对分割图、文本、位置或合成图像等的约束生成。这对于在罕见情况下合成图像非常有用，例如肺结节触及肺边界（Jin等人，2018）。此外，通过将生成过程分为两个阶段，也可以从GANs（Guibas等人，2017）或预训练分割网络（Costa等人，2017a）生成条件分割图。Mok和Chung（2018）使用cGAN增强用于脑肿瘤分割的训练图像。该发生器在分割图上进行调节，并以从粗到精的方式生成大脑MR图像。为了确保生成的图像中肿瘤边界清晰，他们进一步强制生成器在生成过程中输出肿瘤边界。表6总结了综合工作的完整清单。 3.3 SegmentationGenerally, researchers have used pixel-wise or voxel-wise loss such as cross entropy for segmentation. Despite the fact that U-net ( Ronneberger et al., 2015 ) was used to combine both low-level and high-level features, there is no guarantee of spatial consistency in the final segmentation map. Traditionally, conditional random field (CRF) and graph cut methods are usually adopted for segmentation refinement by incorporating spatial correlation. Their limitation is that they only take into account pair-wise potentials which might cause serious boundary leakage in low contrast regions. On the other hand, adversarial losses as introduced by the discriminator can take into account high order potentials ( Yang et al., 2017a ). In this case, the discriminator can be regarded as a shape regulator. This regularization effect is more prominent when the object of interest has a compact shape, e.g. for lung and heart mask(???) but less useful for deformable objects such as vessels and catheters. This regulation effect can be also applied to the internal features of the segmentor to achieve domain (different scanners, imaging protocols, modality) invariance ( Kamnitsas et al., 2017; Dou et al., 2018 ). The adversarial loss can also be viewed as a adaptively learned similarity measure between the segmented outputs and the annotated groundtruth. Therefore, instead of measuring the similarity in the pixel domain, the discriminative network projects the input to a low dimension manifold and measures the similarity there. The idea is similar to the perceptual loss. The difference is that the perceptual loss is computed from a pre-trained classification network on natural images whereas the adversarial loss is computed from a network that trained adaptively during the evolvement of the generator. 通常，研究人员使用像素级或体素级的损失，如交叉熵进行分割。尽管U-net（Ronneberger et al.，2015）被用于结合低层和高层特征，但无法保证最终分割图的空间一致性。传统上，通常采用条件随机场（CRF）和图切割方法，通过结合空间相关性进行分割细化。它们的局限性在于，它们只考虑了在低对比度区域可能导致严重边界泄漏的二元势函数pair-wise potentials。另一方面，判别器引入的对抗性损失可以考虑高阶势函数high order potentials（Yang等人，2017a）。在这种情况下，判别器可被视为形状调节器。当感兴趣的对象具有紧凑的形状时，这种正则化效果更为显著，例如用于肺和*心脏面罩(???)*，但对于可变形对象（如血管和导管）不太有用。该调节效应也可应用于分割器的内部特征，以实现域（不同扫描仪、成像协议、模态）不变性（Kamnitsas等人，2017年；Dou等人，2018年）。对抗性损失也可以被视为分割输出和正确标注数据之间的自适应学习相似性度量。因此，区别网络不是在像素域中测量相似性，而是将输入投影到低维流形并在那里测量相似性。这种想法类似于感知损失。不同之处在于，感知损失是通过对自然图像进行预训练的分类网络计算的，而对抗损失是通过在生成器演化过程中进行自适应训练的网络计算的。 Xue et al. (2018) used a multi-scale $L_1$ loss in the discriminator where features coming from different depths are compared. This was demonstrated to be effective in enforcing the multiscale spatial constraints on segmentation maps and the system achieved state-of-the-art performance in the BRATS 13 and 15 challenges. Zhang et al. (2017c) proposed to use both annotated and unan- notated images in the segmentation pipeline. The annotated images are used in the same way as in Xue et al. (2018) and Son et al. (2017) where both element-wise loss and adversarial loss are applied. The unannotated images on the other hand are only used to compute a segmentation map to confuse the discriminator. Li and Shen (2018) combined pix2pix with ACGAN for segmentation of fluorescent microscopy images of different cell types. They found that the introduction of the auxiliary classifier branch provides regulation to both the discriminator and the segmentor. Xue et al.（2018）在判别器中使用多尺度$L_1$损失，比较来自不同深度的特征。这被证明是有效的，在分割地图上实施多尺度空间约束，系统在BRAT 13和15挑战中实现了最先进的性能。Zhang等人（2017c）建议在分割管道中同时使用注释图像和非注释图像。注释图像的使用方式与Xue et al.（2018）和Son et al.（2017）中相同，其中元素损失和对抗损失均适用。另一方面，未标注的图像仅用于计算分割图以混淆判别器。Li和Shen（2018）将pix2pix与ACGAN相结合，对不同细胞类型的荧光显微镜图像进行分割。他们发现，辅助分类器分支的引入为判别器和分割器提供了调节。 Unlike these aforementioned segmentation works where adversarial training is used to ensure higher order structure consistency on the final segmentation maps, the adversarial training scheme in Zhu et al. (2018) enforces network invariance to small perturbations of the training samples in order to reduce overfitting on small dataset. Papers related to medical image segmentation are summarized in Table 8 . 与上述使用对抗性训练确保最终分割图上的高阶结构一致性的分割工作不同，Zhu等人（2018）的对抗性训练方案对训练样本的小扰动实施网络不变性，以减少小数据集上的过度拟合。表8总结了与医学图像分割相关的论文。 3.4 ClassificationClassification is arguably one of the most successful tasks where deep learning has been applied. Hierarchical image features can be extracted from a deep neural network discriminatively trained with image-wise class labels. GANs have been used for classification problems as well, either using part of the generator and discriminator as a feature extractor or directly using the discriminator as a classifier (by adding an extra class corresponding to the generated images). Hu et al. (2018) used combined WGAN and InfoGAN for unsupervised cell-level feature representation learning in histopathology images whereas Yi et al. (2018) combined WGAN and CatGAN for unsupervised and semi-supervised feature representation learning for dermoscopy images. Both works extract features from the discriminator and build a classifier on top. Madani et al. (2018b) , Lahiri et al. (2017) and Lecouat et al. (2018) adopted the semi- supervised training scheme of GAN for chest abnormality classification, patch-based retinal vessel classification and cardiac disease diagnosis respectively. They found that the semi-supervised GAN can achieve performance comparable with a traditional supervised CNN with an order of magnitude less labeled data. Furthermore, Madani et al. (2018b) have also shown that the adversarial loss can reduce domain overfitting by simply supplying unlabeled test domain images to the discriminator in identifying cardiac abnormalities in chest X-ray. A similar work in addressing domain variance in whole slide images (WSI) has been conducted by Ren et al. (2018) . 分类可以说是应用深度学习的最成功的任务之一。分层图像特征可以从深度神经网络中提取，深度神经网络通过图像分类标签进行区分训练。GANs也用于分类问题，或者使用生成器和判别器的一部分作为特征提取器，或者直接使用判别器作为分类器（通过添加与生成的图像相对应的额外类）。Hu et al.（2018）将WGAN和InfoGAN组合用于组织病理学图像的无监督细胞级特征表示学习，而Yi et al.（2018）将WGAN和CatGAN组合用于皮肤镜图像的无监督和半监督特征表示学习。这两项工作都从判别器中提取特征，并在顶部构建分类器。Madani et al.（2018b）、Lahiri et al.（2017）和Lecouat et al.（2018）分别采用GAN的半监督训练方案进行胸部异常分类、基于斑片的视网膜血管分类和心脏病诊断。他们发现，半监督GAN可以实现与传统监督CNN相当的性能，标记数据数量级更少。此外，Madani等人（2018b）还表明，对抗性丢失可以通过简单地向判别器提供未标记的测试域图像来减少域过度拟合，从而识别胸部X射线中的心脏异常。Ren等人（2018年）在解决整张幻灯片图像中的域差异（WSI）方面进行了类似的工作。 Most of the other works that used GANs to generate new training samples have been already mentioned in Section 3.2.1 . These studies applied a two stage process, with the first stage learned to augment the images and the second stage learned to perform classification by adopting the traditional classification network. The two stages are trained disjointedly without any communication in between. The advantage is that these two components can be replaced easily if more advanced unconditional synthesis architectures are proposed whereas the downside is that the generation has to be conducted for each class separately (N models for N classes), which is not memory and computation efficient. A single model that is capable of performing conditional synthesis of mul- tiple categories is an active research direction ( Brock et al., 2018 ). Surprisingly, Frid-Adar et al. (2018) found that using separate GAN (DCGAN) for each lesion class resulted in better performance in lesion classification than using a unified GAN (ACGAN) for all classes. The underlying reason remains to be explored. Furthermore, Finlayson et al. (2018) argue that images generated from GANs may serve as an effective augmentation in the medium-data regime, but may not be helpful in a high or low-data regime. 第3.2.1节已经提到了使用GANs生成新训练样本的大多数其他工作。这些研究采用了两个阶段的过程，第一阶段学习增强图像，第二阶段学习采用传统分类网络进行分类。这两个阶段是分开训练的，中间没有任何交流。优点是，如果提出更高级的无条件合成体系结构，这两个组件可以很容易地被替换，而缺点是必须对每个类分别进行生成（N个类的N个模型），这不利于内存和计算效率。能够对多个类别进行条件合成的单一模型是一个积极的研究方向（Brock等人，2018年）。令人惊讶的是，Frid Adar等人（2018年）发现，对每个病变类别使用单独的GAN（DCGAN）比对所有类别使用统一的GAN（ACGAN）在病变分类方面表现更好。根本原因仍有待探讨。此外，Finlayson等人（2018年）认为，从GANs生成的图像可以作为中等数据区域的有效增强，但在高或低数据区域可能没有帮助。 3.5 DetectionThe discriminator of GANs can be utilized to detect abnormalities such as lesions by learning the probability distribution of training images depicting normal pathology. Any image that falls out of this distribution can be deemed as abnormal. Schlegl et al. (2017) used the exact idea to learn a manifold of normal anatomical variability and proposed a novel anomaly scoring scheme based on the fitness of the test image’s latent code to the learned manifold. The learning process was conducted in an unsupervised fashion and effectiveness was demonstrated by state- of-the-art performance of anomaly detection on optical coherence tomography (OCT) images. Alex et al. (2017) used GAN for brain lesion detection on MR images. The generator was used to model the distribution of normal patches and the trained discriminator was used to compute a posterior probability of patches centered on every pixel in the test image. Chen and Konukoglu (2018) used an adversarial auto-encoder to learn the data distribution of healthy brain MR images. The lesion image was then mapped to an image without a lesion by exploring the learned latent space, and the lesion could be highlighted by computing the residual of these two images. We can see that all the detection studies targeted for abnormalities that are hard to enumerate. 通过学习描述正常病理学的训练图像的概率分布，GANs鉴别器可用于检测异常，如病变。任何不符合此分布的图像都可以被视为异常。Schlegl等人（2017年）利用准确的想法学习了一个正常解剖变异的流形，并基于测试图像的潜在代码与学习的流形的适合度，提出了一种新的异常评分方案。学习过程以无监督的方式进行，光学相干断层扫描（OCT）图像异常检测的最新性能证明了学习过程的有效性。Alex等人（2017年）使用GAN在MR图像上检测脑损伤。该生成器用于模拟正态面片的分布，训练的鉴别器用于计算以测试图像中每个像素为中心的面片的后验概率。Chen和Konukoglu（2018）使用对抗式自动编码器学习健康大脑MR图像的数据分布。然后，通过探索学习到的潜在空间，将病变图像映射到没有病变的图像，并通过计算这两个图像的残差来突出病变。我们可以看到，所有的检测研究都针对难以列举的异常。 附录最大对数似然目标鞍点优化JS散度模式崩溃f散度铰链损失Wasserstein距离自动编码器架构完全卷积采样分割掩模像素级或体素级二元势函数高阶势函数感知损失","categories":[],"tags":[{"name":"GAN, 生成对抗网络, Medical imaging, 医学图像","slug":"GAN-生成对抗网络-Medical-imaging-医学图像","permalink":"http://lethewind.github.io/tags/GAN-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-Medical-imaging-%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/"}]},{"title":"机器学习相关名词解释","slug":"机器学习相关名词解释","date":"2021-10-11T05:39:23.000Z","updated":"2021-10-11T05:40:09.804Z","comments":true,"path":"2021/10/11/机器学习相关名词解释/","link":"","permalink":"http://lethewind.github.io/2021/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/","excerpt":"","text":"名词解释机器学习Machine Learning：机器学习致力于研究如何通过计算的手段，利用经验来改善自身性能。也即在计算机上从数据中产生“模型”model的算法，即学习算法learning algorithm 经验：通常以数据形式存在的训练集 模型model：泛指从数据中学习到的结果。有时用“模型”指全局性的结果（如一棵决策树），而用“模式”指代局部性结果（如一条规则） 数据集data set：数据的集合，每一条记录是关于一个事件或对象的描述，称为一个示例instance或样本sample，反应事件或对象在某一方面的表现或性质的事项，称为属性attribute或特征feature；属性上的取值称为“属性值”attribute value","categories":[],"tags":[{"name":"名词解释, 机器学习, 人工智能","slug":"名词解释-机器学习-人工智能","permalink":"http://lethewind.github.io/tags/%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"数据结构笔记（基于浙大MOOC）","slug":"数据结构笔记（基于浙大MOOC）","date":"2021-10-11T05:30:24.000Z","updated":"2021-10-11T05:32:06.368Z","comments":true,"path":"2021/10/11/数据结构笔记（基于浙大MOOC）/","link":"","permalink":"http://lethewind.github.io/2021/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9F%BA%E4%BA%8E%E6%B5%99%E5%A4%A7MOOC%EF%BC%89/","excerpt":"","text":"数据结构（ZJU-MOOC）第一讲 基本概念1.1 什么是数据结构 数据结构是计算机中存储、组织数据的方式。通常情况下，精心准备的数据结构可以带来最有效率的算法。 通常来说代码的效率与数据的规模直接挂钩，通过将大规模的问题缩小到小规模的问题的方法，往往有奇效。 递归对于空间的占用是极为恐怖的。 时间库&lt;time.h&gt;的使用方法 12345678910111213141516171819202122#include &lt;time.h&gt;#include &lt;stdio.h&gt;clock_t start, stop;/* clock_t 是clock()函数返回的变量类型 */double duration;/* 用来记录运行时间，以秒为单位 */int main()&#123; /* 不在测试范围之前的准备工作写在clock()调用之前 */ start = clock(); //开始计时 MyFunction(); //把测试函数写在这里 stop = clock(); duration = ((double)(stop - start))/CLK_TCK; /* 其他不在测试范围的处理写在后面，例如输出duration的值 */ return 0;&#125; 数据结构是数据对象在计算机中的组织方式，数据对象一定与一系列加在其之上的操作相关联，完成这些操作所用的方法就是算法 线性结构 1 to 1 树形结构 1 to n 图 n to n 抽象数据类型 数据对象集 数据集合相关联的操作集 1.2 什么是算法 算法的定义（一个有限的指令集，输入输出，在有限的步骤后停止，每一条指令都必须有明确的目标且不存在歧义，在计算机处理范围内，描述应不依赖于任何一种计算机语言以及具体的实现手段） 算法的评价指标 空间复杂度$S(n)$ 时间复杂度$O(n)$ 乘除法的时间消耗比加减法高很多，在时间复杂度计算的过程中权重更高 在分析一般算法的效率时，我们经常关注下面两种复杂度 最坏情况复杂度$T_{worst}(n)$ 平均复杂度$T_{avg}(n)$ $T_{avg}(n)\\le T_{worst}(n)$ 复杂度的渐进表示法 1.3 应用实例：最大子列和问题问题描述：给定$N$个整数的序列${A_1,A_2,\\dots,A_N}$,求函数$f(i,j)=max{0,\\sum^j_{k=1}A_k}$的最大值 算法一：暴力搜索，计算出所有子列和，$O(n^3)$ 算法二：利用前缀和，减少一层循环，$O(n^2)$ 算法三：分治思想，分成两段分别寻找最大子列和，然后合并寻找最大子列和，$O(n\\log{n})$ 算法四：在线处理（指每输入一个数据就进行即时处理，在任何一个地方中止输入，算法都能正确给出当前解），$O(N)$ 第二讲 线性结构2.1 线性表及其实现2.1.1 多项式的表示一元多项式$f(x)=a_0+a_1x+\\dots+a_{n-1}x^{n-1}+a_n x^n$及其计算（多项式相加、相减、相乘） 方法一：顺序存储结构直接表示（每一位固定存储对应的指数级的系数） 造成大量浪费，诸如$x+3x^{2000}$ 方法二：顺序存储结构表示非零项（使用结构数组表示，数组分量表示系数和指数，按照指数大小有序存储即可方便计算） 方法三：链表结构存储非零项（链表中每个节点存储多项式的一个非零项，包括系数和指数两个数据域以及一个指针域用于指向下一个节点） 多项式表示问题的启示： 同一个问题可以有不同的表示、存储方式 有一类共性问题：有序线性序列的组织和管理 2.1.2 线性表的实现线性表(Linear List)：由同类型数据元素构成的有序序列的线性结构 表中元素个数称为长度 线性表没有元素时，称为空表 表起始位置称表头，结束位置称表尾 线性表的抽象数据类型描述 主要操作的实现 数组方式 插入 1234for(j=PtrL-&gt;Last;j&gt;=i-1;j--) PtrL-&gt;Data[j+1]=PtrL-&gt;Data[j]; /*将a[i]~a[n]倒序向后移动*/PtrL-&gt;Data[i-1]=X; /*新元素插入*/PtrL-&gt;Last++; /*Last依然指向最后元素*/ 删除 123for(j=i;j&lt;=PtrL-&gt;Last;j++) PtrL-&gt;Data[j-1]=PtrL-&gt;Data[j]; /*将a[i+1]~a[n]顺序向后移动*/PtrL-&gt;Last--; /*Last依然指向最后元素*/ 链表方式 组织形式 1234567typedef struct LNode *List;struct LNode&#123;ElementType Data;List Next;&#125;;struct Lnode L;List PtrL; 求表长（遍历一遍） 123456789int Length(List PtrL)&#123; List p=PtrL; /*p指向表的第一个节点*/ int j=0; while(p)&#123; p=p-&gt;next; j++; /*当前p指向的是第j个节点*/ &#125; return j;&#125; 查找 1234567891011121314151617181920/*按照序号查找*/List FindKth(int K,List PtrL)&#123; List p=PtrL; int i=1; while(p!=NULL&amp;&amp;i&lt;K)&#123; p=p-&gt;next; i++; &#125; if(i==K)return p; /*找到第K个，返回指针*/ else return NULL; /*否则返回空*/&#125;/*按照数据值进行查找*/List Find(List PtrL,ElementType X)&#123; List p=PtrL; /* p指向L的第1个结点 */ while (p!=NULL&amp;&amp;p-&gt;Data!=X) p=p-&gt;Next; /* 下列语句可以用 return p; 替换 */ if(p)return p; else return ERROR;&#125; 插入 先构造一个新节点，用s指向； 再找到链表的第$i-1$个节点，用p指向； 然后修改指针，插入节点（p之后插入新节点s）。 1234567891011121314151617181920List Insert(ElementType X,int i,List PtrL)&#123; List p,s; if(i==1)&#123; /*新节点插入在表头*/ s=(List)malloc(sizeof(struct LNode)); /*申请、装填节点*/ s-&gt;Data=X; s-&gt;Next=PtrL; return s; &#125; p=FindKth(i-1,PtrL); /*查找第i-1个节点*/ if(p==NULL)&#123; /*第i-1个节点不存在*/ return ERROR; &#125;else&#123; s=(List)malloc(sizeof(struct LNode)); s-&gt;Data=X; s-&gt;Next=p-&gt;Next; /*新节点插入在第i-1个节点之后*/ p-&gt;Next=s; return PtrL; &#125; &#125; 删除 先找到链表的第$i-1$个节点，用p指向； 再用指针s指向要被删除的节点（p的下一个节点）； 然后修改指针，删除s所指节点； 最后释放s所指的节点的空间。 123456789101112131415161718192021List Dlete(int i,List PtrL)&#123; List p,s; if(i==1)&#123; s=PtrL; if(PtrL!=NULL)PtrL=PtrL-&gt;Next; else return NULL; free(s); return PtrL; &#125; p=FindKth(i-1,PtrL); if(p==NULL)&#123; printf(&quot;第%d个节点不存在&quot;,i-1);return NULL; &#125;else if(p-&gt;next==NULL)&#123; printf(&quot;第%d个节点不存在&quot;,i);return NULL; &#125;else &#123; s=p-&gt;Next; /*s指向第i个节点*/ p-&gt;Next=s-&gt;Next; /*从链表中删除*/ free(s); /*释放被删除节点空间*/ return PtrL; &#125;&#125; 2.1.3 广义表广义表是线性表的推广，对于线性表来说，n个元素都是基本的单元素，广义表中，这些元素不仅可以是单元素也可以是另一个广义表。 双向链表、多重链表 矩阵尤其是稀疏矩阵，使用多重链表中的十字链表进行存储更有利于节省存储空间 2.2 堆栈2.2.1 什么是堆栈堆栈Stack：具有一定操作约束的线性表，只能在一端（栈顶，top）做插入和删除（先进后出Last In First Out） 插入数据：入栈Push，删除数据：出栈Pop 堆栈的抽象数据类型描述： 2.2.2 堆栈的实现 数组实现 12345678910111213141516171819202122typedef struct SNode *Stack;struct SNode&#123; ElementType Data[MaxSize]; int Top;&#125;;void Push(Stack PtrS,ElementType item)&#123; if(PtrS-&gt;Top==MaxSize-1)&#123; printf(&quot;Full&quot;);return; &#125;else&#123; PtrS-&gt;Data[++(PtrS-&gt;Top)]=item; return; &#125;&#125;ElementType Pop(Stack PtrS)&#123; if(PtrS-&gt;Top==-1)&#123; printf(&quot;Empty&quot;); return ERROR; &#125;else return (PtrS-&gt;Data[(PtrS-&gt;Top)--]);&#125; 链表实现 1234567891011121314151617181920212223242526272829303132333435363738struct SNode&#123; ElementType Data; struct SNode *Next;&#125;;Stack CreateStack()&#123; Stack S; S=(Stack)malloc(sizeof(struct SNode)); S-&gt;Next=NULL; return s;&#125;int IsEmpty(Stack S)&#123; return (S-&gt;Next==NULL);&#125;void Push(ElementType item,Stack S)&#123; struct SNode *TmpCell; TmpCell=(struct SNode *)malloc(sizeof(struct SNode)); TmpCell-&gt;Element=item; TmpCell-&gt;Next=S-&gt;Next; S-&gt;Next=TmpCell;&#125;/*可以看到链表的堆栈是以链表头为栈顶，在此处进行插入和删除实现的*/ElementType Pop(Stack S)&#123; struct SNode *FirstCell; ElementType TopElem; if(IsEmpty(S))&#123; printf(&quot;Empty&quot;);return NULL; &#125;else&#123; FirstCell=S-&gt;Next; S-&gt;Next=FirstCell-&gt;Next; TopElem=FirstCell-&gt;Element; free(FirstCell); return TopElem; &#125;&#125; 2.2.3 表达式求值 中缀表达式：$a+b*c-d/e$ 后缀表达式：$abc*+de/-$ 后缀表达式求值策略：从左向右“扫描”，逐个处理运算数和运算符号；遇到运算数时压栈，遇到运算符号时从堆栈中弹出适当的运算数，计算结构后入栈；最后栈顶元素就是表达式的结果。 中缀表达式转后缀表达式 2.3 队列2.3.1 什么是队列队列Queue：具有一定操作约束的线性表，只能在一端插入，另一端删除，即先进先出。 数据插入：入队列AddQ，数据删除：出队列DeleteQ，先进先出FIFO 队列的抽象数据类型描述 2.3.2 队列的实现 数组实现 1234567891011121314151617181920212223242526272829struct QNode&#123; ElementType Data[MaxSize]; int rear; int front;&#125;;typedef struct QNode *Queue;//思考循环链表判断队列空和满的条件void AddQ(Queue PtrQ,ElementType item)&#123; if(PtrQ-&gt;rear+1==MaxSize)&#123; //(PtrQ-&gt;rear+1)%MaxSize==PtrQ-&gt;front printf(&quot;Full&quot;); return; &#125; //PtrQ-&gt;rear=(PtrQ-&gt;rear+1)%MaxSize; //PtrQ-&gt;Data[PtrQ-&gt;rear]=item; PtrQ-&gt;Data[++PtrQ-&gt;rear]=item;&#125;ElementType DeleteQ(Queue PtrQ)&#123; if(PtrQ-&gt;front==PtrQ-&gt;rear)&#123; printf(&quot;Empty&quot;); return; &#125;else&#123; //PtrQ-&gt;front=(PtrQ-&gt;front+1)%MaxSize; //return PtrQ-&gt;Data[PtrQ-&gt;front]; return PtrQ[PtrQ-&gt;front++]; &#125;&#125; 链表实现 123456789101112131415161718192021222324252627282930struct Node&#123; ElementType Data; struct Node *Next;&#125;;struct QNode&#123; struct Node *rear; struct Node *front;&#125;;typedef struct QNode *Queue;Queue PtrQ;ElementType DeleteQ(Queue PtrQ)&#123; struct Node *FrontCell; ElementType FrontElem; if(PtrQ-&gt;front==NULL)&#123; printf(&quot;Empty&quot;); return ERROR; &#125; FrontCell=PtrQ-&gt;front; if(PtrQ-&gt;front==PtrQ-&gt;rear)//若队列只有一个元素 PtrQ-&gt;front=PtrQ-&gt;rear=NULL;//删除后置队列为空 else PtrQ-&gt;front=PtrQ-&gt;front-&gt;Next; FrontElem=FrontCell-&gt;Data; free(FrontCell);//释放被删除节点空间 return FrontElem;&#125; 第三章 树3.1 树与树的表示3.1.1 查找查找Searching：根据某个给定的关键词K，从集合R中找到关键字与K相同的记录 静态查找：集合中记录是固定的，没有插入和删除操作，只有查找 动态查找：集合中记录是动态变化的；除查找，还可能发生插入和删除 静态查找方法 方法一：顺序查找$O(n)$ 方法二：二分查找$O(log{n})$ 假设n个数据元素的关键字满足有序，如$k_1&lt;k_2&lt;\\cdots&lt;k_n$，并且是连续存放（数组），那么可以进行二分查找 $mid=(left+right)/2$ 123456789101112int BinarySearch(List Tbl,ElementType K)&#123; int left,right,mid,NotFound=-1; left=1; right=Tbl-&gt;Length; while(left&lt;=right)&#123; mid=(left&lt;=right)/2; if(K&lt;Tbl-&gt;Element[mid])right=mid-1; else if(K&gt;Tbl-&gt;Element[mid])left=mid+1; else return mid; &#125; return NotFound;&#125; 3.1.2 树的基础树Tree：$n$个节点构成的有限集合。当$n=0$时，称为空树；对于任一非空树$n&gt;0$，它具备如下特征： 树中有一个称为根Root节点的特殊节点，用r表示； 其余节点可以分为$m(m&gt;0)$个互不相交的有限集$T_1,T_2,\\dots,T_m$，其中每个集合本身又是一棵树，称为原来树的“子树SubTree” 树的一些基本术语 结点的度Degree：结点的子树个数 树的度：树的所有节点中最大的度数 叶结点Leaf：度为0的结点 父结点Parent：有子树的结点是其子树的根结点的父结点 子结点Child：若A结点是B结点的父结点，则称B结点是A结点的子结点 兄弟结点Siblings：具有同一父结点的各结点彼此是兄弟结点 路径和路径长度：从结点$n_1$到结点$n_k$的路径为一个结点序列$n_1,n_2,\\dots,n_k$，$n_i$是$n_{i+1}$的父结点。路径所包含的边的个数为路径的长度。 祖先结点Ancestor：沿树根到某一结点路径上的所有结点都是这个结点的祖先结点。 子孙结点Descendant：某一结点的子树中所有结点是这个结点的子孙。 结点的层次Level：规定根结点在1层，其他任一结点的层数是其父结点的层数加1。 树的深度Depth：树中所有结点中最大层次是这棵树的深度 树相关的计算 规律1：（节点个数）m=（边数）n+1规律2： 度为节点的子女个数，可以看作几个出边就是几个度，叶子节点没有度 树的表示 儿子兄弟表示法 实际上此方法就构造了一棵新的二叉树，也即实现了二叉树的表示即可表示任意树。 3.2 二叉树及存储结构3.2.1 二叉树的定义二叉树$T$：一个有穷的结点集合，这个结点可以为空，若不为空，则它是由根结点和称为其左子树$T_L$和右子树$T_R$的两个不相交的二叉树组成。其中每个结点的度最大为2。 二叉树的子树有左右顺序之分 二叉树的五种基本形态 特殊二叉树 斜二叉树Skewed Binary Tree 完全二叉树Complete Binary Tree 有n个结点的二叉树，对树中结点按从上至下、从左到右顺序进行编号，编号为$i (1\\le i \\le n)$结点与满二叉树中编号为i结点在二叉树中位置相同 完美二叉树Perfect Binary Tree、满二叉树Full Binary Tree 3.2.2 二叉树的几个重要性质 一个二叉树第$i$层最大结点数为：$2^{i-1},i\\ge 1$ 深度为$k$的二叉树有最大结点数为：$2^k-1,k\\ge1$ 对任何非空二叉树$T$，若$n_0$表示叶结点的个数、$n_2$是度为2的非叶结点的个数，那么两者的关系满足$n_0=n_2+1$ $n$个结点的二叉树一共多少种？ $f(n)=\\frac{(2n)!}{n!(n+1)!}$ $n$层二叉树的第$n$层最多有多少个结点？ $f(n)=2^{n-1}$ 一个有$n$个结点的完全二叉树的深度为？ $h(n)=log_2n+1$ 一个完全二叉树的结点为$n$，则该二叉树的叶子结点为多少？ $f(n)=n-(n/2)$ 3.2.3 二叉树的表示和实现二叉树的抽象表示 二叉树的存储结构 顺序存储结构 完全二叉树：按从上至下、从左到右顺序存储 $n$个结点的完全二叉树的结点父子关系： 非根结点（序号$i&gt;1$）的父结点的序号是$\\lfloor i \\rfloor$ 结点（序号为$i$）的左孩子结点的序号是$2i$（$2i\\le n$，否则没有左孩子） 结点（序号为$i$）的右孩子结点的序号是$2i+1$（$2i+1\\le n$，否则没有左孩子） 对于一般的二叉树也可以使用这种结构，但会造成很高的空间浪费 链表存储 1234567typedef struct TreeNode *BinTree;typedef BinTree Position;struct TreeNode&#123; ElementType Data; BinTree Left; BinTree Right;&#125;; 静态链表 使用结构数组构建“链表形式”的“静态链表”，其中左右孩子指示位存储的是左右孩子所对应的下标 3.3 二叉树的遍历先序、中序、后序遍历过程中经过节点的路线一样，只是访问各结点的实际不同。 3.3.1 先序遍历访问根结点、先序遍历其左子树、先序遍历其右子树 先序遍历非递归遍历算法：使用堆栈 遇到一个结点，就把它输入然后压栈，并去遍历其左子树 当左子树遍历结束后，按照其右指针再去中序遍历该结点的右子树 1234567891011121314151617181920void preOrder2(BinTree *root) //非递归前序遍历&#123; stack&lt;BinTree*&gt; s; BinTree *p=root; while(p!=NULL||!s.empty()) &#123; while(p!=NULL) &#123; cout&lt;&lt;p-&gt;data&lt;&lt;&quot; &quot;; s.push(p); p=p-&gt;lchild; &#125; if(!s.empty()) &#123; p=s.top(); s.pop(); p=p-&gt;rchild; &#125; &#125;&#125; 3.3.2 中序遍历中序遍历其左子树、访问根结点、中序遍历其右子树 中序遍历非递归遍历算法：使用堆栈 遇到一个结点，就把它压栈，并去遍历其左子树 当左子树遍历结束后，从栈顶弹出此结点并访问之 然后按照其右指针再去中序遍历该结点的右子树 1234567891011121314151617181920void inOrder2(BinTree *root) //非递归中序遍历&#123; stack&lt;BinTree*&gt; s; BinTree *p=root; while(p!=NULL||!s.empty()) &#123; while(p!=NULL) &#123; s.push(p); p=p-&gt;lchild; &#125; if(!s.empty()) &#123; p=s.top(); cout&lt;&lt;p-&gt;data&lt;&lt;&quot; &quot;; s.pop(); p=p-&gt;rchild; &#125; &#125;&#125; 3.3.3 后序遍历后序遍历其左子树、后序遍历其右子树、访问根节点 后序遍历非递归遍历算法：使用堆栈 第一种思路：对于任一结点P，将其入栈，然后沿其左子树一直往下搜索，直到搜索到没有左孩子的结点，此时该结点出现在栈顶，但是此时不能将其出栈并访问， 因此其右孩子还为被访问。所以接下来按照相同的规则对其右子树进行相同的处理，当访问完其右孩子时，该结点又出现在栈顶，此时可以将其出栈并访问。这样就 保证了正确的访问顺序。可以看出，在这个过程中，每个结点都两次出现在栈顶，只有在第二次出现在栈顶时，才能访问它。因此需要多设置一个变量标识该结点是 否是第一次出现在栈顶。 123456789101112131415161718192021222324252627282930313233void postOrder2(BinTree *root) //非递归后序遍历&#123; stack&lt;BTNode*&gt; s; BinTree *p=root; BTNode *temp; while(p!=NULL||!s.empty()) &#123; while(p!=NULL) //沿左子树一直往下搜索，直至出现没有左子树的结点 &#123; BTNode *btn=(BTNode *)malloc(sizeof(BTNode)); btn-&gt;btnode=p; btn-&gt;isFirst=true; s.push(btn); p=p-&gt;lchild; &#125; if(!s.empty()) &#123; temp=s.top(); s.pop(); if(temp-&gt;isFirst==true) //表示是第一次出现在栈顶 &#123; temp-&gt;isFirst=false; s.push(temp); p=temp-&gt;btnode-&gt;rchild; //访问其右子树 &#125; else //第二次出现在栈顶 &#123; cout&lt;&lt;temp-&gt;btnode-&gt;data&lt;&lt;&quot; &quot;; p=NULL; &#125; &#125; &#125;&#125; 第二种思路：要保证根结点在左孩子和右孩子访问之后才能访问，因此对于任一结点P，先将其入栈。如果P不存在左孩子和右孩子，则可以直接访问它；或者P存 在左孩子或者右孩子，但是其左孩子和右孩子都已被访问过了，则同样可以直接访问该结点。若非上述两种情况，则将P的右孩子和左孩子依次入栈，这样就保证了 每次取栈顶元素的时候，左孩子在右孩子前面被访问，左孩子和右孩子都在根结点前面被访问。 12345678910111213141516171819202122232425void postOrder3(BinTree *root) //非递归后序遍历&#123; stack&lt;BinTree*&gt; s; BinTree *cur; //当前结点 BinTree *pre=NULL; //前一次访问的结点 s.push(root); while(!s.empty()) &#123; cur=s.top(); if((cur-&gt;lchild==NULL&amp;&amp;cur-&gt;rchild==NULL)|| (pre!=NULL&amp;&amp;(pre==cur-&gt;lchild||pre==cur-&gt;rchild))) &#123; cout&lt;&lt;cur-&gt;data&lt;&lt;&quot; &quot;; //如果当前结点没有孩子结点或者孩子节点都已被访问过 s.pop(); pre=cur; &#125; else &#123; if(cur-&gt;rchild!=NULL) s.push(cur-&gt;rchild); if(cur-&gt;lchild!=NULL) s.push(cur-&gt;lchild); &#125; &#125;&#125; 3.3.4 层次遍历二叉树遍历的核心问题：二维结构的线性化 从结点访问其左、右儿子结点 访问左儿子后，右儿子结点需要一个存储结构（堆栈、队列）保存暂时不访问的结点 层序遍历的实现：利用队列，遍历从根节点开始，首先将根结点入队，然后开始执行循环：结点出队、访问该结点、其左右儿子入队 3.3.5 遍历二叉树算法的应用 输出二叉树中的叶子结点：在二叉树的遍历算法中增加检测结点“左右子树是否都为空”的判断语句。 求二叉树的高度：二叉树的高度为其左子树和右子树高度最大值+1 二元运算表达式树及其遍历 由两种遍历序列确定二叉树（必须要有中序序列） 判别两个二叉树是否同构 3.4 二叉搜索树3.4.1 什么是二叉搜索树组织动态查找时，若将数据按照一定的规则在二叉树中进行存储，则每次的搜索的效率取决于树的深度$h(n)=log_2n+1$，即得到一种高效的算法。 二叉搜索树BST,Binary Search Tree，也称二叉排序树或二叉查找树。为一棵非空二叉树，且满足如下三条性质： 非空左子树的所有键值小于其根结点的键值； 非空右子树的所有键值大于其根结点的键值； 左、右子树都是二叉搜索树。 3.4.2 二叉搜索树的抽象表示和实现二叉搜索树的抽象表示 二叉搜索树的查找操作Find 查找从根结点开始，如果树为空，返回NULL 若搜索树非空，则根结点关键字和X进行比较，并进行不同处理： 若X小于根结点键值，只需要在左子树中继续搜索 若X大于根结点键值，在右子树中进行继续搜索 若两者比较结果相等，搜索完成，返回指向此节点的指针 递归实现 123456789Position Find(ElementType X,BinTree BST)&#123; if(!BST)return NULL; if(X&gt;BST-&gt;Data) return Find(X,BST-&gt;Right); else if(X&lt;BST-&gt;Data) return Find(X,BST-&gt;Left); else return BST;&#125; 非递归（循环）实现 1234567891011Position IterFind(ElementType X,BinTree BST)&#123; while(BST)&#123; if(X&gt;BST-&gt;Data) BST=BST-&gt;Right; else if(X&lt;BST-&gt;Data) BST=BST-&gt;Left; else return BST; &#125; return NULL;&#125; 查找最大和最小元素 最大元素一定在树的最右分枝的端结点上，最小元素一定在树的最左分枝的端结点上 查找最大/小元素实现 12345678910111213Position FindMin(BinTree BST)&#123; if(!BST)return NULL; else if(!BST-&gt;Left) return BST; else return FindMin(BST-&gt;Left);&#125;Position FindMax(BinTree BST)&#123; if(BST) while(BST-&gt;Right)BST=BST-&gt;Right; return BST;&#125; 二叉搜索树的插入 12345678910111213BinTree Insert(ElementType X,BinTree BST)&#123; if(!BST)&#123; //若原树为空，生成并返回一个结点的二叉搜索树 BST=malloc(sizeof(struct TreeNode)); BST-&gt;Data=X; BST-&gt;Left=BST-&gt;Right=NULL; &#125;else if(X&lt;BST-&gt;Data) //递归插入左子树 BST-&gt;Left=Insert(X,BST-&gt;Left); else if(X&gt;BST-&gt;Data) //递归插入右子树 BST-&gt;Right=Insert(X,BST-&gt;Right); //X已经存在，查找到原址 return BST;&#125; 二叉搜索树的删除 考虑三种情况： 要删除的是叶结点：直接删除并修改其父节点指针——置为NULL 要删除的节点只有一个孩子结点：将其父结点的指针指向要删除的结点的孩子结点 要删除的结点有左、右子树：用另一个结点替代被删除节点，通常是左子树的最大元素或右子树的最小元素 12345678910111213141516171819202122232425BinTree Delete(ElementType X,BinTree BST)&#123; Position Tmp; if(!BST)printf(&quot;Unfindable!&quot;); else if(X&lt;BST-&gt;Data) BST-&gt;Left=Delete(X,BST-&gt;Left); //左子树递归删除 else if(X&gt;BST-&gt;Data) BST-&gt;Right=Delete(X,BST-&gt;Right); //右子树递归删除 else if(BST-&gt;Left &amp;&amp; BST-&gt;Right)&#123; //找到了被删除节点，且点有左右两个子结点 //在右子树中找到最小元素 Tmp=FindMin(BST-&gt;Right); //将找到的最小值赋值给被删除结点 BST-&gt;Data=Tmp-&gt;Data; BST-&gt;Right=Delete(BST-&gt;Data,BST-&gt;Right); //在删除节点的右子树中删除最小元素 &#125;else&#123; //被删除结点有一个或无子结点 Tmp=BST; if(!BST-&gt;Left) // 有右孩子或无子结点 BST=BST-&gt;Right; else if(!BST-&gt;Right) // 有左孩子或无子结点 BST=BST-&gt;Left; free(Tmp); &#125; return BST;&#125; 3.4.3 判别是否是同一棵二叉搜索树 分别两个输入序列构造两棵二叉搜索树，然后判别是否相同 不建树的判别方法，根据序列，通过定位根节点位置进行判断 建一棵树，再判别其他序列是否与该树一致 搜索树的表示 建搜索树 判别一序列是否与搜索树$T$一致 3.5 平衡二叉树3.5.1 什么是平衡二叉树搜索树结点不同的插入次序，将导致不同的深度和平均查找长度ASL的不同 平衡因子Balance Factor(BF)：$BF(T)=h_L-h_R$，其中$h_L$和$h_R$分别为$T$的左子树和右子树的高度 平衡二叉树Balanced Binary Tree/AVL Tree：空树或者任一结点左右子树高度差的绝对值不超过1，即$|BF(T)|\\le 1$ 3.5.2 平衡二叉树的调整 RR旋转：不平衡的“发现者”是A，“麻烦结点”在发现者右子树的右边，因此成为RR插入，需要RR旋转（右单旋） LL旋转：不平衡的“发现者”是A，“麻烦结点”在发现者左子树的左边，因此称为LL插入，需要LL旋转（左单旋） LR旋转：不平衡的“发现者”是A，“麻烦结点”在左子树的右边，因此叫做LR插入，需要LR旋转 RL旋转：与LR旋转类似 PS：有的时候插入元素即使不需要调整结构，也可能需要重新计算平衡因子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281#include&lt;iostream&gt;#include&lt;cmath&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;using namespace std;template&lt;class T&gt;struct Node &#123; T key; Node&lt;T&gt;* lchild; Node&lt;T&gt;* rchild; Node&lt;T&gt;(T k) : key(k), lchild(nullptr), rchild(nullptr) &#123;&#125;&#125;;template&lt;class T&gt;class AVLTree &#123;private: Node&lt;T&gt;* root;public: AVLTree() :root(nullptr) &#123;&#125;; Node&lt;T&gt;* getRoot() &#123; return root; &#125; void printTree(); Node&lt;T&gt;* llRotation(Node&lt;T&gt;*); Node&lt;T&gt;* lrRotation(Node&lt;T&gt;*); Node&lt;T&gt;* rrRotation(Node&lt;T&gt;*); Node&lt;T&gt;* rlRotation(Node&lt;T&gt;*); void balance(Node&lt;T&gt;*); void insert(const T&amp;); bool remove(Node&lt;T&gt;*, Node&lt;T&gt;*, T); int getDepth(Node&lt;T&gt;*); int getBalanceFactor(Node&lt;T&gt;*); Node&lt;T&gt;* findMin(Node&lt;T&gt;*); Node&lt;T&gt;* findMax(Node&lt;T&gt;*); void fixUp(); Node&lt;T&gt;* find(Node&lt;T&gt;* node, T key);&#125;;template&lt;class T&gt;void AVLTree&lt;T&gt;::printTree() &#123; //层次遍历 Node&lt;T&gt;* pos = root; //当前位置 Node&lt;T&gt;* flag = root; //层末标识 queue&lt;Node&lt;T&gt;*&gt; q; q.push(root); //根节点入队 while (!q.empty()) &#123; //队列非空 Node&lt;T&gt;* node = q.front(); q.pop(); //弹出队首 cout &lt;&lt; node-&gt;key &lt;&lt; &#x27;\\t&#x27;; if (node-&gt;lchild != nullptr) &#123; //左孩子非空则入队 q.push(node-&gt;lchild); pos = node-&gt;lchild; &#125; if (node-&gt;rchild != nullptr) &#123; //右孩子非空则入队 q.push(node-&gt;rchild); pos = node-&gt;rchild; &#125; if (node == flag) &#123; //抵达层末 flag = pos; cout &lt;&lt; &quot;\\n&quot;; &#125; &#125;&#125;template&lt;class T&gt;void AVLTree&lt;T&gt;::insert(const T&amp; key) &#123; Node&lt;T&gt;* node = new Node&lt;T&gt;(key); if (root == nullptr) &#123; root = node; return; &#125; Node&lt;T&gt;* pos = root; while (true) &#123; //查找插入位置 if (node-&gt;key &lt; pos-&gt;key) &#123; if (pos-&gt;lchild == nullptr) &#123; pos-&gt;lchild = node; fixUp(); return; &#125; //end if else pos = pos-&gt;lchild; &#125; //end if else if (node-&gt;key &gt; pos-&gt;key) &#123; if (pos-&gt;rchild == nullptr) &#123; pos-&gt;rchild = node; fixUp(); return; &#125; //end if else pos = pos-&gt;rchild; &#125; //end if else return; //树中已有此节点则无操作 &#125; //end while&#125;template&lt;class T&gt;int AVLTree&lt;T&gt;::getDepth(Node&lt;T&gt;* node) &#123; if (node == nullptr) return 0; return max(getDepth(node-&gt;lchild), getDepth(node-&gt;rchild)) + 1;&#125;template&lt;class T&gt;int AVLTree&lt;T&gt;::getBalanceFactor(Node&lt;T&gt;* node) &#123; //平衡因子 = 左子树高-右子树高 return getDepth(node-&gt;lchild) - getDepth(node-&gt;rchild);&#125;template&lt;class T&gt;void AVLTree&lt;T&gt;::balance(Node&lt;T&gt;* node) &#123; int bf = getBalanceFactor(node); if (bf &gt; 1) &#123; if (getBalanceFactor(node-&gt;lchild) &gt; 0) root = llRotation(node); else root = lrRotation(node); &#125; else if (bf &lt; -1) &#123; if (getBalanceFactor(node-&gt;rchild) &gt; 0) root = rlRotation(node); else root = rrRotation(node); &#125; return;&#125;//LLtemplate&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::llRotation(Node&lt;T&gt;* node) &#123; //插入节点在左子树左边，右旋 Node&lt;T&gt;* temp = node-&gt;lchild; node-&gt;lchild = temp-&gt;rchild; temp-&gt;rchild = node; return temp;&#125;//LRtemplate&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::lrRotation(Node&lt;T&gt;* node) &#123; //插入节点在左子树右边 Node&lt;T&gt;* temp = node-&gt;lchild; node-&gt;lchild = rrRotation(temp); return llRotation(node);&#125;//RLtemplate&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::rlRotation(Node&lt;T&gt;* node) &#123; //插入节点在右子树左边 Node&lt;T&gt;* temp = node-&gt;rchild; node-&gt;rchild = llRotation(temp); return rrRotation(node);&#125;//RRtemplate&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::rrRotation(Node&lt;T&gt;* node) &#123; //插入节点在右子树右边，左旋 Node&lt;T&gt;* temp = node-&gt;rchild; node-&gt;rchild = temp-&gt;lchild; temp-&gt;lchild = node; return temp;&#125;template&lt;class T&gt;bool AVLTree&lt;T&gt;::remove(Node&lt;T&gt;* node, Node&lt;T&gt;* parent, T key) &#123; Node&lt;T&gt;* temp = nullptr; if (node == nullptr) // 未找到目标节点 return false; else if (key &lt; node-&gt;key) return remove(node-&gt;lchild, node, key); else if (key &gt; node-&gt;key) return remove(node-&gt;rchild, node, key); else if (node-&gt;lchild &amp;&amp; node-&gt;rchild) &#123; //删除节点有左子树也有右子树 if (getDepth(node-&gt;lchild) &gt; getDepth(node-&gt;rchild)) &#123; //左子树高，前驱替代 temp = findMax(node-&gt;lchild); node-&gt;key = temp-&gt;key; return remove(node-&gt;lchild,node, node-&gt;key); &#125; else &#123; //右子树不比左子树矮，后驱替代 temp = findMin(node-&gt;rchild); node-&gt;key = temp-&gt;key; return remove(node-&gt;rchild, node, node-&gt;key); &#125; &#125; else &#123; if ((node-&gt;lchild &amp;&amp; node-&gt;rchild == nullptr)) &#123; //删除节点有左孩子无右孩子 temp = findMax(node-&gt;lchild); node-&gt;key = temp-&gt;key; return remove(node-&gt;lchild, node, node-&gt;key); &#125; else if (node-&gt;rchild &amp;&amp; node-&gt;lchild == nullptr) &#123; //删除节点有右孩子无左孩子 temp = findMin(node-&gt;rchild); node-&gt;key = temp-&gt;key; return remove(node-&gt;rchild, node, node-&gt;key); &#125; //end if else &#123; //删除节点最终递归到删除叶子节点 if (node == parent-&gt;lchild) //父节点指针置空 parent-&gt;lchild = nullptr; else parent-&gt;rchild = nullptr; delete node; //释放子节点 node = nullptr; fixUp(); &#125; &#125; //end else return true;&#125;template&lt;class T&gt;void AVLTree&lt;T&gt;::fixUp() &#123; Node&lt;T&gt;* temp = this-&gt;root; //自顶向下调整树 while (1) //寻找失衡的节点 &#123; if (getBalanceFactor(temp) == 2) &#123; if (fabs(getBalanceFactor(temp-&gt;lchild)) == 1) break; else temp = temp-&gt;lchild; &#125; else if (getBalanceFactor(temp) == -2) &#123; if (fabs(getBalanceFactor(temp-&gt;rchild)) == 1) break; else temp = temp-&gt;rchild; &#125; else break; &#125; balance(temp); return;&#125;template&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::find(Node&lt;T&gt;* node, T key) &#123; while (node != nullptr &amp;&amp; key != node-&gt;key) &#123; //迭代查找 if (key &lt; node-&gt;key) node = node-&gt;lchild; else node = node-&gt;rchild; &#125; if (node == nullptr) cout &lt;&lt; &quot;Element &quot; &lt;&lt; key &lt;&lt; &quot; doesn&#x27;t exist!&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;Element &quot; &lt;&lt; key &lt;&lt; &quot; exists.&quot; &lt;&lt; endl; return node;&#125;template&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::findMax(Node&lt;T&gt;* node) &#123; if (node != nullptr) &#123; while (node-&gt;rchild) node = node-&gt;rchild; &#125; return node;&#125;template&lt;class T&gt;Node&lt;T&gt;* AVLTree&lt;T&gt;::findMin(Node&lt;T&gt;* node) &#123; if (node != nullptr) &#123; if (node-&gt;lchild == nullptr) //左孩子为空，当前节点已是最左下 return node; else return findMin(node-&gt;lchild); //左孩子不为空，往左子树遍历 &#125; else return nullptr; //空树返回nullptr&#125;int main() &#123; int arr[]&#123; 7,4,8,5,1,6&#125;;//ll:738512建树;rr:7385129删除2;rl:7385124删除4;lr:748516建树 AVLTree&lt;int&gt; avl; for (int i = 0; i &lt; 6; i++) &#123; avl.insert(arr[i]); &#125; avl.printTree(); avl.find(avl.getRoot(),8); avl.remove(avl.getRoot(), nullptr, 8); avl.printTree();&#125; Above Code from [kite97] 3.6 堆3.6.1 什么是堆优先队列Priority Queue：特殊的队列，取出元素的顺序是按照元素的优先权（关键字）大小，而不是元素进入队列的先后顺序。 堆Heap即为优先队列的完全二叉树表示，堆的两个特性： 结构性：用数组表示的完全二叉树； 有序性：任一结点的关键字是其子树所有结点的最大值（或最小值） 最大堆MaxHeap也称“大顶堆”：最大值 最小堆MinHeap也称“小顶堆”：最小值 3.6.2 堆的表示和实现堆抽象数据结构描述 最大堆的操作：创建、插入、删除、维护 定义 12345678910111213141516171819202122typedef struct HNode *Heap; /* 堆的类型定义 */struct HNode &#123; ElementType *Data; /* 存储元素的数组 */ int Size; /* 堆中当前元素个数 */ int Capacity; /* 堆的最大容量 */&#125;;typedef Heap MaxHeap; /* 最大堆 */typedef Heap MinHeap; /* 最小堆 */#define MAXDATA 1000 /* 该值应根据具体情况定义为大于堆中所有可能元素的值 */MaxHeap CreateHeap( int MaxSize )&#123; /* 创建容量为MaxSize的空的最大堆 */ MaxHeap H = (MaxHeap)malloc(sizeof(struct HNode)); H-&gt;Data = (ElementType *)malloc((MaxSize+1)*sizeof(ElementType)); H-&gt;Size = 0; H-&gt;Capacity = MaxSize; H-&gt;Data[0] = MAXDATA; /* 定义&quot;哨兵&quot;为大于堆中所有可能元素的值*/ return H;&#125; 插入 通过一个示例来理解堆插入的过程，将16插入到下面的堆中 `16` 被添加最后一行的第一个空位。不行的是，现在堆属性不满足，因为 `2` 在 `16` 的上面，我们需要将大的数字在上面（这是一个最大堆）为了恢复堆属性，我们需要交换 `16` 和 `2`。现在还没有完成，因为 `10` 也比 `16` 小。我们继续交换我们的插入元素和它的父节点，直到它的父节点比它大或者我们到达树的顶部。这就是所谓的 **shift-up**，每一次插入操作后都需要进行。它将一个太大或者太小的数字“浮起”到树的顶部。 12345678910111213141516171819202122bool IsFull( MaxHeap H )&#123; return (H-&gt;Size == H-&gt;Capacity);&#125;//将新增结点插入到从其父结点到根节点的有序序列中bool Insert( MaxHeap H, ElementType X )&#123; /* 将元素X插入最大堆H，其中H-&gt;Data[0]已经定义为哨兵 */ int i; if ( IsFull(H) ) &#123; printf(&quot;最大堆已满&quot;); return false; &#125; i = ++H-&gt;Size; /* i指向插入后堆中的最后一个元素的位置 */ //哨兵起到一个边界判定的作用，若是没有在data[0]设置哨兵元素则判定条件应为 H-&gt;Data[i/2] &lt; X &amp;&amp; i&gt;1 for ( ; H-&gt;Data[i/2] &lt; X; i/=2 ) //当父结点小于当前结点时进行交换 H-&gt;Data[i] = H-&gt;Data[i/2]; /* 上滤X */ H-&gt;Data[i] = X; /* 将X插入 */ return true;&#125; 删除 我们将这个树中的 10 删除，但在删除后顶部空出了一个节点，很自然的我们要从下面找到合适的结点来维持堆的属性。 当插入节点的时候，我们将新的值返给数组的尾部。现在我们来做相反的事情：我们取出数组中的最后一个元素，将它放到树的顶部，然后再修复堆属性。 现在来看怎么 shift-down。为了保持最大堆的堆属性，我们需要树的顶部是最大的数据。现在有两个数字可用于交换 7 和 2。我们选择这两者中的较大者称为最大值放在树的顶部，所以交换 7 和 1。 继续堆化直到该节点没有任何子节点或者它比两个子节点都要大为止。对于我们的堆，我们只需要再有一次交换就恢复了堆属性。 实质的核心思想就是：已知左子树是一个堆，右子树也是一个堆，对于一个新的元素，要如何将其调整为一个堆。 123456789101112131415161718192021222324252627282930313233343536#define ERROR -1 /* 错误标识应根据具体情况定义为堆中不可能出现的元素值 */bool IsEmpty( MaxHeap H )&#123; return (H-&gt;Size == 0);&#125;ElementType DeleteMax( MaxHeap H )&#123; /* 从最大堆H中取出键值为最大的元素，并删除一个结点 */ int Parent, Child; ElementType MaxItem, X; if ( IsEmpty(H) ) &#123; printf(&quot;最大堆已为空&quot;); return ERROR; &#125; MaxItem = H-&gt;Data[1]; /* 取出根结点存放的最大值 */ /* 用最大堆中最后一个元素从根结点开始向上过滤下层结点 */ X = H-&gt;Data[H-&gt;Size--]; /* 取最后一个结点，且注意当前堆的规模要减小 */ //将最后一个元素假定为最大值，之后找出其左右儿子中较大的那个替换位置 //之后重复操作到找不到左右儿子，则此时堆的顺序维护完成 for( Parent=1; Parent*2&lt;=H-&gt;Size; Parent=Child ) &#123; Child = Parent * 2; //Child先指向左儿子 if( (Child!=H-&gt;Size) //child!=H-&gt;Size意味着一定存在右儿子 &amp;&amp; (H-&gt;Data[Child]&lt;H-&gt;Data[Child+1]) ) Child++; /* Child指向左右子结点的较大者 */ if( X &gt;= H-&gt;Data[Child] ) break; /* 找到了合适位置 */ else /* 下滤X */ H-&gt;Data[Parent] = H-&gt;Data[Child]; &#125; H-&gt;Data[Parent] = X; return MaxItem;&#125; 给定n个元素进行创建 方法一：通过插入操作，将N个元素一个个相继插入到一个初始为空的堆中去，其时间代价最大为$O(Nlog{N})$ 方法二：在线性时间复杂度下建立最大堆。 将N个元素按照输入顺序存入，先满足完全二叉树的结构特性； 调整各结点位置，以满足最大堆的有序特性。调整堆时采用删除操作中的方法进行调整，但从下往上进行调整，满足左右子树为堆+1结点的条件。故从最后一个非叶子节点也即最后一个父结点进行调整。 12345678910111213141516171819202122232425262728/*----------- 建造最大堆 -----------*/void PercDown( MaxHeap H, int p )&#123; /* 下滤：将H中以H-&gt;Data[p]为根的子堆调整为最大堆 */ int Parent, Child; ElementType X; X = H-&gt;Data[p]; /* 取出根结点存放的值 */ for( Parent=p; Parent*2&lt;=H-&gt;Size; Parent=Child ) &#123; Child = Parent * 2; if( (Child!=H-&gt;Size) &amp;&amp; (H-&gt;Data[Child]&lt;H-&gt;Data[Child+1]) ) Child++; /* Child指向左右子结点的较大者 */ if( X &gt;= H-&gt;Data[Child] ) break; /* 找到了合适位置 */ else /* 下滤X */ H-&gt;Data[Parent] = H-&gt;Data[Child]; &#125; H-&gt;Data[Parent] = X;&#125;void BuildHeap( MaxHeap H )&#123; /* 调整H-&gt;Data[]中的元素，使满足最大堆的有序性 */ /* 这里假设所有H-&gt;Size个元素已经存在H-&gt;Data[]中 */ int i; /* 从最后一个结点的父节点（也即最后一个非叶子结点）开始，到根结点1 */ for( i = H-&gt;Size/2; i&gt;0; i-- ) PercDown( H, i );&#125; 3.7 哈夫曼树和哈夫曼编码3.7.1 什么是哈夫曼树带权路径长度WPL：设二叉树有n个叶子结点，每个叶子结点带有权值$W_k$，从根结点到每个叶子结点的长度为$l_k$，则每个叶子结点的带权路径长度之和就是：$WPL=\\sum^n_{k=1}w_kl_k$ 最优二叉树/哈夫曼树：WPL最小的二叉树 3.7.2 哈夫曼树的构造每次把权值最小的两棵二叉树合并（利用构造最小堆可以很好地实现） 123456789101112131415161718typedef struct TreeNode *HuffmanTree;struct TreeNode&#123; int Weight; HuffmanTree Left,Right;&#125;;HuffmanTree Huffman(MinHeap H)&#123; //假设H-&gt;Size个权值已经存在H-&gt;Elements[]-&gt;Weight里 int i; HuffmanTree T; BuildMinHeap(H); //将H-&gt;Elements[]按照权值调整为最小堆 for(i=1;i&lt;H-&gt;Size;i++)&#123; //做H-&gt;Size-1次合并 T=malloc(sizeof(struct TreeNode)); T-&gt;Left=DeleteMin(H); T-&gt;Right=DeleteMin(H); //从最小堆中取出两个最小的节点作为左右节点 T-&gt;Weight=T-&gt;Left-&gt;Weight+T-&gt;Right-&gt;Weight; //重新计算权值 Insert(H,T); //将新的T插入到最小堆中 &#125;&#125; 3.7.3 哈夫曼树的特点 没有度为1的结点 n个叶子结点的哈夫曼树共有2n-1个结点 哈夫曼树的任意非叶节点的左右子树交换后仍是哈夫曼树 对同一组权值${w_1,w_2,\\dots,w_n}$，存在不同构的哈夫曼树，但WPL值是一样的 3.7.4 哈夫曼编码给定一段字符串，使用哈夫曼编码进行编码（不等长编码）可以使得该字符串的编码存储空间最小 在不等长编码中，为避免二义性，需要满足前缀码prefix code要求（任何字符的编码都不是另一字符编码的前缀），用二叉树表示编码即可完美避免二义性 3.8 集合及运算3.8.1 集合的表示 集合运算：交、并、补、差，判定一个元素是否属于某一集合 并查集：集合并、查某元素属于什么集合 并查集问题中使用树的结构存储集合，树的每一个结点代表一个集合元素 3.8.2 并查集的实现 采用数组存储形式 查找某个元素所在的集合（用根结点表示） 1234567891011121314151617181920212223#define MAXN 1000 /* 集合最大元素个数 */typedef int ElementType; /* 默认元素可以用非负整数表示 */typedef int SetName; /* 默认用根结点的下标作为集合名称 */typedef ElementType SetType[MAXN]; /* 假设集合元素下标从0开始 */SetName Find( SetType S, ElementType X )&#123; /* 默认集合元素全部初始化为-1 */ if ( S[X] &lt; 0 ) /* 找到集合的根 */ return X; else return S[X] = Find( S, S[X] ); /* 路径压缩 */&#125;//循环实现int Find(SetType S[],ElementType X)&#123; //在数组S中查找值为X的元素所对应的集合 //MaxSize是全局变量，为数组S的最大长度 int i; for(i=0;i&lt;MaxSize &amp;&amp; S[i].Data!=X;i++); if(i&gt;=MaxSize)return -1; //未找到X，返回-1 for(;S[i].Parent&gt;=0;i=S[i].Parent); return i; //找到x所属集合，返回树根结点在数组S中的下标&#125; 集合的并运算 分别找到X1和X2两个元素所在的集合树的根结点 如果他们不同根，则将其中一个根节点的父结点指针设置为另一个根结点的数组下标 123456789101112131415161718192021void Union(SetType S[],ElementType X1,ElementType X2)&#123; int Root1,Root2; Root1=Find(S,X1); Root2=Find(S,X2); if(Root1!=Root2)S[Root2].Parent=Root1;&#125;//这种固定将root2挂在root1下的方式会导致树的深度越来越深，影响find的效率//于是通过负数判定是否为根结点，而负数的绝对值则表示节点的个数，通过简单的修改，在判断时对两个集合的个数进行修改即可更具效率void Union( SetType S, SetName Root1, SetName Root2 )&#123; /* 这里默认Root1和Root2是不同集合的根结点 */ /* 保证小集合并入大集合 */ if ( S[Root2] &lt; S[Root1] ) &#123; /* 如果集合2比较大 */ S[Root2] += S[Root1]; /* 集合1并入集合2 */ S[Root1] = Root2; &#125; else &#123; /* 如果集合1比较大 */ S[Root1] += S[Root2]; /* 集合2并入集合1 */ S[Root2] = Root1; &#125;&#125; 第四章 图3.1 什么是图图Graph表示多对多的关系，包含一组顶点（通常用$V(Vertex)$）表示顶点集合，一组边（通常用$E(Edge)$）表示边的集合： 边是顶点对：$(v,w)\\in E$，其中$v,w\\in V$ 有向边$&lt;v,w&gt;$表示从$v$指向$w$的边（单向） 不考虑重边和自回路 抽象数据类型定义 图的表示 邻接矩阵$G[N][N]$，$N$个定点从0到$N-1$的编号$$G[i][j]=\\left{\\begin{aligned}1 &amp;&amp; 若&lt;v_i,v_j&gt;是G中的边 \\0 &amp;&amp; 否则\\end{aligned}\\right.$$ 对于无向图，可以使用一个长度为$N(N+1)/2$的一维数组$A$存储${G_{00},G_{10},G_{11},\\dots,G_{n-1 \\ 0},\\dots,G_{n-1 \\ n-1}}$，则$G_{ij}$在$A$中而对应的下标是$(i*(i+1)/2+j)$ 邻接矩阵的优点： 简单直观好理解 方便检查任意一队顶点间是否存在边 方便找任一顶点的所有“邻接点”（有边直接相连的顶点） 方便计算任一顶点的“度”（从该点发出的边数为“出度”，指向该点的边数为“入度”）。无向图的度为对应行/列的非零元素个数；有向图对应行非零元素个数为出度，对应列非零元素个数为入度 邻接矩阵的缺点： 浪费空间：对于稀疏图（点很多，边很少）有大量无效元素，而对于稠密图（特别是完全图）还是很合算的 浪费时间：统计稀疏图一共有多少条边 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/* 图的邻接矩阵表示法 */#define MaxVertexNum 100 /* 最大顶点数设为100 */#define INFINITY 65535 /* ∞设为双字节无符号整数的最大值65535*/typedef int Vertex; /* 用顶点下标表示顶点,为整型 */typedef int WeightType; /* 边的权值设为整型 */typedef char DataType; /* 顶点存储的数据类型设为字符型 *//* 边的定义 */typedef struct ENode *PtrToENode;struct ENode&#123; Vertex V1, V2; /* 有向边&lt;V1, V2&gt; */ WeightType Weight; /* 权重 */&#125;;typedef PtrToENode Edge; /* 图结点的定义 */typedef struct GNode *PtrToGNode;struct GNode&#123; int Nv; /* 顶点数 */ int Ne; /* 边数 */ WeightType G[MaxVertexNum][MaxVertexNum]; /* 邻接矩阵 */ DataType Data[MaxVertexNum]; /* 存顶点的数据 */ /* 注意：很多情况下，顶点无数据，此时Data[]可以不用出现 */&#125;;typedef PtrToGNode MGraph; /* 以邻接矩阵存储的图类型 */MGraph CreateGraph( int VertexNum )&#123; /* 初始化一个有VertexNum个顶点但没有边的图 */ Vertex V, W; MGraph Graph; Graph = (MGraph)malloc(sizeof(struct GNode)); /* 建立图 */ Graph-&gt;Nv = VertexNum; Graph-&gt;Ne = 0; /* 初始化邻接矩阵 */ /* 注意：这里默认顶点编号从0开始，到(Graph-&gt;Nv - 1) */ for (V=0; V&lt;Graph-&gt;Nv; V++) for (W=0; W&lt;Graph-&gt;Nv; W++) Graph-&gt;G[V][W] = INFINITY; return Graph; &#125; void InsertEdge( MGraph Graph, Edge E )&#123; /* 插入边 &lt;V1, V2&gt; */ Graph-&gt;G[E-&gt;V1][E-&gt;V2] = E-&gt;Weight; /* 若是无向图，还要插入边&lt;V2, V1&gt; */ Graph-&gt;G[E-&gt;V2][E-&gt;V1] = E-&gt;Weight;&#125;MGraph BuildGraph()&#123; MGraph Graph; Edge E; Vertex V; int Nv, i; scanf(&quot;%d&quot;, &amp;Nv); /* 读入顶点个数 */ Graph = CreateGraph(Nv); /* 初始化有Nv个顶点但没有边的图 */ scanf(&quot;%d&quot;, &amp;(Graph-&gt;Ne)); /* 读入边数 */ if ( Graph-&gt;Ne != 0 ) &#123; /* 如果有边 */ E = (Edge)malloc(sizeof(struct ENode)); /* 建立边结点 */ /* 读入边，格式为&quot;起点 终点 权重&quot;，插入邻接矩阵 */ for (i=0; i&lt;Graph-&gt;Ne; i++) &#123; scanf(&quot;%d %d %d&quot;, &amp;E-&gt;V1, &amp;E-&gt;V2, &amp;E-&gt;Weight); /* 注意：如果权重不是整型，Weight的读入格式要改 */ InsertEdge( Graph, E ); &#125; &#125; /* 如果顶点有数据的话，读入数据 */ for (V=0; V&lt;Graph-&gt;Nv; V++) scanf(&quot; %c&quot;, &amp;(Graph-&gt;Data[V])); return Graph;&#125; 邻接表：$G[N]$为指针数组，对应矩阵每行一个链表，只存非零元素 邻接表优点： 方便找任一顶点的所有邻接点 节约稀疏图的空间：需要N个头指针+2E个结点（每个指针至少两个域） 对于无向图方便计算任一顶点的度；而对于有向图则只能计算出度，需要构造逆邻接表来方便计算出度 邻接表缺点：不方便检查任意一对顶点间是否存在边 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* 图的邻接表表示法 */#define MaxVertexNum 100 /* 最大顶点数设为100 */typedef int Vertex; /* 用顶点下标表示顶点,为整型 */typedef int WeightType; /* 边的权值设为整型 */typedef char DataType; /* 顶点存储的数据类型设为字符型 *//* 边的定义 */typedef struct ENode *PtrToENode;struct ENode&#123; Vertex V1, V2; /* 有向边&lt;V1, V2&gt; */ WeightType Weight; /* 权重 */&#125;;typedef PtrToENode Edge;/* 邻接点的定义 */typedef struct AdjVNode *PtrToAdjVNode; struct AdjVNode&#123; Vertex AdjV; /* 邻接点下标 */ WeightType Weight; /* 边权重 */ PtrToAdjVNode Next; /* 指向下一个邻接点的指针 */&#125;;/* 顶点表头结点的定义 */typedef struct Vnode&#123; PtrToAdjVNode FirstEdge;/* 边表头指针 */ DataType Data; /* 存顶点的数据 */ /* 注意：很多情况下，顶点无数据，此时Data可以不用出现 */&#125; AdjList[MaxVertexNum]; /* AdjList是邻接表类型 *//* 图结点的定义 */typedef struct GNode *PtrToGNode;struct GNode&#123; int Nv; /* 顶点数 */ int Ne; /* 边数 */ AdjList G; /* 邻接表 */&#125;;typedef PtrToGNode LGraph; /* 以邻接表方式存储的图类型 */LGraph CreateGraph( int VertexNum )&#123; /* 初始化一个有VertexNum个顶点但没有边的图 */ Vertex V; LGraph Graph; Graph = (LGraph)malloc( sizeof(struct GNode) ); /* 建立图 */ Graph-&gt;Nv = VertexNum; Graph-&gt;Ne = 0; /* 初始化邻接表头指针 */ /* 注意：这里默认顶点编号从0开始，到(Graph-&gt;Nv - 1) */ for (V=0; V&lt;Graph-&gt;Nv; V++) Graph-&gt;G[V].FirstEdge = NULL; return Graph; &#125; void InsertEdge( LGraph Graph, Edge E )&#123; PtrToAdjVNode NewNode; /* 插入边 &lt;V1, V2&gt; */ /* 为V2建立新的邻接点 */ NewNode = (PtrToAdjVNode)malloc(sizeof(struct AdjVNode)); NewNode-&gt;AdjV = E-&gt;V2; NewNode-&gt;Weight = E-&gt;Weight; /* 将V2插入V1的表头 */ NewNode-&gt;Next = Graph-&gt;G[E-&gt;V1].FirstEdge; Graph-&gt;G[E-&gt;V1].FirstEdge = NewNode; /* 若是无向图，还要插入边 &lt;V2, V1&gt; */ /* 为V1建立新的邻接点 */ NewNode = (PtrToAdjVNode)malloc(sizeof(struct AdjVNode)); NewNode-&gt;AdjV = E-&gt;V1; NewNode-&gt;Weight = E-&gt;Weight; /* 将V1插入V2的表头 */ NewNode-&gt;Next = Graph-&gt;G[E-&gt;V2].FirstEdge; Graph-&gt;G[E-&gt;V2].FirstEdge = NewNode;&#125;LGraph BuildGraph()&#123; LGraph Graph; Edge E; Vertex V; int Nv, i; scanf(&quot;%d&quot;, &amp;Nv); /* 读入顶点个数 */ Graph = CreateGraph(Nv); /* 初始化有Nv个顶点但没有边的图 */ scanf(&quot;%d&quot;, &amp;(Graph-&gt;Ne)); /* 读入边数 */ if ( Graph-&gt;Ne != 0 ) &#123; /* 如果有边 */ E = (Edge)malloc( sizeof(struct ENode) ); /* 建立边结点 */ /* 读入边，格式为&quot;起点 终点 权重&quot;，插入邻接矩阵 */ for (i=0; i&lt;Graph-&gt;Ne; i++) &#123; scanf(&quot;%d %d %d&quot;, &amp;E-&gt;V1, &amp;E-&gt;V2, &amp;E-&gt;Weight); /* 注意：如果权重不是整型，Weight的读入格式要改 */ InsertEdge( Graph, E ); &#125; &#125; /* 如果顶点有数据的话，读入数据 */ for (V=0; V&lt;Graph-&gt;Nv; V++) scanf(&quot; %c&quot;, &amp;(Graph-&gt;G[V].Data)); return Graph;&#125; 3.2 图的遍历","categories":[],"tags":[{"name":"数据结构, 算法","slug":"数据结构-算法","permalink":"http://lethewind.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"}]},{"title":"激活函数","slug":"激活函数","date":"2021-09-18T04:17:19.000Z","updated":"2021-10-11T05:28:33.350Z","comments":true,"path":"2021/09/18/激活函数/","link":"","permalink":"http://lethewind.github.io/2021/09/18/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2021-09-18T03:18:50.091Z","updated":"2021-09-18T03:18:50.092Z","comments":true,"path":"2021/09/18/hello-world/","link":"","permalink":"http://lethewind.github.io/2021/09/18/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"GAN, 生成对抗网络, Medical imaging, 医学图像","slug":"GAN-生成对抗网络-Medical-imaging-医学图像","permalink":"http://lethewind.github.io/tags/GAN-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-Medical-imaging-%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/"},{"name":"名词解释, 机器学习, 人工智能","slug":"名词解释-机器学习-人工智能","permalink":"http://lethewind.github.io/tags/%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"数据结构, 算法","slug":"数据结构-算法","permalink":"http://lethewind.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"}]}